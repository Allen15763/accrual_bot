"""
SPX PR ERM é‚è¼¯åˆ¤æ–·èˆ‡è©•ä¼° - é…ç½®é©…å‹•ç‰ˆæœ¬
å°ˆé–€è™•ç† PR (Purchase Request) çš„ç‹€æ…‹è©•ä¼°å’Œæœƒè¨ˆæ¬„ä½è¨­ç½®

èˆ‡ PO çš„æ ¸å¿ƒå·®ç•°ï¼š
1. ä¸åˆ¤æ–·æ”¶è²¨ç‹€æ…‹ï¼ˆç„¡ Received Quantity ç›¸é—œé‚è¼¯ï¼‰
2. ä¸åˆ¤æ–·å…¥è³¬ç‹€æ…‹ï¼ˆç„¡ Billed Amount ç›¸é—œé‚è¼¯ï¼‰
3. åŸºæ–¼æ¥­å‹™é¡å‹ï¼ˆç§Ÿé‡‘/Intermediary/è³‡ç”¢ï¼‰é€²è¡Œåˆ¤æ–·
4. ç°¡åŒ–çš„æœƒè¨ˆæ¬„ä½è¨­ç½®ï¼ˆä¸è™•ç†é ä»˜æ¬¾å’Œè² å‚µç§‘ç›®ï¼‰

ç‹€æ…‹æ¢ä»¶å¾ [spx_pr_erm_status_rules] é…ç½®è®€å–ï¼Œ
ç”± SPXConditionEngine ä¾ priority é †åºåŸ·è¡Œã€‚

ä½œè€…: Claude
å‰µå»ºæ—¥æœŸ: 2025-10-27
"""

import time
from typing import Dict, Any
import pandas as pd
import numpy as np

from accrual_bot.core.pipeline.base import PipelineStep, StepResult, StepStatus
from accrual_bot.core.pipeline.context import ProcessingContext
from accrual_bot.utils.config import config_manager
from accrual_bot.core.pipeline.steps.common import StepMetadataBuilder


class SPXPRERMLogicStep(PipelineStep):
    """
    SPX PR ERM é‚è¼¯æ­¥é©Ÿ - é…ç½®é©…å‹•ç‰ˆæœ¬

    åŠŸèƒ½ï¼š
    1. è¨­ç½®æª”æ¡ˆæ—¥æœŸ
    2. åˆ¤æ–· 8 ç¨® PR ç‹€æ…‹ï¼ˆå¾ [spx_pr_erm_status_rules] é…ç½®è®€å–ï¼‰
    3. æ ¹æ“šç‹€æ…‹è¨­ç½®æ˜¯å¦ä¼°è¨ˆå…¥å¸³
    4. è¨­ç½®æœƒè¨ˆç›¸é—œæ¬„ä½ï¼ˆç°¡åŒ–ç‰ˆæœ¬ï¼‰

    æ¥­å‹™è¦å‰‡ï¼š
    - PR é‚è¼¯ï¼šåŸºæ–¼ ERMã€æ‘˜è¦æœˆä»½ã€æ¥­å‹™é¡å‹åˆ¤æ–·ç‹€æ…‹
    - å®Œæˆç‹€æ…‹çš„é …ç›®éœ€è¦ä¼°åˆ—å…¥å¸³
    - æœªå®Œæˆç‹€æ…‹ä¸€å¾‹ä¸ä¼°åˆ—ï¼ˆæ˜¯å¦ä¼°è¨ˆå…¥å¸³ = Nï¼‰
    - 8 å€‹ ERM æ¢ä»¶ç”±é…ç½®å¼•æ“ä¾ priority é †åºåŸ·è¡Œ

    èˆ‡ PO çš„ä¸»è¦å·®ç•°ï¼š
    - ç§»é™¤æ”¶è²¨ç›¸é—œåˆ¤æ–·ï¼ˆç„¡ Received Quantityï¼‰
    - ç§»é™¤å…¥è³¬ç›¸é—œåˆ¤æ–·ï¼ˆç„¡ Billed Amountï¼‰
    - ç§»é™¤é ä»˜æ¬¾è™•ç†
    - ç§»é™¤è² å‚µç§‘ç›®è¨­ç½®
    - åŸºæ–¼æ¥­å‹™é¡å‹ï¼ˆç§Ÿé‡‘/Intermediary/è³‡ç”¢ï¼‰é€²è¡Œåˆ¤æ–·

    è¼¸å…¥ï¼š
    - DataFrame with required columns for PR
    - Reference data (ç§‘ç›®æ˜ å°„)
    - Processing date

    è¼¸å‡ºï¼š
    - DataFrame with PRç‹€æ…‹, æ˜¯å¦ä¼°è¨ˆå…¥å¸³, and simplified accounting fields
    """

    def __init__(self, name: str = "SPX_PR_ERM_Logic", **kwargs):
        super().__init__(
            name=name,
            description="Apply SPX PR ERM logic with config-driven status conditions",
            **kwargs
        )

        # å¾é…ç½®è®€å–é—œéµåƒæ•¸
        self.fa_accounts = config_manager.get_list('SPX', 'fa_accounts', ['199999'])
        self.dept_accounts = config_manager.get_list('SPX', 'dept_accounts', [])

        # åˆå§‹åŒ–é…ç½®é©…å‹•å¼•æ“
        from accrual_bot.core.pipeline.steps.spx_condition_engine import SPXConditionEngine
        self.engine = SPXConditionEngine('spx_pr_erm_status_rules')

        self.logger.info(f"Initialized {name} for PR processing (config-driven)")
        self.logger.info(f"  - FA accounts: {self.fa_accounts}")
    
    async def execute(self, context: ProcessingContext) -> StepResult:
        """åŸ·è¡Œ PR ERM é‚è¼¯"""
        start_time = time.time()

        try:
            df = context.data.copy()
            processing_date = context.get_variable('processing_date')

            # ç²å–åƒè€ƒæ•¸æ“š
            ref_account = context.get_auxiliary_data('reference_account')

            if ref_account is None:
                raise ValueError("ç¼ºå°‘åƒè€ƒæ•¸æ“šï¼šç§‘ç›®æ˜ å°„")

            self.logger.info("=" * 70)
            self.logger.info("ğŸš€ é–‹å§‹ PR ERM é‚è¼¯è™•ç†ï¼ˆé…ç½®é©…å‹•ï¼‰")
            self.logger.info(f"ğŸ“… è™•ç†æ—¥æœŸï¼š{processing_date}")
            self.logger.info(f"ğŸ“Š è¼¸å…¥è¨˜éŒ„æ•¸ï¼š{len(df):,}")
            self.logger.info("=" * 70)

            # ========== éšæ®µ 1: è¨­ç½®åŸºæœ¬æ¬„ä½ ==========
            df = self._set_file_date(df, processing_date)

            # ========== éšæ®µ 2: ç¢ºèªç‹€æ…‹æ¬„ä½ ==========
            status_column = self._get_status_column(df)
            self.logger.info(f"ğŸ“‹ ç‹€æ…‹æ¬„ä½ï¼š{status_column}")

            # ========== éšæ®µ 3: æ‡‰ç”¨é…ç½®é©…å‹•çš„ PR ç‹€æ…‹æ¢ä»¶ ==========
            df = self._apply_pr_status_conditions(df, status_column, processing_date)

            # ========== éšæ®µ 4: è™•ç†æ ¼å¼éŒ¯èª¤èˆ‡å…¶ä»– ==========
            df = self._handle_format_errors(df, status_column)

            # ========== éšæ®µ 5: è¨­ç½®æ˜¯å¦ä¼°è¨ˆå…¥å¸³ ==========
            df = self._set_accrual_flag(df, status_column)

            # ========== éšæ®µ 6: è¨­ç½®æœƒè¨ˆæ¬„ä½ ==========
            df = self._set_pr_accounting_fields(df, ref_account)

            # æ›´æ–°ä¸Šä¸‹æ–‡
            context.update_data(df)

            # ç”Ÿæˆçµ±è¨ˆè³‡è¨Š
            stats = self._generate_statistics(df, status_column)

            # è¨˜éŒ„çµ±è¨ˆæ‘˜è¦
            self._log_summary_statistics(stats, status_column)

            duration = time.time() - start_time

            self.logger.info("=" * 70)
            self.logger.info("âœ… PR ERM é‚è¼¯å®Œæˆ")
            self.logger.info(f"â±ï¸  è€—æ™‚ï¼š{duration:.2f} ç§’")
            self.logger.info(f"ğŸ“ˆ éœ€ä¼°åˆ—ï¼š{stats['accrual_count']:,} ç­†")
            self.logger.info(f"ğŸ“Š ç¸½è¨ˆï¼š{stats['total_count']:,} ç­†")
            self.logger.info("=" * 70)

            return StepResult(
                step_name=self.name,
                status=StepStatus.SUCCESS,
                data=df,
                message=f"PR ERM é‚è¼¯å·²æ‡‰ç”¨ï¼Œ{stats['accrual_count']:,} ç­†éœ€ä¼°åˆ—",
                duration=duration,
                metadata=stats
            )

        except Exception as e:
            self.logger.error(f"âŒ PR ERM é‚è¼¯è™•ç†å¤±æ•—: {str(e)}", exc_info=True)
            context.add_error(f"PR ERM é‚è¼¯å¤±æ•—: {str(e)}")
            duration = time.time() - start_time
            return StepResult(
                step_name=self.name,
                status=StepStatus.FAILED,
                error=e,
                duration=duration,
                message=str(e)
            )

    # ========== éšæ®µ 1: åŸºæœ¬è¨­ç½® ==========

    def _set_file_date(self, df: pd.DataFrame, processing_date: int) -> pd.DataFrame:
        """è¨­ç½®æª”æ¡ˆæ—¥æœŸ"""
        df['æª”æ¡ˆæ—¥æœŸ'] = processing_date
        self.logger.debug(f"âœ“ å·²è¨­ç½®æª”æ¡ˆæ—¥æœŸï¼š{processing_date}")
        return df

    def _get_status_column(self, df: pd.DataFrame) -> str:
        """
        ç²å–ç‹€æ…‹æ¬„ä½åç¨±

        PR æ‡‰è©²ä½¿ç”¨ 'PRç‹€æ…‹' æ¬„ä½
        """
        if 'PRç‹€æ…‹' in df.columns:
            return 'PRç‹€æ…‹'
        else:
            df['PRç‹€æ…‹'] = np.nan
            return 'PRç‹€æ…‹'

    # ========== éšæ®µ 3: æ‡‰ç”¨ç‹€æ…‹æ¢ä»¶ï¼ˆé…ç½®é©…å‹•ï¼‰==========

    def _apply_pr_status_conditions(self, df: pd.DataFrame,
                                    status_column: str,
                                    processing_date: int) -> pd.DataFrame:
        """
        æ‡‰ç”¨ PR ç‹€æ…‹åˆ¤æ–·æ¢ä»¶ï¼ˆé…ç½®é©…å‹•ï¼‰

        ç”± SPXConditionEngine å¾ [spx_pr_erm_status_rules] è®€å–è¦å‰‡ï¼Œ
        ä¾ priority é †åºåŸ·è¡Œ 8 å€‹ PR ç‹€æ…‹æ¢ä»¶ã€‚

        Args:
            df: PR DataFrame
            status_column: ç‹€æ…‹æ¬„ä½åç¨±
            processing_date: è™•ç†æ—¥æœŸï¼ˆYYYYMM æ ¼å¼ï¼‰

        Returns:
            pd.DataFrame: è¨­ç½®ç‹€æ…‹å¾Œçš„ DataFrame
        """
        engine_context: Dict[str, Any] = {
            'processing_date': processing_date,
            'prebuilt_masks': {},
        }

        self.logger.info("ğŸ”„ å¼•æ“é©…å‹•: åŸ·è¡Œ PR é…ç½®åŒ–æ¢ä»¶...")
        df, stats = self.engine.apply_rules(
            df, status_column, engine_context,
            processing_type='PR',
            update_no_status=True
        )

        # è¨˜éŒ„çµ±è¨ˆ
        total_hits = sum(stats.values())
        self.logger.info(
            f"âœ… PR å¼•æ“é©…å‹•å®Œæˆ: {len(stats)} æ¢è¦å‰‡, "
            f"å…±å‘½ä¸­ {total_hits:,} ç­†"
        )

        return df

    def _log_condition_result(self, condition_name: str, count: int):
        """
        è¨˜éŒ„æ¢ä»¶åˆ¤æ–·çµæœ

        Args:
            condition_name: æ¢ä»¶åç¨±
            count: ç¬¦åˆæ¢ä»¶çš„è¨˜éŒ„æ•¸
        """
        if count > 0:
            self.logger.info(f"  âœ“ [{condition_name:40s}]: {count:6,} ç­†")

    # ========== éšæ®µ 4: è™•ç†æ ¼å¼éŒ¯èª¤ ==========

    def _handle_format_errors(self, df: pd.DataFrame,
                              status_column: str) -> pd.DataFrame:
        """
        è™•ç†æ ¼å¼éŒ¯èª¤èˆ‡å…¶ä»–æœªåŒ¹é…è¨˜éŒ„

        åœ¨å¼•æ“è™•ç†å®Œæ‰€æœ‰é…ç½®æ¢ä»¶å¾Œï¼Œè™•ç†å‰©é¤˜çš„ï¼š
        1. æ ¼å¼éŒ¯èª¤ï¼ˆYMs of Item Description == '100001,100002'ï¼‰
        2. å…¶ä»–ï¼ˆæ‰€æœ‰æœªåŒ¹é…çš„è¨˜éŒ„ï¼‰

        Args:
            df: PR DataFrame
            status_column: ç‹€æ…‹æ¬„ä½åç¨±

        Returns:
            pd.DataFrame: è™•ç†å¾Œçš„ DataFrame
        """
        no_status = (
            df[status_column].isna()
            | (df[status_column] == 'nan')
            | (df[status_column] == '')
        )

        # æ ¼å¼éŒ¯èª¤
        format_error = df['YMs of Item Description'] == '100001,100002'
        mask_format_error = no_status & format_error
        df.loc[mask_format_error, status_column] = 'æ ¼å¼éŒ¯èª¤ï¼Œé€€å–®'

        error_count = mask_format_error.sum()
        if error_count > 0:
            self.logger.warning(f"âš ï¸  ç™¼ç¾ {error_count:,} ç­†æ ¼å¼éŒ¯èª¤")

        # å…¶ä»–ï¼ˆæ›´æ–° no_status å¾Œï¼‰
        no_status = (
            df[status_column].isna()
            | (df[status_column] == 'nan')
            | (df[status_column] == '')
        )
        df.loc[no_status, status_column] = 'å…¶ä»–'
        self._log_condition_result("å…¶ä»–", no_status.sum())

        return df
    
    # ========== éšæ®µ 5: è¨­ç½®æ˜¯å¦ä¼°è¨ˆå…¥å¸³ ==========
    
    def _set_accrual_flag(self, df: pd.DataFrame, status_column: str) -> pd.DataFrame:
        """
        æ ¹æ“š PRç‹€æ…‹ è¨­ç½®æ˜¯å¦ä¼°è¨ˆå…¥å¸³
        
        PR é‚è¼¯ï¼š
        - 'å·²å®Œæˆ'ï¼šéœ€è¦ä¼°åˆ—å…¥å¸³ï¼ˆYï¼‰
        - 'å·²å…¥å¸³'ï¼šå·²ç¶“å…¥å¸³ï¼Œä¸éœ€ä¼°åˆ—ï¼ˆNï¼‰
        - å…¶ä»–ç‹€æ…‹ï¼šä¸ä¼°åˆ—ï¼ˆNï¼‰
        
        Args:
            df: PR DataFrame
            status_column: ç‹€æ…‹æ¬„ä½åç¨±
            
        Returns:
            pd.DataFrame: è¨­ç½®ä¼°åˆ—æ¨™è¨˜å¾Œçš„ DataFrame
        """
        self.logger.info("âš™ï¸  è¨­ç½®ä¼°åˆ—æ¨™è¨˜...")
        
        # åˆå§‹åŒ–ç‚º 'N'
        df['æ˜¯å¦ä¼°è¨ˆå…¥å¸³'] = 'N'
        
        # éœ€è¦ä¼°åˆ—çš„ç‹€æ…‹
        accrual_statuses = ['å·²å®Œæˆ']
        mask_need_accrual = df[status_column].isin(accrual_statuses)
        
        df.loc[mask_need_accrual, 'æ˜¯å¦ä¼°è¨ˆå…¥å¸³'] = 'Y'
        
        accrual_count = mask_need_accrual.sum()
        non_accrual_count = (~mask_need_accrual).sum()
        
        self.logger.info(f"  â”œâ”€ éœ€ä¼°åˆ—ï¼ˆYï¼‰ï¼š{accrual_count:,} ç­†")
        self.logger.info(f"  â””â”€ ä¸ä¼°åˆ—ï¼ˆNï¼‰ï¼š{non_accrual_count:,} ç­†")
        
        return df
    
    # ========== éšæ®µ 6: è¨­ç½®æœƒè¨ˆæ¬„ä½ ==========
    
    def _set_pr_accounting_fields(self, df: pd.DataFrame,
                                  ref_account: pd.DataFrame) -> pd.DataFrame:
        """
        è¨­ç½® PR æœƒè¨ˆç›¸é—œæ¬„ä½ï¼ˆç°¡åŒ–ç‰ˆæœ¬ï¼‰
        
        èˆ‡ PO çš„å·®ç•°ï¼š
        - ä¸è™•ç†é ä»˜æ¬¾ï¼ˆç„¡ Entry Prepay Amountï¼‰
        - ä¸è¨­ç½® Liabilityï¼ˆç„¡è² å‚µç§‘ç›®ï¼‰
        - ä¸è¨ˆç®— Accr. Amountï¼ˆç›´æ¥ä½¿ç”¨ Entry Amountï¼‰
        
        è¨­ç½®çš„æ¬„ä½ï¼š
        1. Account code (å¾ GL#)
        2. Account Name (å¾åƒè€ƒè³‡æ–™)
        3. Product code (å¾ Product Code)
        4. Region_c (å›ºå®š "TW")
        5. Dep. (éƒ¨é–€ä»£ç¢¼)
        6. Currency_c (å¾ Currency)
        
        Args:
            df: PR DataFrame
            ref_account: ç§‘ç›®æ˜ å°„åƒè€ƒè³‡æ–™
            
        Returns:
            pd.DataFrame: è¨­ç½®æœƒè¨ˆæ¬„ä½å¾Œçš„ DataFrame
        """
        self.logger.info("ğŸ’¼ è¨­ç½®æœƒè¨ˆæ¬„ä½...")
        
        need_accrual = df['æ˜¯å¦ä¼°è¨ˆå…¥å¸³'] == 'Y'
        accrual_count = need_accrual.sum()
        
        if accrual_count == 0:
            self.logger.info("  â””â”€ ç„¡éœ€ä¼°åˆ—è¨˜éŒ„ï¼Œè·³éæœƒè¨ˆæ¬„ä½è¨­ç½®")
            return df
        
        self.logger.info(f"  è™•ç† {accrual_count:,} ç­†éœ€ä¼°åˆ—è¨˜éŒ„...")
        
        # 1. Account code
        df.loc[need_accrual, 'Account code'] = df.loc[need_accrual, 'GL#']
        self.logger.debug("  âœ“ Account code è¨­ç½®å®Œæˆ")
        
        # 2. Account Nameï¼ˆé€šé mergeï¼‰
        df = self._set_account_name(df, ref_account, need_accrual)
        self.logger.debug("  âœ“ Account Name è¨­ç½®å®Œæˆ")
        
        # 3. Product code
        df.loc[need_accrual, 'Product code'] = df.loc[need_accrual, 'Product Code']
        self.logger.debug("  âœ“ Product code è¨­ç½®å®Œæˆ")
        
        # 4. Region_cï¼ˆSPX å›ºå®šå€¼ï¼‰
        df.loc[need_accrual, 'Region_c'] = "TW"
        self.logger.debug("  âœ“ Region_c è¨­ç½®å®Œæˆ")
        
        # 5. Dep.ï¼ˆéƒ¨é–€ä»£ç¢¼ï¼‰
        df = self._set_department(df, need_accrual)
        self.logger.debug("  âœ“ Dep. è¨­ç½®å®Œæˆ")
        
        # 6. Currency_c
        df.loc[need_accrual, 'Currency_c'] = df.loc[need_accrual, 'Currency']
        self.logger.debug("  âœ“ Currency_c è¨­ç½®å®Œæˆ")
        
        # 7. Accr. Amountï¼ˆPR ç›´æ¥ä½¿ç”¨ Entry Amountï¼Œä¸éœ€è¦è¨ˆç®—ï¼‰
        df.loc[need_accrual, 'Accr. Amount'] = df.loc[need_accrual, 'Entry Amount'].astype('Float64')
        self.logger.debug("  âœ“ Accr. Amount è¨­ç½®å®Œæˆ")
        
        self.logger.info("âœ“ æœƒè¨ˆæ¬„ä½è¨­ç½®å®Œæˆ")
        
        return df
    
    def _set_account_name(self, df: pd.DataFrame, ref_account: pd.DataFrame,
                          mask: pd.Series) -> pd.DataFrame:
        """
        è¨­ç½®æœƒè¨ˆç§‘ç›®åç¨±
        
        å¾åƒè€ƒè³‡æ–™ä¸­æŸ¥æ‰¾ç§‘ç›®åç¨±
        
        Args:
            df: PR DataFrame
            ref_account: ç§‘ç›®æ˜ å°„åƒè€ƒè³‡æ–™
            mask: éœ€è¦è¨­ç½®çš„è¨˜éŒ„é®ç½©
            
        Returns:
            pd.DataFrame: è¨­ç½®ç§‘ç›®åç¨±å¾Œçš„ DataFrame
        """
        if ref_account.empty:
            self.logger.warning("âš ï¸  åƒè€ƒç§‘ç›®è³‡æ–™ç‚ºç©ºï¼Œç„¡æ³•è¨­ç½® Account Name")
            return df
        
        # ä½¿ç”¨ merge å¾åƒè€ƒè³‡æ–™å–å¾—ç§‘ç›®åç¨±
        merged = pd.merge(
            df, 
            ref_account[['Account', 'Account Desc']],
            how='left',
            left_on='Account code',
            right_on='Account'
        )
        
        df['Account Name'] = merged['Account Desc']
        
        # æª¢æŸ¥éºæ¼
        missing_count = df.loc[mask, 'Account Name'].isna().sum()
        if missing_count > 0:
            self.logger.warning(f"âš ï¸  {missing_count:,} ç­†è¨˜éŒ„ç„¡æ³•æ‰¾åˆ°å°æ‡‰çš„ Account Name")
        
        return df
    
    def _set_department(self, df: pd.DataFrame, mask: pd.Series) -> pd.DataFrame:
        """
        è¨­ç½®éƒ¨é–€ä»£ç¢¼
        
        è¦å‰‡ï¼š
        - å¦‚æœç§‘ç›®åœ¨ dept_accounts æ¸…å–®ä¸­ï¼Œå– Department å‰ 3 ç¢¼
        - å¦å‰‡è¨­ç‚º '000'
        
        Args:
            df: PR DataFrame
            mask: éœ€è¦è¨­ç½®çš„è¨˜éŒ„é®ç½©
            
        Returns:
            pd.DataFrame: è¨­ç½®éƒ¨é–€ä»£ç¢¼å¾Œçš„ DataFrame
        """
        isin_dept = df['Account code'].astype('string').isin(
            [str(x) for x in self.dept_accounts]
        )
        
        # åœ¨ dept_accounts ä¸­çš„ç§‘ç›®
        dept_mask = mask & isin_dept
        if dept_mask.any():
            df.loc[dept_mask, 'Dep.'] = df.loc[dept_mask, 'Department'].str[:3]
        
        # ä¸åœ¨ dept_accounts ä¸­çš„ç§‘ç›®
        non_dept_mask = mask & ~isin_dept
        if non_dept_mask.any():
            df.loc[non_dept_mask, 'Dep.'] = '000'
        
        return df
    
    # ========== è¼”åŠ©æ–¹æ³• ==========
    
    def _generate_statistics(self, df: pd.DataFrame, status_column: str) -> Dict[str, Any]:
        """
        ç”Ÿæˆçµ±è¨ˆè³‡è¨Š
        
        Args:
            df: PR DataFrame
            status_column: ç‹€æ…‹æ¬„ä½åç¨±
            
        Returns:
            Dict: åŒ…å«çµ±è¨ˆè³‡è¨Šçš„å­—å…¸
        """
        total_count = len(df)
        accrual_count = (df['æ˜¯å¦ä¼°è¨ˆå…¥å¸³'] == 'Y').sum()
        
        stats = {
            'total_count': total_count,
            'accrual_count': accrual_count,
            'accrual_percentage': round((accrual_count / total_count * 100), 2) if total_count > 0 else 0,
            'status_distribution': {}
        }
        
        # ç‹€æ…‹åˆ†å¸ƒçµ±è¨ˆ
        if status_column in df.columns:
            status_counts = df[status_column].value_counts().to_dict()
            stats['status_distribution'] = {
                str(k): int(v) for k, v in status_counts.items()
            }
            
            # Top 5 ç‹€æ…‹
            top_5 = dict(sorted(status_counts.items(), key=lambda x: x[1], reverse=True)[:5])
            stats['top_5_statuses'] = {str(k): int(v) for k, v in top_5.items()}
        
        return stats
    
    def _log_summary_statistics(self, stats: Dict[str, Any], status_column: str):
        """
        è¨˜éŒ„çµ±è¨ˆæ‘˜è¦åˆ° logger
        
        Args:
            stats: çµ±è¨ˆè³‡è¨Šå­—å…¸
            status_column: ç‹€æ…‹æ¬„ä½åç¨±
        """
        self.logger.info("")
        self.logger.info("=" * 70)
        self.logger.info(f"ğŸ“Š {status_column} è™•ç†æ‘˜è¦")
        self.logger.info("=" * 70)
        
        # ç¸½è¦½çµ±è¨ˆ
        self.logger.info(f"ğŸ“ˆ ç¸½è¨˜éŒ„æ•¸ï¼š{stats['total_count']:,}")
        self.logger.info(f"   â”œâ”€ éœ€ä¼°åˆ—ï¼š{stats['accrual_count']:,} "
                         f"({stats['accrual_percentage']:.1f}%)")
        self.logger.info(f"   â””â”€ ä¸ä¼°åˆ—ï¼š{stats['total_count'] - stats['accrual_count']:,}")
        
        # Top 5 ç‹€æ…‹
        if 'top_5_statuses' in stats:
            self.logger.info("")
            self.logger.info("ğŸ† Top 5 ç‹€æ…‹åˆ†å¸ƒï¼š")
            for i, (status, count) in enumerate(stats['top_5_statuses'].items(), 1):
                percentage = (count / stats['total_count'] * 100)
                self.logger.info(f"   {i}. {status:40s}: {count:6,} ({percentage:5.1f}%)")
        
        self.logger.info("=" * 70)
    
    # ========== é©—è­‰æ–¹æ³• ==========
    
    async def validate_input(self, context: ProcessingContext) -> bool:
        """
        é©—è­‰è¼¸å…¥æ•¸æ“š
        
        æª¢æŸ¥ï¼š
        1. DataFrame ä¸ç‚ºç©º
        2. å¿…è¦æ¬„ä½å­˜åœ¨
        3. åƒè€ƒæ•¸æ“šå¯ç”¨
        4. è™•ç†æ—¥æœŸå­˜åœ¨
        
        Args:
            context: è™•ç†ä¸Šä¸‹æ–‡
            
        Returns:
            bool: é©—è­‰æ˜¯å¦é€šé
        """
        df = context.data
        
        # æª¢æŸ¥ DataFrame
        if df is None or df.empty:
            self.logger.error("âŒ è¼¸å…¥æ•¸æ“šç‚ºç©º")
            context.add_error("è¼¸å…¥æ•¸æ“šç‚ºç©º")
            return False
        
        # æª¢æŸ¥å¿…è¦æ¬„ä½
        required_columns = [
            'GL#',
            'Expected Received Month_è½‰æ›æ ¼å¼',
            'YMs of Item Description',
            'Item Description',
            'Remarked by Procurement',
            'Remarked by ä¸Šæœˆ FN',
            'Currency',
            'Product Code',
            'Requester',
            'PR Supplier',
            'Entry Amount',
            'Department'
        ]
        
        missing = [col for col in required_columns if col not in df.columns]
        
        if missing:
            self.logger.error(f"âŒ ç¼ºå°‘å¿…è¦æ¬„ä½: {missing}")
            context.add_error(f"ç¼ºå°‘å¿…è¦æ¬„ä½: {missing}")
            return False
        
        # æª¢æŸ¥åƒè€ƒæ•¸æ“š
        ref_account = context.get_auxiliary_data('reference_account')
        
        if ref_account is None:
            self.logger.error("âŒ ç¼ºå°‘åƒè€ƒæ•¸æ“šï¼šç§‘ç›®æ˜ å°„")
            context.add_error("ç¼ºå°‘åƒè€ƒæ•¸æ“šï¼šç§‘ç›®æ˜ å°„")
            return False
        
        # æª¢æŸ¥è™•ç†æ—¥æœŸ
        processing_date = context.get_variable('processing_date')
        if processing_date is None:
            self.logger.error("âŒ ç¼ºå°‘è™•ç†æ—¥æœŸ")
            context.add_error("ç¼ºå°‘è™•ç†æ—¥æœŸ")
            return False
        
        self.logger.info("âœ… è¼¸å…¥é©—è­‰é€šé")
        return True
    
    async def rollback(self, context: ProcessingContext, error: Exception):
        """
        å›æ»¾æ“ä½œ
        
        PR ERM æ­¥é©Ÿé€šå¸¸ä¸éœ€è¦ç‰¹æ®Šå›æ»¾æ“ä½œ
        
        Args:
            context: è™•ç†ä¸Šä¸‹æ–‡
            error: ç™¼ç”Ÿçš„éŒ¯èª¤
        """
        self.logger.warning(f"âš ï¸  å›æ»¾ PR ERM é‚è¼¯ï¼š{str(error)}")
        # å¦‚æœ‰éœ€è¦ï¼Œå¯åœ¨æ­¤è™•æ·»åŠ æ¸…ç†é‚è¼¯

