"""
SPX PR ERM é‚è¼¯åˆ¤æ–·èˆ‡è©•ä¼°
å°ˆé–€è™•ç† PR (Purchase Request) çš„ç‹€æ…‹è©•ä¼°å’Œæœƒè¨ˆæ¬„ä½è¨­ç½®

èˆ‡ PO çš„æ ¸å¿ƒå·®ç•°ï¼š
1. ä¸åˆ¤æ–·æ”¶è²¨ç‹€æ…‹ï¼ˆç„¡ Received Quantity ç›¸é—œé‚è¼¯ï¼‰
2. ä¸åˆ¤æ–·å…¥è³¬ç‹€æ…‹ï¼ˆç„¡ Billed Amount ç›¸é—œé‚è¼¯ï¼‰
3. åŸºæ–¼æ¥­å‹™é¡å‹ï¼ˆç§Ÿé‡‘/Intermediary/è³‡ç”¢ï¼‰é€²è¡Œåˆ¤æ–·
4. ç°¡åŒ–çš„æœƒè¨ˆæ¬„ä½è¨­ç½®ï¼ˆä¸è™•ç†é ä»˜æ¬¾å’Œè² å‚µç§‘ç›®ï¼‰

ä½œè€…: Claude
å‰µå»ºæ—¥æœŸ: 2025-10-27
"""

import time
import re
from dataclasses import dataclass
from typing import Optional, Dict, List, Tuple, Any, Union
from datetime import datetime
import pandas as pd
import numpy as np

from accrual_bot.core.pipeline.base import PipelineStep, StepResult, StepStatus
from accrual_bot.core.pipeline.context import ProcessingContext
from accrual_bot.utils.config import config_manager
from accrual_bot.core.pipeline.steps.common import StepMetadataBuilder


@dataclass
class PRERMConditions:
    """
    PR ERM åˆ¤æ–·æ¢ä»¶é›†åˆ
    
    ç›¸æ¯” PO çš„ ERMConditionsï¼Œç§»é™¤äº†æ”¶è²¨å’Œå…¥è³¬ç›¸é—œæ¢ä»¶
    
    å±¬æ€§ï¼š
        åŸºç¤æ¢ä»¶ï¼š
            no_status: PRç‹€æ…‹ç‚ºç©º
            in_date_range: ERM åœ¨æ‘˜è¦æœˆä»½ç¯„åœå…§
            erm_before_or_equal_file_date: ERM å°æ–¼ç­‰æ–¼æª”æ¡ˆæ—¥æœŸ
            erm_after_file_date: ERM å¤§æ–¼æª”æ¡ˆæ—¥æœŸ
        
        å‚™è¨»æ¢ä»¶ï¼š
            procurement_completed_or_rent
            fn_completed_or_posted: å‰æœŸ FN å‚™è¨»å«å·²å®Œæˆæˆ–å·²å…¥å¸³
            pr_not_incomplete: PR å‚™è¨»ä¸å«æœªå®Œæˆ
            procurement_incomplete: æ¡è³¼å‚™è¨»æœªå®Œæˆ
        
        FA æ¢ä»¶ï¼š
            is_fa: æ˜¯å¦ç‚º FA ç§‘ç›®
        
        éŒ¯èª¤æ¢ä»¶ï¼š
            procurement_not_error: Procurement å‚™è¨»ä¸æ˜¯éŒ¯èª¤
            out_of_date_range: æ‘˜è¦æœˆä»½è¶…å‡º ERM ç¯„åœ
            format_error: æ‘˜è¦æœˆä»½æ ¼å¼éŒ¯èª¤
        
        PR ç‰¹æœ‰æ¢ä»¶ï¼š
            is_rent_related: ç§Ÿé‡‘ç›¸é—œï¼ˆç”³è«‹äºº+ç§‘ç›®+é—œéµå­—ï¼‰
            is_intermediary: Intermediary ç›¸é—œ
            is_asset_related: è³‡ç”¢ç›¸é—œï¼ˆæ™ºå–æ«ƒ/ç¹³è²»æ©Ÿï¼‰
    """
    # åŸºç¤æ¢ä»¶çµ„ä»¶
    no_status: pd.Series
    in_date_range: pd.Series
    erm_before_or_equal_file_date: pd.Series
    erm_after_file_date: pd.Series
    
    # å‚™è¨»æ¢ä»¶
    procurement_completed_or_rent: pd.Series
    fn_completed_or_posted: pd.Series
    pr_not_incomplete: pd.Series
    procurement_incomplete: pd.Series
    
    # FA æ¢ä»¶
    is_fa: pd.Series
    
    # éŒ¯èª¤æ¢ä»¶
    procurement_not_error: pd.Series
    out_of_date_range: pd.Series
    format_error: pd.Series
    
    # PR ç‰¹æœ‰æ¢ä»¶
    is_rent_related: pd.Series
    is_intermediary: pd.Series
    is_asset_related: pd.Series


class SPXPRERMLogicStep(PipelineStep):
    """
    SPX PR ERM é‚è¼¯æ­¥é©Ÿ - PR å°ˆç”¨ç‰ˆæœ¬
    
    åŠŸèƒ½ï¼š
    1. è¨­ç½®æª”æ¡ˆæ—¥æœŸ
    2. åˆ¤æ–· 5-7 ç¨® PR ç‹€æ…‹
    3. æ ¹æ“šç‹€æ…‹è¨­ç½®æ˜¯å¦ä¼°è¨ˆå…¥å¸³
    4. è¨­ç½®æœƒè¨ˆç›¸é—œæ¬„ä½ï¼ˆç°¡åŒ–ç‰ˆæœ¬ï¼‰
    
    æ¥­å‹™è¦å‰‡ï¼š
    - PR é‚è¼¯ï¼šåŸºæ–¼ ERMã€æ‘˜è¦æœˆä»½ã€æ¥­å‹™é¡å‹åˆ¤æ–·ç‹€æ…‹
    - å®Œæˆç‹€æ…‹çš„é …ç›®éœ€è¦ä¼°åˆ—å…¥å¸³
    - æœªå®Œæˆç‹€æ…‹ä¸€å¾‹ä¸ä¼°åˆ—ï¼ˆæ˜¯å¦ä¼°è¨ˆå…¥å¸³ = Nï¼‰
    
    èˆ‡ PO çš„ä¸»è¦å·®ç•°ï¼š
    - ç§»é™¤æ”¶è²¨ç›¸é—œåˆ¤æ–·ï¼ˆç„¡ Received Quantityï¼‰
    - ç§»é™¤å…¥è³¬ç›¸é—œåˆ¤æ–·ï¼ˆç„¡ Billed Amountï¼‰
    - ç§»é™¤é ä»˜æ¬¾è™•ç†
    - ç§»é™¤è² å‚µç§‘ç›®è¨­ç½®
    - åŸºæ–¼æ¥­å‹™é¡å‹ï¼ˆç§Ÿé‡‘/Intermediary/è³‡ç”¢ï¼‰é€²è¡Œåˆ¤æ–·
    
    è¼¸å…¥ï¼š
    - DataFrame with required columns for PR
    - Reference data (ç§‘ç›®æ˜ å°„)
    - Processing date
    
    è¼¸å‡ºï¼š
    - DataFrame with PRç‹€æ…‹, æ˜¯å¦ä¼°è¨ˆå…¥å¸³, and simplified accounting fields
    """
    
    def __init__(self, name: str = "SPX_PR_ERM_Logic", **kwargs):
        super().__init__(
            name=name,
            description="Apply SPX PR ERM logic with simplified status conditions",
            **kwargs
        )
        
        # å¾é…ç½®è®€å–é—œéµåƒæ•¸
        self.fa_accounts = config_manager.get_list('SPX', 'fa_accounts', ['199999'])
        self.dept_accounts = config_manager.get_list('SPX', 'dept_accounts', [])
        
        # PR ç‰¹æœ‰é…ç½®
        self.ops_for_rent = config_manager.get('SPX', 'ops_for_rent', '')
        self.ops_for_intermediary = config_manager.get('SPX', 'ops_for_intermediary', '')
        self.account_rent = config_manager.get('SPX', 'account_rent', '')
        
        self.kiosk_suppliers = config_manager.get_list('SPX', 'kiosk_suppliers', [])
        self.locker_suppliers = config_manager.get_list('SPX', 'locker_suppliers', [])
        
        self.logger.info(f"Initialized {name} for PR processing")
        self.logger.info(f"  - FA accounts: {self.fa_accounts}")
        self.logger.info(f"  - Rent ops: {self.ops_for_rent}")
        self.logger.info(f"  - Intermediary ops: {self.ops_for_intermediary}")
    
    async def execute(self, context: ProcessingContext) -> StepResult:
        """åŸ·è¡Œ PR ERM é‚è¼¯"""
        start_time = time.time()
        
        try:
            df = context.data.copy()
            processing_date = context.get_variable('processing_date')
            
            # ç²å–åƒè€ƒæ•¸æ“š
            ref_account = context.get_auxiliary_data('reference_account')
            
            if ref_account is None:
                raise ValueError("ç¼ºå°‘åƒè€ƒæ•¸æ“šï¼šç§‘ç›®æ˜ å°„")
            
            self.logger.info("=" * 70)
            self.logger.info("ğŸš€ é–‹å§‹ PR ERM é‚è¼¯è™•ç†")
            self.logger.info(f"ğŸ“… è™•ç†æ—¥æœŸï¼š{processing_date}")
            self.logger.info(f"ğŸ“Š è¼¸å…¥è¨˜éŒ„æ•¸ï¼š{len(df):,}")
            self.logger.info("=" * 70)
            
            # ========== éšæ®µ 1: è¨­ç½®åŸºæœ¬æ¬„ä½ ==========
            df = self._set_file_date(df, processing_date)
            
            # ========== éšæ®µ 2: æ§‹å»ºåˆ¤æ–·æ¢ä»¶ ==========
            status_column = self._get_status_column(df)
            self.logger.info(f"ğŸ“‹ ç‹€æ…‹æ¬„ä½ï¼š{status_column}")
            
            conditions = self._build_pr_conditions(df, processing_date, status_column)
            
            # ========== éšæ®µ 3: æ‡‰ç”¨ PR ç‹€æ…‹æ¢ä»¶ ==========
            df = self._apply_pr_status_conditions(df, conditions, status_column)
            
            # ========== éšæ®µ 4: è™•ç†æ ¼å¼éŒ¯èª¤ ==========
            df = self._handle_format_errors(df, conditions, status_column)
            
            # ========== éšæ®µ 5: è¨­ç½®æ˜¯å¦ä¼°è¨ˆå…¥å¸³ ==========
            df = self._set_accrual_flag(df, status_column)
            
            # ========== éšæ®µ 6: è¨­ç½®æœƒè¨ˆæ¬„ä½ ==========
            df = self._set_pr_accounting_fields(df, ref_account)
            
            # æ›´æ–°ä¸Šä¸‹æ–‡
            context.update_data(df)
            
            # ç”Ÿæˆçµ±è¨ˆè³‡è¨Š
            stats = self._generate_statistics(df, status_column)
            
            # è¨˜éŒ„çµ±è¨ˆæ‘˜è¦
            self._log_summary_statistics(stats, status_column)
            
            duration = time.time() - start_time
            
            self.logger.info("=" * 70)
            self.logger.info("âœ… PR ERM é‚è¼¯å®Œæˆ")
            self.logger.info(f"â±ï¸  è€—æ™‚ï¼š{duration:.2f} ç§’")
            self.logger.info(f"ğŸ“ˆ éœ€ä¼°åˆ—ï¼š{stats['accrual_count']:,} ç­†")
            self.logger.info(f"ğŸ“Š ç¸½è¨ˆï¼š{stats['total_count']:,} ç­†")
            self.logger.info("=" * 70)
            
            return StepResult(
                step_name=self.name,
                status=StepStatus.SUCCESS,
                data=df,
                message=f"PR ERM é‚è¼¯å·²æ‡‰ç”¨ï¼Œ{stats['accrual_count']:,} ç­†éœ€ä¼°åˆ—",
                duration=duration,
                metadata=stats
            )
            
        except Exception as e:
            self.logger.error(f"âŒ PR ERM é‚è¼¯è™•ç†å¤±æ•—: {str(e)}", exc_info=True)
            context.add_error(f"PR ERM é‚è¼¯å¤±æ•—: {str(e)}")
            duration = time.time() - start_time
            return StepResult(
                step_name=self.name,
                status=StepStatus.FAILED,
                error=e,
                duration=duration,
                message=str(e)
            )
    
    # ========== éšæ®µ 1: åŸºæœ¬è¨­ç½® ==========
    
    def _set_file_date(self, df: pd.DataFrame, processing_date: int) -> pd.DataFrame:
        """è¨­ç½®æª”æ¡ˆæ—¥æœŸ"""
        df['æª”æ¡ˆæ—¥æœŸ'] = processing_date
        self.logger.debug(f"âœ“ å·²è¨­ç½®æª”æ¡ˆæ—¥æœŸï¼š{processing_date}")
        return df
    
    def _get_status_column(self, df: pd.DataFrame) -> str:
        """
        ç²å–ç‹€æ…‹æ¬„ä½åç¨±
        
        PR æ‡‰è©²ä½¿ç”¨ 'PRç‹€æ…‹' æ¬„ä½
        """
        if 'PRç‹€æ…‹' in df.columns:
            return 'PRç‹€æ…‹'
        else:
            # å¦‚æœæ²’æœ‰ï¼Œå‰µå»ºä¸€å€‹
            df['PRç‹€æ…‹'] = np.nan
            return 'PRç‹€æ…‹'
    
    # ========== éšæ®µ 2: æ§‹å»ºæ¢ä»¶ ==========
    
    def _build_pr_conditions(self, df: pd.DataFrame, file_date: int,
                             status_column: str) -> PRERMConditions:
        """
        æ§‹å»ºæ‰€æœ‰ PR åˆ¤æ–·æ¢ä»¶
        
        èˆ‡ PO çš„å·®ç•°ï¼š
        - ç§»é™¤æ”¶è²¨ç›¸é—œæ¢ä»¶ï¼ˆquantity_matchedï¼‰
        - ç§»é™¤å…¥è³¬ç›¸é—œæ¢ä»¶ï¼ˆnot_billed, has_billing, fully_billed, has_unpaid_amountï¼‰
        - æ–°å¢æ¥­å‹™é¡å‹ç›¸é—œæ¢ä»¶ï¼ˆç§Ÿé‡‘ã€Intermediaryã€è³‡ç”¢ï¼‰
        
        Args:
            df: PR DataFrame
            file_date: è™•ç†æ—¥æœŸï¼ˆYYYYMM æ ¼å¼ï¼‰
            status_column: ç‹€æ…‹æ¬„ä½åç¨±
            
        Returns:
            PRERMConditions: PR å°ˆç”¨æ¢ä»¶é›†åˆ
        """
        self.logger.info("ğŸ”§ é–‹å§‹æ§‹å»º PR åˆ¤æ–·æ¢ä»¶...")
        
        # åŸºç¤ç‹€æ…‹æ¢ä»¶
        no_status = (df[status_column].isna()) | (df[status_column] == 'nan') | (df[status_column] == '')
        
        # æ—¥æœŸç¯„åœæ¢ä»¶
        ym_start = df['YMs of Item Description'].str[:6].astype('Int32')
        ym_end = df['YMs of Item Description'].str[7:].astype('Int32')
        erm = df['Expected Received Month_è½‰æ›æ ¼å¼']
        
        in_date_range = erm.between(ym_start, ym_end, inclusive='both')
        erm_before_or_equal_file_date = erm <= file_date
        erm_after_file_date = erm > file_date
        
        # å‚™è¨»æ¢ä»¶
        procurement_completed_or_rent = df['Remarked by Procurement'].str.contains(
            '(?i)å·²å®Œæˆ|rent', na=False
        )
        fn_completed_or_posted = df['Remarked by ä¸Šæœˆ FN'].astype('string').str.contains(
            '(?i)å·²å®Œæˆ|å·²å…¥å¸³', na=False
        )
        pr_not_incomplete = ~df['Remarked by ä¸Šæœˆ FN'].astype('string').str.contains(
            '(?i)æœªå®Œæˆ', na=False
        )
        procurement_incomplete = df['Remarked by Procurement'].str.contains(
            '(?i)æœªå®Œæˆ|å–æ¶ˆ', na=False
        )
        
        # FA æ¢ä»¶
        is_fa = df['GL#'].astype('string').isin([str(x) for x in self.fa_accounts])
        
        # éŒ¯èª¤æ¢ä»¶
        procurement_not_error = df['Remarked by Procurement'] != 'error'
        out_of_date_range = (
            (in_date_range == False) & 
            (df['YMs of Item Description'] != '100001,100002')
        )
        format_error = df['YMs of Item Description'] == '100001,100002'
        
        # ========== PR ç‰¹æœ‰æ¢ä»¶ ==========
        
        # ç§Ÿé‡‘ç›¸é—œæ¢ä»¶
        is_rent_ops = df['Requester'] == self.ops_for_rent
        is_rent_account = df['GL#'] == self.account_rent
        has_rent_keyword = df['Item Description'].str.contains('(?i)ç§Ÿé‡‘', na=False)
        is_rent_related = is_rent_ops & is_rent_account & has_rent_keyword
        
        # Intermediary ç›¸é—œæ¢ä»¶
        is_intermediary_ops = df['Requester'] == self.ops_for_intermediary
        has_intermediary_keyword = df['Item Description'].fillna('na').str.contains('(?i)intermediary', na=False)
        is_intermediary = is_intermediary_ops & has_intermediary_keyword
        
        # è³‡ç”¢ç›¸é—œæ¢ä»¶ï¼ˆæ™ºå–æ«ƒèˆ‡ç¹³è²»æ©Ÿï¼‰
        asset_suppliers = self.kiosk_suppliers + self.locker_suppliers
        is_asset_related = df['PR Supplier'].isin(asset_suppliers)
        
        # è¨˜éŒ„æ¢ä»¶çµ±è¨ˆ
        self.logger.debug(f"  â”œâ”€ ç„¡ç‹€æ…‹è¨˜éŒ„ï¼š{no_status.sum():,}")
        self.logger.debug(f"  â”œâ”€ ERM åœ¨ç¯„åœå…§ï¼š{in_date_range.sum():,}")
        self.logger.debug(f"  â”œâ”€ ERM <= æª”æ¡ˆæ—¥æœŸï¼š{erm_before_or_equal_file_date.sum():,}")
        self.logger.debug(f"  â”œâ”€ ERM > æª”æ¡ˆæ—¥æœŸï¼š{erm_after_file_date.sum():,}")
        self.logger.debug(f"  â”œâ”€ ç§Ÿé‡‘ç›¸é—œï¼š{is_rent_related.sum():,}")
        self.logger.debug(f"  â”œâ”€ Intermediaryï¼š{is_intermediary.sum():,}")
        self.logger.debug(f"  â””â”€ è³‡ç”¢ç›¸é—œï¼š{is_asset_related.sum():,}")
        
        return PRERMConditions(
            no_status=no_status,
            in_date_range=in_date_range,
            erm_before_or_equal_file_date=erm_before_or_equal_file_date,
            erm_after_file_date=erm_after_file_date,
            procurement_completed_or_rent=procurement_completed_or_rent,
            fn_completed_or_posted=fn_completed_or_posted,
            procurement_not_error=procurement_not_error,
            pr_not_incomplete=pr_not_incomplete,
            procurement_incomplete=procurement_incomplete,
            is_fa=is_fa,
            out_of_date_range=out_of_date_range,
            format_error=format_error,
            is_rent_related=is_rent_related,
            is_intermediary=is_intermediary,
            is_asset_related=is_asset_related
        )
    
    # ========== éšæ®µ 3: æ‡‰ç”¨ç‹€æ…‹æ¢ä»¶ ==========
    
    def _apply_pr_status_conditions(self, df: pd.DataFrame, 
                                    cond: PRERMConditions,
                                    status_column: str) -> pd.DataFrame:
        """
        æ‡‰ç”¨ PR ç‹€æ…‹åˆ¤æ–·æ¢ä»¶
        
        PR ç‹€æ…‹æ¢ä»¶ï¼ˆå…± 7 å€‹ï¼‰ï¼š
        1. å·²å…¥å¸³ï¼ˆå‰æœŸ FN æ˜ç¢ºæ¨™è¨»ï¼‰
        2. å·²å®Œæˆï¼ˆERM åœ¨å°æ–¼ç­‰æ–¼ç•¶æœŸä¸”åœ¨æ‘˜è¦å€é–“å…§ï¼Œæœ‰æ¡è³¼æˆ–æœƒè¨ˆå‚™è¨»ï¼‰
        2-1. å·²å®Œæˆï¼ˆERM åœ¨å°æ–¼ç­‰æ–¼ç•¶æœŸä¸”åœ¨æ‘˜è¦å€é–“å…§ï¼Œæ²’æœ‰æ¡è³¼æˆ–æœƒè¨ˆå‚™è¨»ï¼‰
        3. æœªå®Œæˆï¼ˆERM > æª”æ¡ˆæ—¥æœŸï¼‰
        4. ç¯„åœéŒ¯èª¤_ç§Ÿé‡‘
        5. ç¯„åœéŒ¯èª¤_è–ªè³‡
        6. ç¯„åœéŒ¯èª¤ï¼ˆä¸€èˆ¬ï¼‰
        7. è³‡ç”¢é¡ç‰¹æ®Šè™•ç†
        
        æ¢ä»¶å„ªå…ˆé †åºå¾ä¸Šåˆ°ä¸‹ï¼Œç¬¦åˆçš„æ¢ä»¶æœƒè¢«å„ªå…ˆè¨­ç½®
        
        Args:
            df: PR DataFrame
            cond: PR æ¢ä»¶é›†åˆ
            status_column: ç‹€æ…‹æ¬„ä½åç¨±
            
        Returns:
            pd.DataFrame: è¨­ç½®ç‹€æ…‹å¾Œçš„ DataFrame
        """
        self.logger.info("ğŸ·ï¸  é–‹å§‹æ‡‰ç”¨ PR ç‹€æ…‹æ¢ä»¶...")
        
        # === æ¢ä»¶ 1: å·²å…¥å¸³ï¼ˆå‰æœŸ FN æ˜ç¢ºæ¨™è¨»ï¼‰===
        condition_1 = df['Remarked by ä¸Šæœˆ FN'].astype('string').str.contains('(?i)å·²å…¥å¸³', na=False)
        df.loc[condition_1, status_column] = 'å·²å…¥å¸³'
        self._log_condition_result("å·²å…¥å¸³ï¼ˆå‰æœŸ FN æ˜ç¢ºæ¨™è¨»ï¼‰", condition_1.sum())
        
        # ğŸ”´ æ›´æ–° no_status
        cond.no_status = (df[status_column].isna()) | (df[status_column] == 'nan') | (df[status_column] == '')
        
        # === æ¢ä»¶ 2: å·²å®Œæˆ ===
        # ERM åœ¨ç¯„åœå…§ & ERM <= æª”æ¡ˆæ—¥æœŸ & æ¡è³¼å‚™è¨»ç‚ºå·²å®Œæˆæˆ–Rentç›¸é—œ | å‰æœŸ FN å·²å®Œæˆæˆ–å·²å…¥å¸³
        condition_2 = (
            (cond.procurement_completed_or_rent | cond.fn_completed_or_posted) &
            cond.pr_not_incomplete &
            cond.no_status &
            cond.in_date_range &
            cond.erm_before_or_equal_file_date &
            cond.procurement_not_error
        )
        df.loc[condition_2, status_column] = 'å·²å®Œæˆ'
        self._log_condition_result("å·²å®Œæˆ", condition_2.sum())
        
        # ğŸ”´ æ›´æ–° no_status
        cond.no_status = (df[status_column].isna()) | (df[status_column] == 'nan') | (df[status_column] == '')

        # === æ¢ä»¶ 2-1: å·²å®Œæˆ ===
        # ERM åœ¨ç¯„åœå…§ & ERM <= æª”æ¡ˆæ—¥æœŸ & æ²’æœ‰æ¡è³¼æˆ–æœƒè¨ˆå‚™è¨»
        condition_2 = (
            ~cond.procurement_incomplete &
            cond.pr_not_incomplete &
            cond.no_status &
            cond.in_date_range &
            cond.erm_before_or_equal_file_date &
            cond.procurement_not_error
        )
        df.loc[condition_2, status_column] = 'å·²å®Œæˆ'
        self._log_condition_result("å·²å®Œæˆ", condition_2.sum())
        
        # ğŸ”´ æ›´æ–° no_status
        cond.no_status = (df[status_column].isna()) | (df[status_column] == 'nan') | (df[status_column] == '')
        
        # === æ¢ä»¶ 3: æœªå®Œæˆ ===
        # ERM åœ¨ç¯„åœå…§ & ERM > æª”æ¡ˆæ—¥æœŸ
        condition_3 = (
            cond.procurement_not_error &
            cond.no_status &
            cond.in_date_range &
            cond.erm_after_file_date
        )
        df.loc[condition_3, status_column] = 'æœªå®Œæˆ'
        self._log_condition_result("æœªå®Œæˆ", condition_3.sum())
        
        # ğŸ”´ æ›´æ–° no_status
        cond.no_status = (df[status_column].isna()) | (df[status_column] == 'nan') | (df[status_column] == '')
        
        # === æ¢ä»¶ 4: ç¯„åœéŒ¯èª¤_ç§Ÿé‡‘ ===
        condition_4 = (
            cond.procurement_not_error &
            cond.no_status &
            cond.out_of_date_range &
            cond.is_rent_related
        )
        df.loc[condition_4, status_column] = 'error(Description Period is out of ERM)_ç§Ÿé‡‘'
        self._log_condition_result("ç¯„åœéŒ¯èª¤_ç§Ÿé‡‘", condition_4.sum())
        
        # ğŸ”´ æ›´æ–° no_status
        cond.no_status = (df[status_column].isna()) | (df[status_column] == 'nan') | (df[status_column] == '')
        
        # === æ¢ä»¶ 5: ç¯„åœéŒ¯èª¤_è–ªè³‡ ===
        condition_5 = (
            cond.procurement_not_error &
            cond.no_status &
            cond.out_of_date_range &
            (df['Item Description'].str.contains('(?i)æ´¾é£|Salary|Agency Fee', na=False))
        )
        df.loc[condition_5, status_column] = 'error(Description Period is out of ERM)_è–ªè³‡'
        self._log_condition_result("ç¯„åœéŒ¯èª¤_è–ªè³‡", condition_5.sum())
        
        # ğŸ”´ æ›´æ–° no_status
        cond.no_status = (df[status_column].isna()) | (df[status_column] == 'nan') | (df[status_column] == '')
        
        # === æ¢ä»¶ 6: ç¯„åœéŒ¯èª¤ï¼ˆä¸€èˆ¬ï¼‰===
        condition_6 = (
            cond.procurement_not_error &
            cond.no_status &
            cond.out_of_date_range
        )
        df.loc[condition_6, status_column] = 'error(Description Period is out of ERM)'
        self._log_condition_result("ç¯„åœéŒ¯èª¤ï¼ˆä¸€èˆ¬ï¼‰", condition_6.sum())
        
        # ğŸ”´ æ›´æ–° no_status
        cond.no_status = (df[status_column].isna()) | (df[status_column] == 'nan') | (df[status_column] == '')
        
        # === æ¢ä»¶ 7: è³‡ç”¢é¡ç‰¹æ®Šè™•ç† ===
        # æ™ºå–æ«ƒèˆ‡ç¹³è²»æ©Ÿä¸é€²è¡Œä¸€èˆ¬çš„ ERM åˆ¤æ–·
        # é€™å€‹æ¢ä»¶æ‡‰è©²åœ¨æœ€å¾Œï¼Œå› ç‚ºå®ƒä¸è€ƒæ…® ERM
        condition_7 = (
            cond.no_status &
            cond.is_asset_related
        )
        df.loc[condition_7, status_column] = 'è³‡ç”¢é¡_å¾…ç¢ºèª'
        self._log_condition_result("è³‡ç”¢é¡_å¾…ç¢ºèª", condition_7.sum())
        
        self.logger.info("âœ“ PR ç‹€æ…‹æ¢ä»¶æ‡‰ç”¨å®Œæˆ")
        
        return df
    
    def _log_condition_result(self, condition_name: str, count: int):
        """
        è¨˜éŒ„æ¢ä»¶åˆ¤æ–·çµæœ
        
        Args:
            condition_name: æ¢ä»¶åç¨±
            count: ç¬¦åˆæ¢ä»¶çš„è¨˜éŒ„æ•¸
        """
        if count > 0:
            self.logger.info(f"  âœ“ [{condition_name:40s}]: {count:6,} ç­†")
    
    # ========== éšæ®µ 4: è™•ç†æ ¼å¼éŒ¯èª¤ ==========
    
    def _handle_format_errors(self, df: pd.DataFrame, 
                              cond: PRERMConditions,
                              status_column: str) -> pd.DataFrame:
        """
        è™•ç†æ ¼å¼éŒ¯èª¤çš„è¨˜éŒ„
        
        Args:
            df: PR DataFrame
            cond: PR æ¢ä»¶é›†åˆ
            status_column: ç‹€æ…‹æ¬„ä½åç¨±
            
        Returns:
            pd.DataFrame: è™•ç†å¾Œçš„ DataFrame
        """
        # æ›´æ–° no_statusï¼ˆæœ€å¾Œä¸€æ¬¡ï¼‰
        no_status = (df[status_column].isna()) | (df[status_column] == 'nan') | (df[status_column] == '')
        
        mask_format_error = no_status & cond.format_error
        df.loc[mask_format_error, status_column] = 'æ ¼å¼éŒ¯èª¤ï¼Œé€€å–®'
        # ğŸ”´ æ›´æ–° no_status
        cond.no_status = (df[status_column].isna()) | (df[status_column] == 'nan') | (df[status_column] == '')
        
        error_count = mask_format_error.sum()
        if error_count > 0:
            self.logger.warning(f"âš ï¸  ç™¼ç¾ {error_count:,} ç­†æ ¼å¼éŒ¯èª¤")
        
        # å…¶ä»–
        condition_others = (
            cond.no_status
        )
        df.loc[condition_others, status_column] = 'å…¶ä»–'
        self._log_condition_result("å…¶ä»–", condition_others.sum())

        return df
    
    # ========== éšæ®µ 5: è¨­ç½®æ˜¯å¦ä¼°è¨ˆå…¥å¸³ ==========
    
    def _set_accrual_flag(self, df: pd.DataFrame, status_column: str) -> pd.DataFrame:
        """
        æ ¹æ“š PRç‹€æ…‹ è¨­ç½®æ˜¯å¦ä¼°è¨ˆå…¥å¸³
        
        PR é‚è¼¯ï¼š
        - 'å·²å®Œæˆ'ï¼šéœ€è¦ä¼°åˆ—å…¥å¸³ï¼ˆYï¼‰
        - 'å·²å…¥å¸³'ï¼šå·²ç¶“å…¥å¸³ï¼Œä¸éœ€ä¼°åˆ—ï¼ˆNï¼‰
        - å…¶ä»–ç‹€æ…‹ï¼šä¸ä¼°åˆ—ï¼ˆNï¼‰
        
        Args:
            df: PR DataFrame
            status_column: ç‹€æ…‹æ¬„ä½åç¨±
            
        Returns:
            pd.DataFrame: è¨­ç½®ä¼°åˆ—æ¨™è¨˜å¾Œçš„ DataFrame
        """
        self.logger.info("âš™ï¸  è¨­ç½®ä¼°åˆ—æ¨™è¨˜...")
        
        # åˆå§‹åŒ–ç‚º 'N'
        df['æ˜¯å¦ä¼°è¨ˆå…¥å¸³'] = 'N'
        
        # éœ€è¦ä¼°åˆ—çš„ç‹€æ…‹
        accrual_statuses = ['å·²å®Œæˆ']
        mask_need_accrual = df[status_column].isin(accrual_statuses)
        
        df.loc[mask_need_accrual, 'æ˜¯å¦ä¼°è¨ˆå…¥å¸³'] = 'Y'
        
        accrual_count = mask_need_accrual.sum()
        non_accrual_count = (~mask_need_accrual).sum()
        
        self.logger.info(f"  â”œâ”€ éœ€ä¼°åˆ—ï¼ˆYï¼‰ï¼š{accrual_count:,} ç­†")
        self.logger.info(f"  â””â”€ ä¸ä¼°åˆ—ï¼ˆNï¼‰ï¼š{non_accrual_count:,} ç­†")
        
        return df
    
    # ========== éšæ®µ 6: è¨­ç½®æœƒè¨ˆæ¬„ä½ ==========
    
    def _set_pr_accounting_fields(self, df: pd.DataFrame,
                                  ref_account: pd.DataFrame) -> pd.DataFrame:
        """
        è¨­ç½® PR æœƒè¨ˆç›¸é—œæ¬„ä½ï¼ˆç°¡åŒ–ç‰ˆæœ¬ï¼‰
        
        èˆ‡ PO çš„å·®ç•°ï¼š
        - ä¸è™•ç†é ä»˜æ¬¾ï¼ˆç„¡ Entry Prepay Amountï¼‰
        - ä¸è¨­ç½® Liabilityï¼ˆç„¡è² å‚µç§‘ç›®ï¼‰
        - ä¸è¨ˆç®— Accr. Amountï¼ˆç›´æ¥ä½¿ç”¨ Entry Amountï¼‰
        
        è¨­ç½®çš„æ¬„ä½ï¼š
        1. Account code (å¾ GL#)
        2. Account Name (å¾åƒè€ƒè³‡æ–™)
        3. Product code (å¾ Product Code)
        4. Region_c (å›ºå®š "TW")
        5. Dep. (éƒ¨é–€ä»£ç¢¼)
        6. Currency_c (å¾ Currency)
        
        Args:
            df: PR DataFrame
            ref_account: ç§‘ç›®æ˜ å°„åƒè€ƒè³‡æ–™
            
        Returns:
            pd.DataFrame: è¨­ç½®æœƒè¨ˆæ¬„ä½å¾Œçš„ DataFrame
        """
        self.logger.info("ğŸ’¼ è¨­ç½®æœƒè¨ˆæ¬„ä½...")
        
        need_accrual = df['æ˜¯å¦ä¼°è¨ˆå…¥å¸³'] == 'Y'
        accrual_count = need_accrual.sum()
        
        if accrual_count == 0:
            self.logger.info("  â””â”€ ç„¡éœ€ä¼°åˆ—è¨˜éŒ„ï¼Œè·³éæœƒè¨ˆæ¬„ä½è¨­ç½®")
            return df
        
        self.logger.info(f"  è™•ç† {accrual_count:,} ç­†éœ€ä¼°åˆ—è¨˜éŒ„...")
        
        # 1. Account code
        df.loc[need_accrual, 'Account code'] = df.loc[need_accrual, 'GL#']
        self.logger.debug("  âœ“ Account code è¨­ç½®å®Œæˆ")
        
        # 2. Account Nameï¼ˆé€šé mergeï¼‰
        df = self._set_account_name(df, ref_account, need_accrual)
        self.logger.debug("  âœ“ Account Name è¨­ç½®å®Œæˆ")
        
        # 3. Product code
        df.loc[need_accrual, 'Product code'] = df.loc[need_accrual, 'Product Code']
        self.logger.debug("  âœ“ Product code è¨­ç½®å®Œæˆ")
        
        # 4. Region_cï¼ˆSPX å›ºå®šå€¼ï¼‰
        df.loc[need_accrual, 'Region_c'] = "TW"
        self.logger.debug("  âœ“ Region_c è¨­ç½®å®Œæˆ")
        
        # 5. Dep.ï¼ˆéƒ¨é–€ä»£ç¢¼ï¼‰
        df = self._set_department(df, need_accrual)
        self.logger.debug("  âœ“ Dep. è¨­ç½®å®Œæˆ")
        
        # 6. Currency_c
        df.loc[need_accrual, 'Currency_c'] = df.loc[need_accrual, 'Currency']
        self.logger.debug("  âœ“ Currency_c è¨­ç½®å®Œæˆ")
        
        # 7. Accr. Amountï¼ˆPR ç›´æ¥ä½¿ç”¨ Entry Amountï¼Œä¸éœ€è¦è¨ˆç®—ï¼‰
        df.loc[need_accrual, 'Accr. Amount'] = df.loc[need_accrual, 'Entry Amount'].astype('Float64')
        self.logger.debug("  âœ“ Accr. Amount è¨­ç½®å®Œæˆ")
        
        self.logger.info("âœ“ æœƒè¨ˆæ¬„ä½è¨­ç½®å®Œæˆ")
        
        return df
    
    def _set_account_name(self, df: pd.DataFrame, ref_account: pd.DataFrame,
                          mask: pd.Series) -> pd.DataFrame:
        """
        è¨­ç½®æœƒè¨ˆç§‘ç›®åç¨±
        
        å¾åƒè€ƒè³‡æ–™ä¸­æŸ¥æ‰¾ç§‘ç›®åç¨±
        
        Args:
            df: PR DataFrame
            ref_account: ç§‘ç›®æ˜ å°„åƒè€ƒè³‡æ–™
            mask: éœ€è¦è¨­ç½®çš„è¨˜éŒ„é®ç½©
            
        Returns:
            pd.DataFrame: è¨­ç½®ç§‘ç›®åç¨±å¾Œçš„ DataFrame
        """
        if ref_account.empty:
            self.logger.warning("âš ï¸  åƒè€ƒç§‘ç›®è³‡æ–™ç‚ºç©ºï¼Œç„¡æ³•è¨­ç½® Account Name")
            return df
        
        # ä½¿ç”¨ merge å¾åƒè€ƒè³‡æ–™å–å¾—ç§‘ç›®åç¨±
        merged = pd.merge(
            df, 
            ref_account[['Account', 'Account Desc']],
            how='left',
            left_on='Account code',
            right_on='Account'
        )
        
        df['Account Name'] = merged['Account Desc']
        
        # æª¢æŸ¥éºæ¼
        missing_count = df.loc[mask, 'Account Name'].isna().sum()
        if missing_count > 0:
            self.logger.warning(f"âš ï¸  {missing_count:,} ç­†è¨˜éŒ„ç„¡æ³•æ‰¾åˆ°å°æ‡‰çš„ Account Name")
        
        return df
    
    def _set_department(self, df: pd.DataFrame, mask: pd.Series) -> pd.DataFrame:
        """
        è¨­ç½®éƒ¨é–€ä»£ç¢¼
        
        è¦å‰‡ï¼š
        - å¦‚æœç§‘ç›®åœ¨ dept_accounts æ¸…å–®ä¸­ï¼Œå– Department å‰ 3 ç¢¼
        - å¦å‰‡è¨­ç‚º '000'
        
        Args:
            df: PR DataFrame
            mask: éœ€è¦è¨­ç½®çš„è¨˜éŒ„é®ç½©
            
        Returns:
            pd.DataFrame: è¨­ç½®éƒ¨é–€ä»£ç¢¼å¾Œçš„ DataFrame
        """
        isin_dept = df['Account code'].astype('string').isin(
            [str(x) for x in self.dept_accounts]
        )
        
        # åœ¨ dept_accounts ä¸­çš„ç§‘ç›®
        dept_mask = mask & isin_dept
        if dept_mask.any():
            df.loc[dept_mask, 'Dep.'] = df.loc[dept_mask, 'Department'].str[:3]
        
        # ä¸åœ¨ dept_accounts ä¸­çš„ç§‘ç›®
        non_dept_mask = mask & ~isin_dept
        if non_dept_mask.any():
            df.loc[non_dept_mask, 'Dep.'] = '000'
        
        return df
    
    # ========== è¼”åŠ©æ–¹æ³• ==========
    
    def _generate_statistics(self, df: pd.DataFrame, status_column: str) -> Dict[str, Any]:
        """
        ç”Ÿæˆçµ±è¨ˆè³‡è¨Š
        
        Args:
            df: PR DataFrame
            status_column: ç‹€æ…‹æ¬„ä½åç¨±
            
        Returns:
            Dict: åŒ…å«çµ±è¨ˆè³‡è¨Šçš„å­—å…¸
        """
        total_count = len(df)
        accrual_count = (df['æ˜¯å¦ä¼°è¨ˆå…¥å¸³'] == 'Y').sum()
        
        stats = {
            'total_count': total_count,
            'accrual_count': accrual_count,
            'accrual_percentage': round((accrual_count / total_count * 100), 2) if total_count > 0 else 0,
            'status_distribution': {}
        }
        
        # ç‹€æ…‹åˆ†å¸ƒçµ±è¨ˆ
        if status_column in df.columns:
            status_counts = df[status_column].value_counts().to_dict()
            stats['status_distribution'] = {
                str(k): int(v) for k, v in status_counts.items()
            }
            
            # Top 5 ç‹€æ…‹
            top_5 = dict(sorted(status_counts.items(), key=lambda x: x[1], reverse=True)[:5])
            stats['top_5_statuses'] = {str(k): int(v) for k, v in top_5.items()}
        
        return stats
    
    def _log_summary_statistics(self, stats: Dict[str, Any], status_column: str):
        """
        è¨˜éŒ„çµ±è¨ˆæ‘˜è¦åˆ° logger
        
        Args:
            stats: çµ±è¨ˆè³‡è¨Šå­—å…¸
            status_column: ç‹€æ…‹æ¬„ä½åç¨±
        """
        self.logger.info("")
        self.logger.info("=" * 70)
        self.logger.info(f"ğŸ“Š {status_column} è™•ç†æ‘˜è¦")
        self.logger.info("=" * 70)
        
        # ç¸½è¦½çµ±è¨ˆ
        self.logger.info(f"ğŸ“ˆ ç¸½è¨˜éŒ„æ•¸ï¼š{stats['total_count']:,}")
        self.logger.info(f"   â”œâ”€ éœ€ä¼°åˆ—ï¼š{stats['accrual_count']:,} "
                         f"({stats['accrual_percentage']:.1f}%)")
        self.logger.info(f"   â””â”€ ä¸ä¼°åˆ—ï¼š{stats['total_count'] - stats['accrual_count']:,}")
        
        # Top 5 ç‹€æ…‹
        if 'top_5_statuses' in stats:
            self.logger.info("")
            self.logger.info("ğŸ† Top 5 ç‹€æ…‹åˆ†å¸ƒï¼š")
            for i, (status, count) in enumerate(stats['top_5_statuses'].items(), 1):
                percentage = (count / stats['total_count'] * 100)
                self.logger.info(f"   {i}. {status:40s}: {count:6,} ({percentage:5.1f}%)")
        
        self.logger.info("=" * 70)
    
    # ========== é©—è­‰æ–¹æ³• ==========
    
    async def validate_input(self, context: ProcessingContext) -> bool:
        """
        é©—è­‰è¼¸å…¥æ•¸æ“š
        
        æª¢æŸ¥ï¼š
        1. DataFrame ä¸ç‚ºç©º
        2. å¿…è¦æ¬„ä½å­˜åœ¨
        3. åƒè€ƒæ•¸æ“šå¯ç”¨
        4. è™•ç†æ—¥æœŸå­˜åœ¨
        
        Args:
            context: è™•ç†ä¸Šä¸‹æ–‡
            
        Returns:
            bool: é©—è­‰æ˜¯å¦é€šé
        """
        df = context.data
        
        # æª¢æŸ¥ DataFrame
        if df is None or df.empty:
            self.logger.error("âŒ è¼¸å…¥æ•¸æ“šç‚ºç©º")
            context.add_error("è¼¸å…¥æ•¸æ“šç‚ºç©º")
            return False
        
        # æª¢æŸ¥å¿…è¦æ¬„ä½
        required_columns = [
            'GL#',
            'Expected Received Month_è½‰æ›æ ¼å¼',
            'YMs of Item Description',
            'Item Description',
            'Remarked by Procurement',
            'Remarked by ä¸Šæœˆ FN',
            'Currency',
            'Product Code',
            'Requester',
            'PR Supplier',
            'Entry Amount',
            'Department'
        ]
        
        missing = [col for col in required_columns if col not in df.columns]
        
        if missing:
            self.logger.error(f"âŒ ç¼ºå°‘å¿…è¦æ¬„ä½: {missing}")
            context.add_error(f"ç¼ºå°‘å¿…è¦æ¬„ä½: {missing}")
            return False
        
        # æª¢æŸ¥åƒè€ƒæ•¸æ“š
        ref_account = context.get_auxiliary_data('reference_account')
        
        if ref_account is None:
            self.logger.error("âŒ ç¼ºå°‘åƒè€ƒæ•¸æ“šï¼šç§‘ç›®æ˜ å°„")
            context.add_error("ç¼ºå°‘åƒè€ƒæ•¸æ“šï¼šç§‘ç›®æ˜ å°„")
            return False
        
        # æª¢æŸ¥è™•ç†æ—¥æœŸ
        processing_date = context.get_variable('processing_date')
        if processing_date is None:
            self.logger.error("âŒ ç¼ºå°‘è™•ç†æ—¥æœŸ")
            context.add_error("ç¼ºå°‘è™•ç†æ—¥æœŸ")
            return False
        
        self.logger.info("âœ… è¼¸å…¥é©—è­‰é€šé")
        return True
    
    async def rollback(self, context: ProcessingContext, error: Exception):
        """
        å›æ»¾æ“ä½œ
        
        PR ERM æ­¥é©Ÿé€šå¸¸ä¸éœ€è¦ç‰¹æ®Šå›æ»¾æ“ä½œ
        
        Args:
            context: è™•ç†ä¸Šä¸‹æ–‡
            error: ç™¼ç”Ÿçš„éŒ¯èª¤
        """
        self.logger.warning(f"âš ï¸  å›æ»¾ PR ERM é‚è¼¯ï¼š{str(error)}")
        # å¦‚æœ‰éœ€è¦ï¼Œå¯åœ¨æ­¤è™•æ·»åŠ æ¸…ç†é‚è¼¯

