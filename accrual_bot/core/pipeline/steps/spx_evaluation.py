"""
é‚è¼¯åˆ¤æ–·ã€æ•¸æ“šè¨ˆç®—èˆ‡æ›´æ–°
"""
import time
import re
from dataclasses import dataclass
from typing import Optional, Dict, List, Tuple, Any, Union
from datetime import datetime
import pandas as pd
import numpy as np

from accrual_bot.core.pipeline.base import PipelineStep, StepResult, StepStatus
from accrual_bot.core.pipeline.context import ProcessingContext
from accrual_bot.utils.config import config_manager
from accrual_bot.core.pipeline.steps.common import StepMetadataBuilder


class StatusStage1Step(PipelineStep):
    """
    ç¬¬ä¸€éšæ®µç‹€æ…‹åˆ¤æ–·æ­¥é©Ÿ
    
    åŠŸèƒ½:
    æ ¹æ“šé—œå–®æ¸…å–®çµ¦äºˆåˆå§‹ç‹€æ…‹
    
    è¼¸å…¥: DataFrame + Closing list
    è¼¸å‡º: DataFrame with initial status
    """
    
    def __init__(self, name: str = "StatusStage1", **kwargs):
        super().__init__(name, description="Evaluate status stage 1", **kwargs)
    
    async def execute(self, context: ProcessingContext) -> StepResult:
        """åŸ·è¡Œç¬¬ä¸€éšæ®µç‹€æ…‹åˆ¤æ–·"""
        start_time = time.time()
        try:
            df = context.data.copy()
            df_spx_closing = context.get_auxiliary_data('closing_list')
            processing_date = context.metadata.processing_date
            
            self.logger.info("Evaluating status stage 1...")
            
            if df_spx_closing is None or df_spx_closing.empty:
                self.logger.warning("No closing list data, skipping status stage 1")
                return StepResult(
                    step_name=self.name,
                    status=StepStatus.SKIPPED,
                    data=df,
                    message="No closing list data"
                )
            
            # çµ¦äºˆç¬¬ä¸€éšæ®µç‹€æ…‹
            df = self._give_status_stage_1(df, 
                                           df_spx_closing, 
                                           processing_date,
                                           entity_type=context.metadata.entity_type)
            
            context.update_data(df)
            
            status_counts = df['POç‹€æ…‹'].value_counts().to_dict() if 'POç‹€æ…‹' in df.columns else {}
            
            self.logger.info("Status stage 1 evaluation completed")
            duration = time.time() - start_time
            
            return StepResult(
                step_name=self.name,
                status=StepStatus.SUCCESS,
                data=df,
                message="Status stage 1 evaluated",
                duration=duration,
                metadata={'status_counts': status_counts}
            )
            
        except Exception as e:
            self.logger.error(f"Status stage 1 evaluation failed: {str(e)}", exc_info=True)
            context.add_error(f"Status stage 1 evaluation failed: {str(e)}")
            duration = time.time() - start_time
            return StepResult(
                step_name=self.name,
                status=StepStatus.FAILED,
                error=e,
                duration=duration,
                message=str(e)
            )
    
    def _give_status_stage_1(self, 
                             df: pd.DataFrame, 
                             df_spx_closing: pd.DataFrame, 
                             date, 
                             **kwargs) -> pd.DataFrame:
        #     # é€™è£¡å¯¦ç¾é¡ä¼¼åŸå§‹ give_status_stage_1 çš„é‚è¼¯
        #     # æ ¹æ“šé—œå–®æ¸…å–®æ¨™è¨˜å·²é—œå–®çš„ PO
        """çµ¦äºˆç¬¬ä¸€éšæ®µç‹€æ…‹ - SPXç‰¹æœ‰é‚è¼¯
        
        Args:
            df: PO/PR DataFrame
            df_spx_closing: SPXé—œå–®æ•¸æ“šDataFrame
            
        Returns:
            pd.DataFrame: è™•ç†å¾Œçš„DataFrame
        """
        if 'entity_type' in kwargs:
            entity_type = kwargs.get('entity_type')
        else:
            entity_type = 'context transfer error'

        utility_suppliers = config_manager.get(entity_type, 'utility_suppliers')
        if 'POç‹€æ…‹' in df.columns:
            tag_column = 'POç‹€æ…‹'
            # ä¾æ“šå·²é—œå–®æ¢ä»¶å–å¾—å°æ‡‰çš„PO#
            c1, c2 = self.is_closed_spx(df_spx_closing)
            to_be_close = df_spx_closing.loc[c1, 'po_no'].unique() if c1.any() else []
            closed = df_spx_closing.loc[c2, 'po_no'].unique() if c2.any() else []
            
            # å®šç¾©ã€Œä¸ŠæœˆFNã€å‚™è¨»é—œå–®æ¢ä»¶
            remarked_close_by_fn_last_month = (
                (df['Remarked by ä¸Šæœˆ FN'].str.contains('åˆª|é—œ', na=False)) | 
                (df['Remarked by ä¸Šæœˆ FN PR'].astype('string').str.contains('åˆª|é—œ', na=False))
            )
            
            # çµ±ä¸€è½‰æ›æ—¥æœŸæ ¼å¼
            df['Remarked by ä¸Šæœˆ FN'] = self.convert_date_format_in_remark(df['Remarked by ä¸Šæœˆ FN'])
            df['Remarked by ä¸Šæœˆ FN PR'] = self.convert_date_format_in_remark(df['Remarked by ä¸Šæœˆ FN PR'])
            
            # æ¢ä»¶1ï¼šæ‘˜è¦ä¸­æœ‰æŠ¼é‡‘/ä¿è­‰é‡‘/Deposit/æ‰¾é›¶é‡‘ï¼Œä¸”ä¸æ˜¯FAç›¸é—œç§‘ç›®
            cond1 = \
                df['Item Description'].str.contains(config_manager.get(entity_type, 'deposit_keywords'), 
                                                    na=False)
            is_fa = df['GL#'].astype('string') == config_manager.get('FA_ACCOUNTS', entity_type, '199999')
            cond_exclude = df['Item Description'].str.contains('(?i)ç¹³è²»æ©Ÿè¨‚é‡‘', na=False)  # ç¹³è²»æ©Ÿè¨‚é‡‘å±¬FA
            df.loc[cond1 & ~is_fa & ~cond_exclude, tag_column] = \
                config_manager.get(entity_type, 'deposit_keywords_label')
            
            # æ¢ä»¶2ï¼šä¾›æ‡‰å•†èˆ‡é¡åˆ¥å°æ‡‰ï¼ŒåšGLèª¿æ•´
            bao_supplier: list = config_manager.get_list(entity_type, 'bao_supplier')
            bao_categories: list = config_manager.get_list(entity_type, 'bao_categories')
            cond2 = (df['PO Supplier'].isin(bao_supplier)) & (df['Category'].isin(bao_categories))
            df.loc[cond2, tag_column] = 'GLèª¿æ•´'
            
            # æ¢ä»¶3ï¼šè©²PO#åœ¨å¾…é—œå–®æ¸…å–®ä¸­
            cond3 = df['PO#'].astype('string').isin([str(x) for x in to_be_close])
            df.loc[cond3, tag_column] = 'å¾…é—œå–®'
            
            # æ¢ä»¶4ï¼šè©²PO#åœ¨å·²é—œå–®æ¸…å–®ä¸­
            cond4 = df['PO#'].astype('string').isin([str(x) for x in closed])
            df.loc[cond4, tag_column] = 'å·²é—œå–®'
            
            # æ¢ä»¶5ï¼šä¸ŠæœˆFNå‚™è¨»å«æœ‰ã€Œåˆªã€æˆ–ã€Œé—œã€
            cond5 = remarked_close_by_fn_last_month
            df.loc[cond5, tag_column] = 'åƒç…§ä¸Šæœˆé—œå–®'
            
            # æ¢ä»¶6ï¼šè‹¥ã€ŒRemarked by ä¸Šæœˆ FNã€å«æœ‰ã€Œå…¥FAã€ï¼Œå‰‡æå–è©²æ•¸å­—ï¼Œä¸¦æ›´æ–°ç‹€æ…‹(xxxxxxå…¥FA)
            # éƒ¨åˆ†å®Œæˆxxxxxxå…¥FAä¸è¨ˆå…¥ï¼Œå‰æœŸFNå‚™è¨»å¦‚æœæ˜¯éƒ¨åˆ†å®Œæˆçš„æœƒæ‰åˆ°ermé‚è¼¯åˆ¤æ–·
            cond6 = (
                (df['Remarked by ä¸Šæœˆ FN'].str.contains('å…¥FA', na=False)) & 
                (~df['Remarked by ä¸Šæœˆ FN'].str.contains('éƒ¨åˆ†å®Œæˆ', na=False))
            )
            if cond6.any():
                extracted_fn = self.extract_fa_remark(df.loc[cond6, 'Remarked by ä¸Šæœˆ FN'])
                df.loc[cond6, tag_column] = extracted_fn
            
            # æ¢ä»¶7ï¼šè‹¥ã€ŒRemarked by ä¸Šæœˆ FN PRã€å«æœ‰ã€Œå…¥FAã€ï¼Œå‰‡æå–è©²æ•¸å­—ï¼Œä¸¦æ›´æ–°ç‹€æ…‹
            cond7 = (
                (df['Remarked by ä¸Šæœˆ FN PR'].astype('string').str.contains('å…¥FA', na=False)) & 
                (~df['Remarked by ä¸Šæœˆ FN PR'].astype('string').str.contains('éƒ¨åˆ†å®Œæˆ', na=False))
            )
            if cond7.any():
                extracted_pr = self.extract_fa_remark(df.loc[cond7, 'Remarked by ä¸Šæœˆ FN PR'])
                df.loc[cond7, tag_column] = extracted_pr

            # æ¢ä»¶8ï¼šè©²ç­†è³‡æ–™supplieræ˜¯"å°é›»"ã€"å°æ°´"ã€"åŒ—æ°´"ç­‰å…¬å…±è²»ç”¨
            cond8 = df['PO Supplier'].fillna('system_filled').str.contains(utility_suppliers)
            df.loc[cond8, tag_column] = 'æˆæ‰£GLèª¿æ•´'

            # è²»ç”¨é¡æŒ‰ç”³è«‹äººç¯©é¸
            is_non_labeled = (df[tag_column].isna()) | (df[tag_column] == '') | (df[tag_column] == 'nan')
            ops_rent: str = config_manager.get(entity_type, 'ops_for_rent')
            account_rent: str = config_manager.get(entity_type, 'account_rent')
            ops_intermediary: str = config_manager.get(entity_type, 'ops_for_intermediary')
            ops_other: str = config_manager.get(entity_type, 'ops_for_other')
            
            mask_erm_equals_current = df['Expected Received Month_è½‰æ›æ ¼å¼'] == date
            mask_account_rent = df['GL#'] == account_rent
            mask_ops_rent = df['PR Requester'] == ops_rent
            mask_descerm_equals_current = df['YMs of Item Description'].str[:6].astype('Int64') == date
            mask_desc_contains_intermediary = df['Item Description'].fillna('na').str.contains('(?i)intermediary')
            mask_ops_intermediary = df['PR Requester'] == ops_intermediary

            combined_cond = is_non_labeled & mask_erm_equals_current & mask_account_rent & mask_ops_rent
            df.loc[combined_cond, tag_column] = 'å·²å®Œæˆ_ç§Ÿé‡‘'

            combined_cond = is_non_labeled & mask_descerm_equals_current & mask_account_rent & mask_ops_rent
            df.loc[combined_cond, tag_column] = 'å·²å®Œæˆ_ç§Ÿé‡‘'

            # ç§Ÿé‡‘å·²å…¥å¸³
            booked_in_ap = (~df['GL DATE'].isna()) & ((df['GL DATE'] != '') | (df['GL DATE'] != 'nan'))
            df.loc[(df[tag_column] == 'å·²å®Œæˆ_ç§Ÿé‡‘') & (booked_in_ap), tag_column] = 'å·²å…¥å¸³'

            uncompleted_rent = (
                ((df['Remarked by Procurement'] != 'error') &
                    is_non_labeled &
                    mask_ops_rent &
                    mask_account_rent &
                    (df['Item Description'].str.contains('(?i)ç§Ÿé‡‘', na=False))
                 ) &
                
                (
                    ((df['Expected Received Month_è½‰æ›æ ¼å¼'] <= df['YMs of Item Description'].str[:6].astype('Int32')) &
                        (df['Expected Received Month_è½‰æ›æ ¼å¼'] > date) &
                        (df['YMs of Item Description'] != '100001,100002')
                     ) |
                    ((df['Expected Received Month_è½‰æ›æ ¼å¼'] > df['YMs of Item Description'].str[:6].astype('Int32')) &
                        (df['Expected Received Month_è½‰æ›æ ¼å¼'] > date) &
                        (df['YMs of Item Description'] != '100001,100002')
                     )
                )
                    

            )
            df.loc[uncompleted_rent, tag_column] = 'æœªå®Œæˆ_ç§Ÿé‡‘'

            combined_cond = is_non_labeled & mask_ops_intermediary & mask_desc_contains_intermediary & \
                ((df['Expected Received Month_è½‰æ›æ ¼å¼'] == date) |
                    ((df['Expected Received Month_è½‰æ›æ ¼å¼'] < date) & (df['Remarked by ä¸Šæœˆ FN'].str.contains('å·²å®Œæˆ')))
                 )
            df.loc[combined_cond, tag_column] = 'å·²å®Œæˆ_intermediary'
            
            combined_cond = is_non_labeled & mask_ops_intermediary & mask_desc_contains_intermediary & \
                (df['Expected Received Month_è½‰æ›æ ¼å¼'] > date)
            df.loc[combined_cond, tag_column] = 'æœªå®Œæˆ_intermediary'

            # è¦åˆ¤æ–·OPSé©—æ”¶æ•¸
            kiosk_suppliers: list = config_manager.get_list(entity_type, 'kiosk_suppliers')
            locker_suppliers: list = config_manager.get_list(entity_type, 'locker_suppliers')
            asset_suppliers: list = kiosk_suppliers + locker_suppliers

            # Exclude both general 'å…¥FA' but Include specific patterns(éƒ¨åˆ†å…¥)
            po_general_fa = df['Remarked by ä¸Šæœˆ FN'].str.contains('å…¥FA', na=False)
            po_specific_pattern = df['Remarked by ä¸Šæœˆ FN'].str.contains(r'éƒ¨åˆ†å®Œæˆ.*\d{6}å…¥FA', na=False, regex=True)

            pr_general_fa = df['Remarked by ä¸Šæœˆ FN PR'].astype('string').str.contains('å…¥FA', na=False)
            pr_specific_pattern = (df['Remarked by ä¸Šæœˆ FN PR']
                                   .astype('string').str.contains(r'éƒ¨åˆ†å®Œæˆ.*\d{6}å…¥FA', na=False, regex=True))

            doesnt_contain_fa = (~pr_general_fa & ~po_general_fa)
            specific_pattern = (pr_specific_pattern | po_specific_pattern)
            ignore_closed = ~df[tag_column].str.contains('é—œ', na=False)
            mask = ((df['PO Supplier'].isin(asset_suppliers)) & 
                    (doesnt_contain_fa | specific_pattern) & 
                    (ignore_closed))
            df.loc[mask, tag_column] = 'Pending_validating'
            
            self.logger.info("æˆåŠŸçµ¦äºˆç¬¬ä¸€éšæ®µç‹€æ…‹")
            return df
        else:
            tag_column = 'PRç‹€æ…‹'
            # ä¾æ“šå·²é—œå–®æ¢ä»¶å–å¾—å°æ‡‰çš„PO#
            c1, c2 = self.is_closed_spx(df_spx_closing)
            to_be_close = df_spx_closing.loc[c1, 'new_pr_no'].unique() if c1.any() else []
            closed = df_spx_closing.loc[c2, 'new_pr_no'].unique() if c2.any() else []
            
            # å®šç¾©ã€Œä¸ŠæœˆFNã€å‚™è¨»é—œå–®æ¢ä»¶
            remarked_close_by_fn_last_month = (
                df['Remarked by ä¸Šæœˆ FN'].astype('string').str.contains('åˆª|é—œ', na=False)
            )
            
            # çµ±ä¸€è½‰æ›æ—¥æœŸæ ¼å¼
            df['Remarked by ä¸Šæœˆ FN'] = self.convert_date_format_in_remark(df['Remarked by ä¸Šæœˆ FN'])
            
            # æ¢ä»¶1ï¼šæ‘˜è¦ä¸­æœ‰æŠ¼é‡‘/ä¿è­‰é‡‘/Deposit/æ‰¾é›¶é‡‘ï¼Œä¸”ä¸æ˜¯FAç›¸é—œç§‘ç›®
            cond1 = \
                df['Item Description'].str.contains(config_manager.get(entity_type, 'deposit_keywords'), 
                                                    na=False)
            is_fa = df['GL#'].astype('string') == config_manager.get('FA_ACCOUNTS', entity_type, '199999')
            cond_exclude = df['Item Description'].str.contains('(?i)ç¹³è²»æ©Ÿè¨‚é‡‘', na=False)  # ç¹³è²»æ©Ÿè¨‚é‡‘å±¬FA
            df.loc[cond1 & ~is_fa & ~cond_exclude, tag_column] = \
                config_manager.get(entity_type, 'deposit_keywords_label')
            
            # æ¢ä»¶2ï¼šä¾›æ‡‰å•†èˆ‡é¡åˆ¥å°æ‡‰ï¼ŒåšGLèª¿æ•´
            bao_supplier: list = config_manager.get_list(entity_type, 'bao_supplier')
            bao_categories: list = config_manager.get_list(entity_type, 'bao_categories')
            cond2 = (df['PR Supplier'].isin(bao_supplier)) & (df['Category'].isin(bao_categories))
            df.loc[cond2, tag_column] = 'GLèª¿æ•´'
            
            # æ¢ä»¶3ï¼šè©²PR#åœ¨å¾…é—œå–®æ¸…å–®ä¸­
            cond3 = df['PR#'].astype('string').isin([str(x) for x in to_be_close])
            df.loc[cond3, tag_column] = 'å¾…é—œå–®'
            
            # æ¢ä»¶4ï¼šè©²PR#åœ¨å·²é—œå–®æ¸…å–®ä¸­
            cond4 = df['PR#'].astype('string').isin([str(x) for x in closed])
            df.loc[cond4, tag_column] = 'å·²é—œå–®'
            
            # æ¢ä»¶5ï¼šä¸ŠæœˆFNå‚™è¨»å«æœ‰ã€Œåˆªã€æˆ–ã€Œé—œã€
            cond5 = remarked_close_by_fn_last_month
            df.loc[cond5, tag_column] = 'åƒç…§ä¸Šæœˆé—œå–®'
            
            # æ¢ä»¶6ï¼šè‹¥ã€ŒRemarked by ä¸Šæœˆ FNã€å«æœ‰ã€Œå…¥FAã€ï¼Œå‰‡æå–è©²æ•¸å­—ï¼Œä¸¦æ›´æ–°ç‹€æ…‹(xxxxxxå…¥FA)
            # éƒ¨åˆ†å®Œæˆxxxxxxå…¥FAä¸è¨ˆå…¥ï¼Œå‰æœŸFNå‚™è¨»å¦‚æœæ˜¯éƒ¨åˆ†å®Œæˆçš„æœƒæ‰åˆ°ermé‚è¼¯åˆ¤æ–·
            cond6 = (
                (df['Remarked by ä¸Šæœˆ FN'].astype('string').str.contains('å…¥FA', na=False)) & 
                (~df['Remarked by ä¸Šæœˆ FN'].astype('string').str.contains('éƒ¨åˆ†å®Œæˆ', na=False))
            )
            if cond6.any():
                extracted_fn = self.extract_fa_remark(df.loc[cond6, 'Remarked by ä¸Šæœˆ FN'])
                df.loc[cond6, tag_column] = extracted_fn
            
            # æ¢ä»¶8ï¼šè©²ç­†è³‡æ–™supplieræ˜¯"å°é›»"ã€"å°æ°´"ã€"åŒ—æ°´"ç­‰å…¬å…±è²»ç”¨
            cond8 = df['PR Supplier'].fillna('system_filled').str.contains(utility_suppliers)
            df.loc[cond8, tag_column] = 'æˆæ‰£GLèª¿æ•´'

            # è²»ç”¨é¡æŒ‰ç”³è«‹äººç¯©é¸
            is_non_labeled = (df[tag_column].isna()) | (df[tag_column] == '') | (df[tag_column] == 'nan')
            ops_rent: str = config_manager.get(entity_type, 'ops_for_rent')
            account_rent: str = config_manager.get(entity_type, 'account_rent')
            ops_intermediary: str = config_manager.get(entity_type, 'ops_for_intermediary')
            ops_other: str = config_manager.get(entity_type, 'ops_for_other')
            
            mask_erm_equals_current = df['Expected Received Month_è½‰æ›æ ¼å¼'] == date
            mask_account_rent = df['GL#'] == account_rent
            mask_ops_rent = df['Requester'] == ops_rent
            mask_descerm_equals_current = df['YMs of Item Description'].str[:6].astype('Int64') == date
            mask_desc_contains_intermediary = df['Item Description'].fillna('na').str.contains('(?i)intermediary')
            mask_ops_intermediary = df['Requester'] == ops_intermediary

            combined_cond = is_non_labeled & mask_erm_equals_current & mask_account_rent & mask_ops_rent
            df.loc[combined_cond, tag_column] = 'å·²å®Œæˆ_ç§Ÿé‡‘'

            combined_cond = is_non_labeled & mask_descerm_equals_current & mask_account_rent & mask_ops_rent
            df.loc[combined_cond, tag_column] = 'å·²å®Œæˆ_ç§Ÿé‡‘'

            uncompleted_rent = (
                ((df['Remarked by Procurement'] != 'error') &
                    is_non_labeled &
                    mask_ops_rent &
                    mask_account_rent &
                    (df['Item Description'].str.contains('(?i)ç§Ÿé‡‘', na=False))
                 ) &
                
                (
                    ((df['Expected Received Month_è½‰æ›æ ¼å¼'] <= df['YMs of Item Description'].str[:6].astype('Int32')) &
                        (df['Expected Received Month_è½‰æ›æ ¼å¼'] > date) &
                        (df['YMs of Item Description'] != '100001,100002')
                     ) |
                    ((df['Expected Received Month_è½‰æ›æ ¼å¼'] > df['YMs of Item Description'].str[:6].astype('Int32')) &
                        (df['Expected Received Month_è½‰æ›æ ¼å¼'] > date) &
                        (df['YMs of Item Description'] != '100001,100002')
                     )
                )

            )
            df.loc[uncompleted_rent, tag_column] = 'æœªå®Œæˆ_ç§Ÿé‡‘'

            combined_cond = is_non_labeled & mask_ops_intermediary & mask_desc_contains_intermediary & \
                ((df['Expected Received Month_è½‰æ›æ ¼å¼'] == date) |
                    ((df['Expected Received Month_è½‰æ›æ ¼å¼'] < date) & (df['Remarked by ä¸Šæœˆ FN']
                                                                    .astype('string').str.contains('å·²å®Œæˆ')))
                 )
            df.loc[combined_cond, tag_column] = 'å·²å®Œæˆ_intermediary'
            
            combined_cond = is_non_labeled & mask_ops_intermediary & mask_desc_contains_intermediary & \
                (df['Expected Received Month_è½‰æ›æ ¼å¼'] > date)
            df.loc[combined_cond, tag_column] = 'æœªå®Œæˆ_intermediary'

            # PRçš„æ™ºå–æ«ƒèˆ‡ç¹³è²»æ©Ÿï¼Œä¸æœƒåœ¨PRé©—æ”¶ä¸ä¼°
            kiosk_suppliers: list = config_manager.get_list(entity_type, 'kiosk_suppliers')
            locker_suppliers: list = config_manager.get_list(entity_type, 'locker_suppliers')
            asset_suppliers: list = kiosk_suppliers + locker_suppliers
            ignore_closed = ~df[tag_column].str.contains('é—œ', na=False)
            mask = ((df['PR Supplier'].isin(asset_suppliers)) & 
                    (ignore_closed))
            df.loc[mask, tag_column] = 'æ™ºå–æ«ƒèˆ‡ç¹³è²»æ©Ÿ'

            self.logger.info("æˆåŠŸçµ¦äºˆç¬¬ä¸€éšæ®µç‹€æ…‹")
            # return df
        
        if 'PO#' in df_spx_closing.columns and 'PO#' in df.columns:
            closed_po_list = df_spx_closing['PO#'].unique().tolist()
            
            # æ¨™è¨˜å·²é—œå–®çš„ PO
            df.loc[df['PO#'].isin(closed_po_list), 'Closing_Status'] = 'Closed'
        
        return df
    
    def is_closed_spx(self, df: pd.DataFrame) -> Tuple[pd.Series, pd.Series]:
        """åˆ¤æ–·SPXé—œå–®ç‹€æ…‹
        
        Args:
            df: é—œå–®æ•¸æ“šDataFrame
            
        Returns:
            Tuple[pd.Series, pd.Series]: (å¾…é—œå–®æ¢ä»¶, å·²é—œå–®æ¢ä»¶)
        """
        # [0]æœ‰æ–°çš„PRç·¨è™Ÿï¼Œä½†FNæœªä¸Šç³»çµ±é—œå–®çš„
        condition_to_be_closed = (
            (~df['new_pr_no'].isna()) & 
            (df['new_pr_no'] != '') & 
            (df['done_by_fn'].isna())
        )
        
        # [1]æœ‰æ–°çš„PRç·¨è™Ÿï¼Œä½†FNå·²ç¶“ä¸Šç³»çµ±é—œå–®çš„
        condition_closed = (
            (~df['new_pr_no'].isna()) & 
            (df['new_pr_no'] != '') & 
            (~df['done_by_fn'].isna())
        )
        
        return condition_to_be_closed, condition_closed
    
    def convert_date_format_in_remark(self, series: pd.Series) -> pd.Series:
        """è½‰æ›å‚™è¨»ä¸­çš„æ—¥æœŸæ ¼å¼ (YYYY/MM -> YYYYMM)
        
        Args:
            series: åŒ…å«æ—¥æœŸçš„Series
            
        Returns:
            pd.Series: è½‰æ›å¾Œçš„Series
        """
        try:
            return series.astype('string').str.replace(r'(\d{4})/(\d{2})', r'\1\2', regex=True)
        except Exception as e:
            self.logger.error(f"è½‰æ›æ—¥æœŸæ ¼å¼æ™‚å‡ºéŒ¯: {str(e)}", exc_info=True)
            return series
        
    def extract_fa_remark(self, series: pd.Series) -> pd.Series:
        """æå–FAå‚™è¨»ä¸­çš„æ—¥æœŸ
        
        Args:
            series: åŒ…å«FAå‚™è¨»çš„Series
            
        Returns:
            pd.Series: æå–çš„æ—¥æœŸSeries
        """
        try:
            return series.astype('string').str.extract(r'(\d{6}å…¥FA)', expand=False)
        except Exception as e:
            self.logger.error(f"æå–FAå‚™è¨»æ™‚å‡ºéŒ¯: {str(e)}", exc_info=True)
            return series
    
    async def validate_input(self, context: ProcessingContext) -> bool:
        """é©—è­‰è¼¸å…¥"""
        if context.data is None or context.data.empty:
            self.logger.error("No data for status stage 1")
            return False
        
        return True


@dataclass
class ERMConditions:
    """ERM åˆ¤æ–·æ¢ä»¶é›†åˆ - æé«˜å¯è®€æ€§"""
    # åŸºç¤æ¢ä»¶çµ„ä»¶
    no_status: pd.Series
    in_date_range: pd.Series
    erm_before_or_equal_file_date: pd.Series
    erm_after_file_date: pd.Series
    quantity_matched: pd.Series
    not_billed: pd.Series
    has_billing: pd.Series
    fully_billed: pd.Series
    has_unpaid_amount: pd.Series
    
    # å‚™è¨»æ¢ä»¶
    procurement_completed_or_rent: pd.Series
    fn_completed_or_posted: pd.Series
    pr_not_incomplete: pd.Series
    
    # FA æ¢ä»¶
    is_fa: pd.Series
    
    # éŒ¯èª¤æ¢ä»¶
    procurement_not_error: pd.Series
    out_of_date_range: pd.Series
    format_error: pd.Series


class SPXERMLogicStep(PipelineStep):
    """
    SPX ERM é‚è¼¯æ­¥é©Ÿ - å®Œæ•´å¯¦ç¾ç‰ˆæœ¬
    
    åŠŸèƒ½ï¼š
    1. è¨­ç½®æª”æ¡ˆæ—¥æœŸ
    2. åˆ¤æ–· 11 ç¨® PO ç‹€æ…‹ï¼ˆå·²å…¥å¸³ã€å·²å®Œæˆã€Checkæ”¶è²¨ç­‰ï¼‰
    3. æ ¹æ“šç‹€æ…‹è¨­ç½®æ˜¯å¦ä¼°è¨ˆå…¥å¸³
    4. è¨­ç½®æœƒè¨ˆç›¸é—œæ¬„ä½ï¼ˆAccount code, Product code, Dep.ç­‰ï¼‰
    5. è¨ˆç®—é ä¼°é‡‘é¡ï¼ˆAccr. Amountï¼‰
    6. è™•ç†é ä»˜æ¬¾å’Œè² å‚µç§‘ç›®
    7. æª¢æŸ¥ PR Product Code
    
    æ¥­å‹™è¦å‰‡ï¼š
    - SPX é‚è¼¯ï¼šã€Œå·²å®Œæˆã€ç‹€æ…‹çš„é …ç›®éœ€è¦ä¼°åˆ—å…¥å¸³
    - å…¶ä»–ç‹€æ…‹ä¸€å¾‹ä¸ä¼°åˆ—ï¼ˆæ˜¯å¦ä¼°è¨ˆå…¥å¸³ = Nï¼‰
    
    è¼¸å…¥ï¼š
    - DataFrame with required columns
    - Reference data (ç§‘ç›®æ˜ å°„ã€è² å‚µç§‘ç›®)
    - Processing date
    
    è¼¸å‡ºï¼š
    - DataFrame with POç‹€æ…‹, æ˜¯å¦ä¼°è¨ˆå…¥å¸³, and accounting fields
    """
    
    def __init__(self, name: str = "SPX_ERM_Logic", **kwargs):
        super().__init__(
            name=name,
            description="Apply SPX ERM logic with 11 status conditions",
            **kwargs
        )
        
        # å¾é…ç½®è®€å–é—œéµåƒæ•¸
        self.fa_accounts = config_manager.get_list('SPX', 'fa_accounts', ['199999'])
        self.dept_accounts = config_manager.get_list('SPX', 'dept_accounts', [])
        
        self.logger.info(f"Initialized {name} with FA accounts: {self.fa_accounts}")
    
    async def execute(self, context: ProcessingContext) -> StepResult:
        """åŸ·è¡Œ ERM é‚è¼¯"""
        start_time = time.time()
        try:
            df = context.data.copy()
            processing_date = context.get_variable('processing_date')
            
            # ç²å–åƒè€ƒæ•¸æ“š
            ref_account = context.get_auxiliary_data('reference_account')
            ref_liability = context.get_auxiliary_data('reference_liability')
            
            if ref_account is None or ref_liability is None:
                raise ValueError("ç¼ºå°‘åƒè€ƒæ•¸æ“šï¼šç§‘ç›®æ˜ å°„æˆ–è² å‚µç§‘ç›®")
            
            self.logger.info(f"é–‹å§‹ ERM é‚è¼¯è™•ç†ï¼Œè™•ç†æ—¥æœŸï¼š{processing_date}")
            
            # ========== éšæ®µ 1: è¨­ç½®åŸºæœ¬æ¬„ä½ ==========
            df = self._set_file_date(df, processing_date)
            
            # ========== éšæ®µ 2: æ§‹å»ºåˆ¤æ–·æ¢ä»¶ ==========
            conditions = self._build_conditions(df, processing_date)
            
            # ========== éšæ®µ 3: æ‡‰ç”¨ 11 å€‹ç‹€æ…‹æ¢ä»¶ ==========
            df = self._apply_status_conditions(df, conditions)
            
            # ========== éšæ®µ 4: è™•ç†æ ¼å¼éŒ¯èª¤ ==========
            df = self._handle_format_errors(df, conditions)
            
            # ========== éšæ®µ 5: è¨­ç½®æ˜¯å¦ä¼°è¨ˆå…¥å¸³ ==========
            df = self._set_accrual_flag(df)
            
            # ========== éšæ®µ 6: è¨­ç½®æœƒè¨ˆæ¬„ä½ ==========
            df = self._set_accounting_fields(df, ref_account, ref_liability)
            
            # ========== éšæ®µ 7: æª¢æŸ¥ PR Product Code ==========
            df = self._check_pr_product_code(df)
            
            # æ›´æ–°ä¸Šä¸‹æ–‡
            context.update_data(df)
            
            # ç”Ÿæˆçµ±è¨ˆè³‡è¨Š
            stats = self._generate_statistics(df)
            
            self.logger.info(
                f"ERM é‚è¼¯å®Œæˆ - "
                f"éœ€ä¼°åˆ—: {stats['accrual_count']} ç­†, "
                f"ç¸½è¨ˆ: {stats['total_count']} ç­†"
            )
            duration = time.time() - start_time
            
            return StepResult(
                step_name=self.name,
                status=StepStatus.SUCCESS,
                data=df,
                message=f"ERM é‚è¼¯å·²æ‡‰ç”¨ï¼Œ{stats['accrual_count']} ç­†éœ€ä¼°åˆ—",
                duration=duration,
                metadata=stats
            )
            
        except Exception as e:
            self.logger.error(f"ERM é‚è¼¯è™•ç†å¤±æ•—: {str(e)}", exc_info=True)
            context.add_error(f"ERM é‚è¼¯å¤±æ•—: {str(e)}")
            duration = time.time() - start_time
            return StepResult(
                step_name=self.name,
                status=StepStatus.FAILED,
                error=e,
                duration=duration,
                message=str(e)
            )
    
    # ========== éšæ®µ 1: åŸºæœ¬è¨­ç½® ==========
    
    def _set_file_date(self, df: pd.DataFrame, processing_date: int) -> pd.DataFrame:
        """è¨­ç½®æª”æ¡ˆæ—¥æœŸ"""
        df['æª”æ¡ˆæ—¥æœŸ'] = processing_date
        self.logger.debug(f"å·²è¨­ç½®æª”æ¡ˆæ—¥æœŸï¼š{processing_date}")
        return df
    
    # ========== éšæ®µ 2: æ§‹å»ºæ¢ä»¶ ==========
    
    def _build_conditions(self, df: pd.DataFrame, file_date: int) -> ERMConditions:
        """
        æ§‹å»ºæ‰€æœ‰åˆ¤æ–·æ¢ä»¶
        
        å°‡æ¢ä»¶é‚è¼¯é›†ä¸­åœ¨æ­¤è™•ï¼Œæé«˜å¯è®€æ€§å’Œç¶­è­·æ€§
        """
        # åŸºç¤ç‹€æ…‹æ¢ä»¶
        no_status = (df['POç‹€æ…‹'].isna()) | (df['POç‹€æ…‹'] == 'nan')
        
        # æ—¥æœŸç¯„åœæ¢ä»¶
        ym_start = df['YMs of Item Description'].str[:6].astype('Int32')
        ym_end = df['YMs of Item Description'].str[7:].astype('Int32')
        erm = df['Expected Received Month_è½‰æ›æ ¼å¼']
        
        in_date_range = erm.between(ym_start, ym_end, inclusive='both')
        erm_before_or_equal_file_date = erm <= file_date
        erm_after_file_date = erm > file_date
        
        # æ•¸é‡æ¢ä»¶
        quantity_matched = df['Entry Quantity'] == df['Received Quantity']
        
        # å¸³å‹™æ¢ä»¶
        not_billed = df['Entry Billed Amount'].astype('Float64') == 0
        has_billing = df['Billed Quantity'] != '0'
        fully_billed = (
            df['Entry Amount'].astype('Float64') - 
            df['Entry Billed Amount'].astype('Float64')
        ) == 0
        has_unpaid_amount = (
            df['Entry Amount'].astype('Float64') - 
            df['Entry Billed Amount'].astype('Float64')
        ) != 0
        
        # å‚™è¨»æ¢ä»¶
        procurement_completed_or_rent = df['Remarked by Procurement'].str.contains(
            '(?i)å·²å®Œæˆ|rent', na=False
        )
        fn_completed_or_posted = df['Remarked by ä¸Šæœˆ FN'].str.contains(
            '(?i)å·²å®Œæˆ|å·²å…¥å¸³', na=False
        )
        pr_not_incomplete = ~df['Remarked by ä¸Šæœˆ FN PR'].str.contains(
            '(?i)æœªå®Œæˆ', na=False
        )
        
        # FA æ¢ä»¶
        is_fa = df['GL#'].astype('string').isin([str(x) for x in self.fa_accounts])
        
        # éŒ¯èª¤æ¢ä»¶
        procurement_not_error = df['Remarked by Procurement'] != 'error'
        out_of_date_range = (
            (in_date_range == False) & 
            (df['YMs of Item Description'] != '100001,100002')
        )
        format_error = df['YMs of Item Description'] == '100001,100002'
        
        return ERMConditions(
            no_status=no_status,
            in_date_range=in_date_range,
            erm_before_or_equal_file_date=erm_before_or_equal_file_date,
            erm_after_file_date=erm_after_file_date,
            quantity_matched=quantity_matched,
            not_billed=not_billed,
            has_billing=has_billing,
            fully_billed=fully_billed,
            has_unpaid_amount=has_unpaid_amount,
            procurement_completed_or_rent=procurement_completed_or_rent,
            fn_completed_or_posted=fn_completed_or_posted,
            pr_not_incomplete=pr_not_incomplete,
            is_fa=is_fa,
            procurement_not_error=procurement_not_error,
            out_of_date_range=out_of_date_range,
            format_error=format_error
        )
    
    # ========== éšæ®µ 3: æ‡‰ç”¨ç‹€æ…‹æ¢ä»¶ ==========
    
    def _apply_status_conditions(self, df: pd.DataFrame, 
                                 cond: ERMConditions) -> pd.DataFrame:
        """
        æ‡‰ç”¨ 11 å€‹ç‹€æ…‹åˆ¤æ–·æ¢ä»¶
        
        æ¢ä»¶å„ªå…ˆé †åºå¾ä¸Šåˆ°ä¸‹ï¼Œç¬¦åˆçš„æ¢ä»¶æœƒè¢«å„ªå…ˆè¨­ç½®
        """
        
        # === æ¢ä»¶ 1: å·²å…¥å¸³ï¼ˆå‰æœŸFNæ˜ç¢ºæ¨™è¨»ï¼‰===
        condition_1 = df['Remarked by ä¸Šæœˆ FN'].str.contains('(?i)å·²å…¥å¸³', na=False)
        df.loc[condition_1, 'POç‹€æ…‹'] = 'å·²å…¥å¸³'
        self._log_condition_result("å·²å…¥å¸³ï¼ˆå‰æœŸFNæ˜ç¢ºæ¨™è¨»ï¼‰", condition_1.sum())
        # ğŸ”´ æ–°å¢ï¼šæ›´æ–° no_status
        cond.no_status = (df['POç‹€æ…‹'].isna()) | (df['POç‹€æ…‹'] == 'nan')
        
        # === æ¢ä»¶ 2: å·²å…¥å¸³ï¼ˆæœ‰ GL DATE ä¸”ç¬¦åˆå…¶ä»–æ¢ä»¶ï¼‰===
        condition_2 = (
            (~df['GL DATE'].isna()) &
            cond.no_status &
            cond.in_date_range &
            cond.erm_before_or_equal_file_date &
            cond.quantity_matched &
            cond.has_billing &
            (cond.procurement_completed_or_rent | cond.fn_completed_or_posted) &
            (~cond.is_fa)
        )
        df.loc[condition_2, 'POç‹€æ…‹'] = 'å·²å…¥å¸³'
        self._log_condition_result("å·²å…¥å¸³ï¼ˆGL DATEï¼‰", condition_2.sum())

        # ğŸ”´ æ–°å¢ï¼šæ›´æ–° no_status
        cond.no_status = (df['POç‹€æ…‹'].isna()) | (df['POç‹€æ…‹'] == 'nan')
        
        # === æ¢ä»¶ 3: å·²å®Œæˆ ===
        condition_3 = (
            (cond.procurement_completed_or_rent | cond.fn_completed_or_posted) &
            cond.pr_not_incomplete &
            cond.no_status &
            cond.in_date_range &
            cond.erm_before_or_equal_file_date &
            cond.quantity_matched &
            cond.not_billed
        )
        df.loc[condition_3, 'POç‹€æ…‹'] = 'å·²å®Œæˆ'
        self._log_condition_result("å·²å®Œæˆ", condition_3.sum())

        # ğŸ”´ æ–°å¢ï¼šæ›´æ–° no_status
        cond.no_status = (df['POç‹€æ…‹'].isna()) | (df['POç‹€æ…‹'] == 'nan')
        
        # === æ¢ä»¶ 4: å…¨ä»˜å®Œï¼Œæœªé—œå–® ===
        condition_4 = (
            (cond.procurement_completed_or_rent | cond.fn_completed_or_posted) &
            cond.no_status &
            cond.in_date_range &
            cond.erm_before_or_equal_file_date &
            cond.quantity_matched &
            (df['Entry Billed Amount'].astype('Float64') != 0) &
            cond.fully_billed
        )
        df.loc[condition_4, 'POç‹€æ…‹'] = 'å…¨ä»˜å®Œï¼Œæœªé—œå–®?'
        self._log_condition_result("å…¨ä»˜å®Œï¼Œæœªé—œå–®", condition_4.sum())

        # ğŸ”´ æ–°å¢ï¼šæ›´æ–° no_status
        cond.no_status = (df['POç‹€æ…‹'].isna()) | (df['POç‹€æ…‹'] == 'nan')
        
        # === æ¢ä»¶ 5: å·²å®Œæˆä½†æœ‰æœªä»˜æ¬¾éƒ¨åˆ† ===
        condition_5 = (
            (cond.procurement_completed_or_rent | cond.fn_completed_or_posted) &
            cond.no_status &
            cond.in_date_range &
            cond.erm_before_or_equal_file_date &
            cond.quantity_matched &
            (df['Entry Billed Amount'].astype('Float64') != 0) &
            cond.has_unpaid_amount
        )
        df.loc[condition_5, 'POç‹€æ…‹'] = 'å·²å®Œæˆ'
        self._log_condition_result("å·²å®Œæˆï¼ˆæœ‰æœªä»˜æ¬¾ï¼‰", condition_5.sum())

        # ğŸ”´ æ–°å¢ï¼šæ›´æ–° no_status
        cond.no_status = (df['POç‹€æ…‹'].isna()) | (df['POç‹€æ…‹'] == 'nan')
        
        # === æ¢ä»¶ 6: Checkæ”¶è²¨ ===
        condition_6 = (
            cond.procurement_not_error &
            cond.no_status &
            cond.in_date_range &
            cond.erm_before_or_equal_file_date &
            (~cond.quantity_matched)
        )
        df.loc[condition_6, 'POç‹€æ…‹'] = 'Checkæ”¶è²¨'
        self._log_condition_result("Checkæ”¶è²¨", condition_6.sum())

        # ğŸ”´ æ–°å¢ï¼šæ›´æ–° no_status
        cond.no_status = (df['POç‹€æ…‹'].isna()) | (df['POç‹€æ…‹'] == 'nan')
        
        # === æ¢ä»¶ 7: æœªå®Œæˆ ===
        condition_7 = (
            cond.procurement_not_error &
            cond.no_status &
            cond.in_date_range &
            cond.erm_after_file_date
        )
        df.loc[condition_7, 'POç‹€æ…‹'] = 'æœªå®Œæˆ'
        self._log_condition_result("æœªå®Œæˆ", condition_7.sum())

        # ğŸ”´ æ–°å¢ï¼šæ›´æ–° no_status
        cond.no_status = (df['POç‹€æ…‹'].isna()) | (df['POç‹€æ…‹'] == 'nan')
        
        # === æ¢ä»¶ 8: ç¯„åœéŒ¯èª¤_ç§Ÿé‡‘ ===
        condition_8 = (
            cond.procurement_not_error &
            cond.no_status &
            cond.out_of_date_range &
            (df['Item Description'].str.contains('(?i)ç§Ÿé‡‘', na=False))
        )
        df.loc[condition_8, 'POç‹€æ…‹'] = 'error(Description Period is out of ERM)_ç§Ÿé‡‘'
        self._log_condition_result("ç¯„åœéŒ¯èª¤_ç§Ÿé‡‘", condition_8.sum())

        # ğŸ”´ æ–°å¢ï¼šæ›´æ–° no_status
        cond.no_status = (df['POç‹€æ…‹'].isna()) | (df['POç‹€æ…‹'] == 'nan')
        
        # === æ¢ä»¶ 9: ç¯„åœéŒ¯èª¤_è–ªè³‡ ===
        condition_9 = (
            cond.procurement_not_error &
            cond.no_status &
            cond.out_of_date_range &
            (df['Item Description'].str.contains('(?i)æ´¾é£|Salary|Agency Fee', na=False))
        )
        df.loc[condition_9, 'POç‹€æ…‹'] = 'error(Description Period is out of ERM)_è–ªè³‡'
        self._log_condition_result("ç¯„åœéŒ¯èª¤_è–ªè³‡", condition_9.sum())

        # ğŸ”´ æ–°å¢ï¼šæ›´æ–° no_status
        cond.no_status = (df['POç‹€æ…‹'].isna()) | (df['POç‹€æ…‹'] == 'nan')
        
        # === æ¢ä»¶ 10: ç¯„åœéŒ¯èª¤ï¼ˆä¸€èˆ¬ï¼‰===
        condition_10 = (
            cond.procurement_not_error &
            cond.no_status &
            cond.out_of_date_range
        )
        df.loc[condition_10, 'POç‹€æ…‹'] = 'error(Description Period is out of ERM)'
        self._log_condition_result("ç¯„åœéŒ¯èª¤ï¼ˆä¸€èˆ¬ï¼‰", condition_10.sum())

        # ğŸ”´ æ–°å¢ï¼šæ›´æ–° no_status
        cond.no_status = (df['POç‹€æ…‹'].isna()) | (df['POç‹€æ…‹'] == 'nan')
        
        # === æ¢ä»¶ 11: éƒ¨åˆ†å®ŒæˆERM ===
        condition_11 = (
            cond.procurement_not_error &
            cond.no_status &
            cond.out_of_date_range &
            (df['Received Quantity'].astype('Float64') != 0) &
            (~cond.quantity_matched)
        )
        df.loc[condition_11, 'POç‹€æ…‹'] = 'éƒ¨åˆ†å®ŒæˆERM'
        self._log_condition_result("éƒ¨åˆ†å®ŒæˆERM", condition_11.sum())
        
        return df
    
    def _log_condition_result(self, condition_name: str, count: int):
        """è¨˜éŒ„æ¢ä»¶åˆ¤æ–·çµæœ"""
        if count > 0:
            self.logger.debug(f"æ¢ä»¶ [{condition_name}]: {count} ç­†ç¬¦åˆ")
    
    # ========== éšæ®µ 4: è™•ç†æ ¼å¼éŒ¯èª¤ ==========
    
    def _handle_format_errors(self, df: pd.DataFrame, 
                              cond: ERMConditions) -> pd.DataFrame:
        """è™•ç†æ ¼å¼éŒ¯èª¤çš„è¨˜éŒ„"""
        mask_format_error = cond.no_status & cond.format_error
        df.loc[mask_format_error, 'POç‹€æ…‹'] = 'æ ¼å¼éŒ¯èª¤ï¼Œé€€å–®'
        
        error_count = mask_format_error.sum()
        if error_count > 0:
            self.logger.warning(f"ç™¼ç¾ {error_count} ç­†æ ¼å¼éŒ¯èª¤")
        
        return df
    
    # ========== éšæ®µ 5: è¨­ç½®æ˜¯å¦ä¼°è¨ˆå…¥å¸³ ==========
    
    def _set_accrual_flag(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        æ ¹æ“š POç‹€æ…‹ è¨­ç½®æ˜¯å¦ä¼°è¨ˆå…¥å¸³
        
        SPX é‚è¼¯ï¼šåªæœ‰ã€Œå·²å®Œæˆã€ç‹€æ…‹éœ€è¦ä¼°åˆ—å…¥å¸³
        """
        mask_completed = df['POç‹€æ…‹'].str.contains('å·²å®Œæˆ', na=False)
        
        df.loc[mask_completed, 'æ˜¯å¦ä¼°è¨ˆå…¥å¸³'] = 'Y'
        df.loc[~mask_completed, 'æ˜¯å¦ä¼°è¨ˆå…¥å¸³'] = 'N'
        
        accrual_count = mask_completed.sum()
        self.logger.info(f"è¨­ç½®ä¼°åˆ—æ¨™è¨˜ï¼š{accrual_count} ç­†éœ€ä¼°åˆ—")
        
        return df
    
    # ========== éšæ®µ 6: è¨­ç½®æœƒè¨ˆæ¬„ä½ ==========
    
    def _set_accounting_fields(self, df: pd.DataFrame,
                               ref_account: pd.DataFrame,
                               ref_liability: pd.DataFrame) -> pd.DataFrame:
        """è¨­ç½®æ‰€æœ‰æœƒè¨ˆç›¸é—œæ¬„ä½"""
        
        need_accrual = df['æ˜¯å¦ä¼°è¨ˆå…¥å¸³'] == 'Y'
        
        # 1. Account code
        df.loc[need_accrual, 'Account code'] = df.loc[need_accrual, 'GL#']
        
        # 2. Account Nameï¼ˆé€šé mergeï¼‰
        df = self._set_account_name(df, ref_account, need_accrual)
        
        # 3. Product code
        df.loc[need_accrual, 'Product code'] = df.loc[need_accrual, 'Product Code']
        
        # 4. Region_cï¼ˆSPX å›ºå®šå€¼ï¼‰
        df.loc[need_accrual, 'Region_c'] = "TW"
        
        # 5. Dep.ï¼ˆéƒ¨é–€ä»£ç¢¼ï¼‰
        df = self._set_department(df, need_accrual)
        
        # 6. Currency_c
        df.loc[need_accrual, 'Currency_c'] = df.loc[need_accrual, 'Currency']
        
        # 7. Accr. Amountï¼ˆé ä¼°é‡‘é¡ï¼‰
        df = self._calculate_accrual_amount(df, need_accrual)
        
        # 8. é ä»˜æ¬¾è™•ç†
        df = self._handle_prepayment(df, need_accrual, ref_liability)
        
        self.logger.info("æœƒè¨ˆæ¬„ä½è¨­ç½®å®Œæˆ")
        
        return df
    
    def _set_account_name(self, df: pd.DataFrame, ref_account: pd.DataFrame,
                          mask: pd.Series) -> pd.DataFrame:
        """è¨­ç½®æœƒè¨ˆç§‘ç›®åç¨±"""
        if ref_account.empty:
            self.logger.warning("åƒè€ƒç§‘ç›®è³‡æ–™ç‚ºç©º")
            return df
        
        # ä½¿ç”¨ merge å¾åƒè€ƒè³‡æ–™å–å¾—ç§‘ç›®åç¨±
        merged = pd.merge(
            df, 
            ref_account[['Account', 'Account Desc']],
            how='left',
            left_on='Account code',
            right_on='Account'
        )
        
        df['Account Name'] = merged['Account Desc']
        
        return df
    
    def _set_department(self, df: pd.DataFrame, mask: pd.Series) -> pd.DataFrame:
        """
        è¨­ç½®éƒ¨é–€ä»£ç¢¼
        
        è¦å‰‡ï¼š
        - å¦‚æœç§‘ç›®åœ¨ dept_accounts æ¸…å–®ä¸­ï¼Œå– Department å‰3ç¢¼
        - å¦å‰‡è¨­ç‚º '000'
        """
        isin_dept = df['Account code'].astype('string').isin(
            [str(x) for x in self.dept_accounts]
        )
        
        # åœ¨ dept_accounts ä¸­çš„ç§‘ç›®
        df.loc[mask & isin_dept, 'Dep.'] = \
            df.loc[mask & isin_dept, 'Department'].str[:3]
        
        # ä¸åœ¨ dept_accounts ä¸­çš„ç§‘ç›®
        df.loc[mask & ~isin_dept, 'Dep.'] = '000'
        
        return df
    
    def _calculate_accrual_amount(self, df: pd.DataFrame, 
                                  mask: pd.Series) -> pd.DataFrame:
        """
        è¨ˆç®—é ä¼°é‡‘é¡
        
        å…¬å¼ï¼šUnit Price Ã— (Entry Quantity - Billed Quantity)
        """
        df['temp_amount'] = (
            df['Unit Price'].astype('Float64') * 
            (df['Entry Quantity'].astype('Float64') - 
             df['Billed Quantity'].astype('Float64'))
        )
        
        df.loc[mask, 'Accr. Amount'] = df.loc[mask, 'temp_amount']
        df.drop('temp_amount', axis=1, inplace=True)
        
        return df
    
    def _handle_prepayment(self, df: pd.DataFrame, mask: pd.Series,
                           ref_liability: pd.DataFrame) -> pd.DataFrame:
        """
        è™•ç†é ä»˜æ¬¾å’Œè² å‚µç§‘ç›®
        
        è¦å‰‡ï¼š
        - æœ‰é ä»˜æ¬¾ï¼šæ˜¯å¦æœ‰é ä»˜ = 'Y'ï¼ŒLiability = '111112'
        - ç„¡é ä»˜æ¬¾ï¼šå¾åƒè€ƒè³‡æ–™æŸ¥æ‰¾ Liability
        """
        is_prepayment = df['Entry Prepay Amount'] != '0'
        df.loc[mask & is_prepayment, 'æ˜¯å¦æœ‰é ä»˜'] = 'Y'
        
        # è¨­ç½® Liabilityï¼ˆç„¡é ä»˜æ¬¾çš„æƒ…æ³ï¼‰
        if not ref_liability.empty:
            merged = pd.merge(
                df,
                ref_liability[['Account', 'Liability']],
                how='left',
                left_on='Account code',
                right_on='Account'
            )
            df['Liability'] = merged['Liability_y']
        
        # æœ‰é ä»˜æ¬¾çš„æƒ…æ³ï¼Œè¦†è“‹ç‚º '111112'
        df.loc[mask & is_prepayment, 'Liability'] = '111112'
        
        return df
    
    # ========== éšæ®µ 7: PR Product Code æª¢æŸ¥ ==========
    
    def _check_pr_product_code(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        æª¢æŸ¥ PR çš„ Product Code æ˜¯å¦èˆ‡ Project ä¸€è‡´
        
        è¦å‰‡ï¼š
        å¾ Project æ¬„ä½æå–ç¬¬ä¸€å€‹è©ï¼Œèˆ‡ Product code æ¯”å°
        - ä¸€è‡´ï¼šgood
        - ä¸ä¸€è‡´ï¼šbad
        """
        if 'Product code' not in df.columns or 'Project' not in df.columns:
            self.logger.warning("ç¼ºå°‘ Product code æˆ– Project æ¬„ä½ï¼Œè·³éæª¢æŸ¥")
            return df
        
        mask = df['Product code'].notnull()
        
        try:
            # æå– Project çš„ç¬¬ä¸€å€‹è©
            project_first_word = df.loc[mask, 'Project'].str.findall(
                r'^(\w+(?:))'
            ).apply(lambda x: x[0] if len(x) > 0 else '')
            
            # æ¯”å°
            product_match = (project_first_word == df.loc[mask, 'Product code'])
            
            df.loc[mask, 'PR Product Code Check'] = np.where(
                product_match, 'good', 'bad'
            )
            
            bad_count = (~product_match).sum()
            if bad_count > 0:
                self.logger.warning(f"ç™¼ç¾ {bad_count} ç­† PR Product Code ä¸ä¸€è‡´")
                
        except Exception as e:
            self.logger.error(f"PR Product Code æª¢æŸ¥å¤±æ•—: {str(e)}")
        
        return df
    
    # ========== è¼”åŠ©æ–¹æ³• ==========
    
    def _generate_statistics(self, df: pd.DataFrame) -> Dict[str, Any]:
        """ç”Ÿæˆçµ±è¨ˆè³‡è¨Š"""
        stats = {
            'total_count': len(df),
            'accrual_count': (df['æ˜¯å¦ä¼°è¨ˆå…¥å¸³'] == 'Y').sum(),
            'status_distribution': {}
        }
        
        if 'POç‹€æ…‹' in df.columns:
            status_counts = df['POç‹€æ…‹'].value_counts().to_dict()
            stats['status_distribution'] = {
                str(k): int(v) for k, v in status_counts.items()
            }
        
        return stats
    
    # ========== é©—è­‰æ–¹æ³• ==========
    
    async def validate_input(self, context: ProcessingContext) -> bool:
        """é©—è­‰è¼¸å…¥æ•¸æ“š"""
        df = context.data
        
        if df is None or df.empty:
            self.logger.error("è¼¸å…¥æ•¸æ“šç‚ºç©º")
            context.add_error("è¼¸å…¥æ•¸æ“šç‚ºç©º")
            return False
        
        # æª¢æŸ¥å¿…è¦æ¬„ä½
        required_columns = [
            'GL#', 'Expected Received Month_è½‰æ›æ ¼å¼',
            'YMs of Item Description', 'Entry Quantity',
            'Received Quantity', 'Billed Quantity',
            'Entry Amount', 'Entry Billed Amount',
            'Item Description', 'Remarked by Procurement',
            'Remarked by ä¸Šæœˆ FN', 'Unit Price', 'Currency',
            'Product Code'
        ]
        
        missing = [col for col in required_columns if col not in df.columns]
        
        if missing:
            self.logger.error(f"ç¼ºå°‘å¿…è¦æ¬„ä½: {missing}")
            context.add_error(f"ç¼ºå°‘å¿…è¦æ¬„ä½: {missing}")
            return False
        
        # æª¢æŸ¥åƒè€ƒæ•¸æ“š
        ref_account = context.get_auxiliary_data('reference_account')
        ref_liability = context.get_auxiliary_data('reference_liability')
        
        if ref_account is None or ref_liability is None:
            self.logger.error("ç¼ºå°‘åƒè€ƒæ•¸æ“š")
            context.add_error("ç¼ºå°‘åƒè€ƒæ•¸æ“š")
            return False
        
        # æª¢æŸ¥è™•ç†æ—¥æœŸ
        processing_date = context.get_variable('processing_date')
        if processing_date is None:
            self.logger.error("ç¼ºå°‘è™•ç†æ—¥æœŸ")
            context.add_error("ç¼ºå°‘è™•ç†æ—¥æœŸ")
            return False
        
        self.logger.info("è¼¸å…¥é©—è­‰é€šé")
        return True
    
    async def rollback(self, context: ProcessingContext, error: Exception):
        """å›æ»¾æ“ä½œï¼ˆå¦‚éœ€è¦ï¼‰"""
        self.logger.warning(f"å›æ»¾ ERM é‚è¼¯ï¼š{str(error)}")
        # SPX ERM æ­¥é©Ÿé€šå¸¸ä¸éœ€è¦ç‰¹æ®Šå›æ»¾æ“ä½œ


class PPEContractDateUpdateStep(PipelineStep):
    """
    PPE åˆç´„æ—¥æœŸæ›´æ–°æ­¥é©Ÿ
    
    åŠŸèƒ½ï¼š
    çµ±ä¸€åŒä¸€åº—è™Ÿï¼ˆsp_codeï¼‰çš„åˆç´„èµ·æ­¢æ—¥æœŸ
    """
    
    def __init__(self, name: str = "PPEContractDateUpdate", **kwargs):
        super().__init__(name, description="Update contract dates", **kwargs)
    
    async def execute(self, context: ProcessingContext) -> StepResult:
        """åŸ·è¡Œæ—¥æœŸæ›´æ–°"""
        start_time = datetime.now()
        
        try:
            df = context.data.copy()
            
            # æ›´æ–°åˆç´„æ—¥æœŸ
            df_updated = self._update_contract_dates(df)
            
            context.update_data(df_updated)
            
            duration = (datetime.now() - start_time).total_seconds()
            
            return StepResult(
                step_name=self.name,
                status=StepStatus.SUCCESS,
                data=df_updated,
                message="åˆç´„æ—¥æœŸæ›´æ–°å®Œæˆ",
                duration=duration
            )
            
        except Exception as e:
            self.logger.error(f"æ—¥æœŸæ›´æ–°å¤±æ•—: {str(e)}", exc_info=True)
            return StepResult(
                step_name=self.name,
                status=StepStatus.FAILED,
                error=e,
                message=str(e)
            )
    
    def _update_contract_dates(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ›´æ–°åˆç´„æ—¥æœŸï¼ˆè¤‡è£½è‡ª SpxPpeProcessorï¼‰"""
        df_updated = df.copy()
        
        # è½‰æ›æ—¥æœŸæ ¼å¼
        date_columns = [
            'contract_start_day_filing', 
            'contract_end_day_filing',
            'contract_start_day_renewal', 
            'contract_end_day_renewal'
        ]
        
        for col in date_columns:
            if col in df_updated.columns:
                df_updated[col] = pd.to_datetime(df_updated[col], errors='coerce')
        
        # æŒ‰ sp_code åˆ†çµ„æ›´æ–°
        for sp_code in df_updated['sp_code'].unique():
            mask = df_updated['sp_code'] == sp_code
            sp_data = df_updated[mask]
            
            # æ”¶é›†æ‰€æœ‰æ—¥æœŸ
            start_dates = []
            end_dates = []
            
            for col in ['contract_start_day_filing', 'contract_start_day_renewal']:
                if col in df_updated.columns:
                    dates = sp_data[col].dropna().tolist()
                    start_dates.extend(dates)
            
            for col in ['contract_end_day_filing', 'contract_end_day_renewal']:
                if col in df_updated.columns:
                    dates = sp_data[col].dropna().tolist()
                    end_dates.extend(dates)
            
            # æ›´æ–°ç‚ºæœ€å°èµ·å§‹æ—¥å’Œæœ€å¤§çµæŸæ—¥
            if start_dates:
                min_start = min(start_dates)
                for col in ['contract_start_day_filing', 'contract_start_day_renewal']:
                    if col in df_updated.columns:
                        df_updated.loc[mask, col] = min_start
            
            if end_dates:
                max_end = max(end_dates)
                for col in ['contract_end_day_filing', 'contract_end_day_renewal']:
                    if col in df_updated.columns:
                        df_updated.loc[mask, col] = max_end
        
        return df_updated.drop_duplicates()

    async def validate_input(self, context: ProcessingContext) -> bool:
        """é©—è­‰è¼¸å…¥"""
        if context.data is None or context.data.empty:
            self.logger.error("No data for update")
            return False
        
        return True

class PPEMonthDifferenceStep(PipelineStep):
    """
    PPE æœˆä»½å·®ç•°è¨ˆç®—æ­¥é©Ÿ
    
    åŠŸèƒ½ï¼š
    è¨ˆç®—åˆç´„çµæŸæ—¥æœŸèˆ‡ç•¶å‰æœˆä»½çš„å·®ç•°
    """
    
    def __init__(self, 
                 name: str = "PPEMonthDifference",
                 current_month: int = None,
                 **kwargs):
        super().__init__(name, description="Calculate month difference", **kwargs)
        self.current_month = current_month
    
    async def execute(self, context: ProcessingContext) -> StepResult:
        """åŸ·è¡Œæœˆä»½å·®ç•°è¨ˆç®—"""
        start_time = datetime.now()
        
        try:
            df = context.data.copy()
            
            # ç²å–ç•¶å‰æœˆä»½
            current_month = (self.current_month or 
                             context.get_variable('current_month'))
            
            if not current_month:
                raise ValueError("æœªæä¾›ç•¶å‰æœˆä»½åƒæ•¸")
            
            # é¸æ“‡å¿…è¦æ¬„ä½
            selected_cols = [
                'sp_code', 
                'address', 
                'contract_start_day_filing', 
                'contract_end_day_renewal'
            ]
            
            # è¨ˆç®—æœˆä»½å·®ç•°
            df_result = self._calculate_month_difference(
                df[selected_cols],
                'contract_end_day_renewal',
                current_month
            )
            
            # æ–°å¢æˆªæ–·åœ°å€æ¬„ä½ï¼ˆç”¨æ–¼åœ°å€æ¨¡ç³ŠåŒ¹é…ï¼‰
            df_result['truncated_address'] = df_result['address'].apply(
                self._truncate_address_at_hao
            )
            
            context.update_data(df_result)
            
            duration = (datetime.now() - start_time).total_seconds()
            
            metadata = (StepMetadataBuilder()
                        .set_row_counts(len(df), len(df_result))
                        .set_time_info(start_time, datetime.now())
                        .add_custom('current_month', current_month)
                        .add_custom('average_months_diff', 
                                    float(df_result['months_diff'].mean()))
                        .build())
            
            return StepResult(
                step_name=self.name,
                status=StepStatus.SUCCESS,
                data=df_result,
                message=f"æœˆä»½å·®ç•°è¨ˆç®—å®Œæˆ: ç•¶å‰æœˆä»½ {current_month}",
                duration=duration,
                metadata=metadata
            )
            
        except Exception as e:
            self.logger.error(f"æœˆä»½å·®ç•°è¨ˆç®—å¤±æ•—: {str(e)}", exc_info=True)
            return StepResult(
                step_name=self.name,
                status=StepStatus.FAILED,
                error=e,
                message=str(e)
            )
    
    def _calculate_month_difference(self, df: pd.DataFrame, 
                                    date_column: str, 
                                    target_ym: int) -> pd.DataFrame:
        """è¨ˆç®—æœˆä»½å·®ç•°"""
        df_result = df.copy()
        
        # ç¢ºä¿æ—¥æœŸæ ¼å¼
        df_result[date_column] = pd.to_datetime(df_result[date_column])
        
        # ç›®æ¨™æ—¥æœŸ
        target_year = target_ym // 100
        target_month = target_ym % 100
        target_date = datetime(target_year, target_month, 1)
        
        # è¨ˆç®—å·®ç•°
        def months_difference(date1, date2):
            return (date1.year - date2.year) * 12 + (date1.month - date2.month)
        
        df_result['months_diff'] = df_result[date_column].apply(
            lambda x: months_difference(x, target_date)
        ).add(1)
        
        return df_result
    
    def _truncate_address_at_hao(self, address: str) -> str:
        """æˆªæ–·åœ°å€åˆ°ã€Œè™Ÿã€"""
        if not isinstance(address, str):
            return address
        
        pattern = r'^.*?è™Ÿ'
        match = re.search(pattern, address)
        return match.group(0) if match else address

    async def validate_input(self, context: ProcessingContext) -> bool:
        """é©—è­‰è¼¸å…¥"""
        if context.data is None or context.data.empty:
            self.logger.error("No data for calculating difference")
            return False
        
        return True