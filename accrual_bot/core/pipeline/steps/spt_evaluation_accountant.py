import time
import pandas as pd
from typing import Dict, Any
from datetime import datetime
from dataclasses import dataclass

from accrual_bot.core.pipeline.base import PipelineStep, StepResult, StepStatus
from accrual_bot.core.pipeline.context import ProcessingContext
from accrual_bot.core.pipeline.steps.common import StepMetadataBuilder, create_error_metadata
from accrual_bot.utils.config import config_manager


@dataclass
class SPTStatusLabelConditions:
    """æœƒè¨ˆæ¨™ç±¤åˆ¤æ–·æ¢ä»¶é›†åˆ - æé«˜å¯è®€æ€§"""

    # Item Description é—œéµå­—æ¢ä»¶
    has_ssp: pd.Series
    has_logistics_fee: pd.Series
    has_handling_fee: pd.Series
    has_remittance_fee: pd.Series
    has_shipping_fee: pd.Series
    has_hidden_code_fee: pd.Series
    has_commissions: pd.Series
    has_seller_affiliate: pd.Series
    has_refund: pd.Series
    has_service_charges: pd.Series

    # Department å’Œ Supplier çµ„åˆæ¢ä»¶
    tradewan_non_g21: pd.Series
    tradewan_g21: pd.Series
    jianqiang_non_mkt: pd.Series
    jianqiang_mkt: pd.Series

    # Department ç‰¹å®šæ¢ä»¶
    g44_telecom: pd.Series

    # Supplier ç‰¹å®šæ¢ä»¶
    ctbc_bank: pd.Series

    # Requester çµ„åˆæ¢ä»¶
    sherry_wu_s01: pd.Series
    chen_hung_i_g42_twn: pd.Series

    # Supplier + Item Description çµ„åˆæ¢ä»¶
    welfare_fund: pd.Series
    cobranded_card: pd.Series
    rent_global_life: pd.Series
    rent_taipei_wenchuang: pd.Series
    rent_united_daily: pd.Series


class SPTStatusLabelStep(PipelineStep):
    """
    æœƒè¨ˆæ¨™ç±¤æ¨™è¨˜æ­¥é©Ÿ

    æ¥­å‹™é‚è¼¯:
    1. æ ¹æ“šé…ç½®æª”æ¡ˆä¸­çš„è¦å‰‡æ¨™è¨˜æœƒè¨ˆæ¨™ç±¤
    2. å„ªå…ˆç´šæ¢ä»¶ï¼šæ›´æ–° POç‹€æ…‹ å’Œ Remarked by FNï¼ˆå¼·åˆ¶è¦†è“‹ï¼‰
    3. ERMæ¢ä»¶ï¼šåƒ…æ›´æ–° Remarked by FNï¼ˆä¸æ›´æ–°ç‹€æ…‹ï¼Œä¼°è¨ˆèˆ‡å¦ç”±ERMæ±ºå®šï¼‰

    é…ç½®ä¾†æº:
    - [spt_status_label_rules.priority_conditions]: å„ªå…ˆæ–¼ERMçš„æ¢ä»¶
    - [spt_status_label_rules.erm_conditions]: ERMæ¢ä»¶

    è¼¸å…¥:
    - DataFrame with required columns

    è¼¸å‡º:
    - DataFrame with updated labels
    """

    def __init__(self,
                 name: str = "Accounting_Label_Marking",
                 status_column: str = "POç‹€æ…‹",
                 remark_column: str = "Remarked by FN",
                 **kwargs):
        """
        åˆå§‹åŒ–æœƒè¨ˆæ¨™ç±¤æ¨™è¨˜æ­¥é©Ÿ

        Args:
            name: æ­¥é©Ÿåç¨±
            status_column: ç‹€æ…‹æ¬„ä½åç¨±ï¼ˆé è¨­ç‚º POç‹€æ…‹ï¼‰
            remark_column: å‚™è¨»æ¬„ä½åç¨±ï¼ˆé è¨­ç‚º Remarked by FNï¼‰
        """
        super().__init__(
            name=name,
            description="Mark accounting labels based on business rules",
            **kwargs
        )
        self.status_column = status_column
        self.remark_column = remark_column

        # å¾é…ç½®æª”æ¡ˆè®€å–è¦å‰‡
        self.priority_rules = self._load_priority_rules()
        self.erm_rules = self._load_erm_rules()

        self.logger.info(f"å·²è¼‰å…¥ {len(self.priority_rules)} å€‹å„ªå…ˆç´šè¦å‰‡")
        self.logger.info(f"å·²è¼‰å…¥ {len(self.erm_rules)} å€‹ ERM è¦å‰‡")

    def _load_priority_rules(self) -> Dict[str, Dict[str, Any]]:
        """å¾é…ç½®æª”æ¡ˆè¼‰å…¥å„ªå…ˆç´šè¦å‰‡"""
        try:
            rules = config_manager._config_toml.get('spt_status_label_rules', {}).get('priority_conditions', {})
            return dict(rules) if rules else {}
        except Exception as e:
            self.logger.error(f"è¼‰å…¥å„ªå…ˆç´šè¦å‰‡å¤±æ•—: {str(e)}")
            return {}

    def _load_erm_rules(self) -> Dict[str, Dict[str, Any]]:
        """å¾é…ç½®æª”æ¡ˆè¼‰å…¥ ERM è¦å‰‡"""
        try:
            rules = config_manager._config_toml.get('spt_status_label_rules', {}).get('erm_conditions', {})
            return dict(rules) if rules else {}
        except Exception as e:
            self.logger.error(f"è¼‰å…¥ ERM è¦å‰‡å¤±æ•—: {str(e)}")
            return {}

    async def execute(self, context: ProcessingContext) -> StepResult:
        """åŸ·è¡Œæœƒè¨ˆæ¨™ç±¤æ¨™è¨˜é‚è¼¯"""
        start_time = time.time()
        start_datetime = datetime.now()

        try:
            df = context.data.copy()
            input_count = len(df)

            self.logger.info("=" * 60)
            self.logger.info("ğŸ·ï¸  é–‹å§‹åŸ·è¡Œæœƒè¨ˆæ¨™ç±¤æ¨™è¨˜...")
            self.logger.info(f"ğŸ“Š ç¸½è¨˜éŒ„æ•¸: {input_count:,}")
            self.logger.info("=" * 60)

            # å‹•æ…‹åˆ¤æ–·ç‹€æ…‹æ¬„ä½åç¨±
            self.status_column = self._get_status_column(df)

            # === éšæ®µ 1: æ§‹å»ºæ¢ä»¶ ===
            self.logger.info("ğŸ” æ§‹å»ºåˆ¤æ–·æ¢ä»¶...")
            conditions = self._build_conditions(df)

            # === éšæ®µ 2: æ‡‰ç”¨å„ªå…ˆç´šæ¢ä»¶ ===
            self.logger.info("âš¡ æ‡‰ç”¨å„ªå…ˆç´šæ¢ä»¶ï¼ˆå¼·åˆ¶è¦†è“‹ï¼‰...")
            priority_stats = self._apply_priority_conditions(df, conditions)

            # === éšæ®µ 3: æ‡‰ç”¨ ERM æ¢ä»¶ ===
            self.logger.info("ğŸ“‹ æ‡‰ç”¨ ERM æ¢ä»¶ï¼ˆåƒ…æ¨™è¨˜å‚™è¨»ï¼‰...")
            erm_stats = self._apply_erm_conditions(df, conditions)

            # === éšæ®µ 4: ç”Ÿæˆçµ±è¨ˆè³‡è¨Š ===
            total_labeled = sum(priority_stats.values()) + sum(erm_stats.values())

            statistics = {
                'total_records': input_count,
                'priority_labeled': sum(priority_stats.values()),
                'erm_labeled': sum(erm_stats.values()),
                'total_labeled': total_labeled,
                'label_rate': f"{(total_labeled / input_count * 100):.2f}%" if input_count > 0 else "0.00%",
                'priority_breakdown': priority_stats,
                'erm_breakdown': erm_stats
            }

            # === éšæ®µ 5: è¨˜éŒ„è©³ç´°æ—¥èªŒ ===
            self._log_detailed_statistics(statistics)

            # === éšæ®µ 6: æ›´æ–°ä¸Šä¸‹æ–‡ ===
            context.update_data(df)

            duration = time.time() - start_time
            end_datetime = datetime.now()

            self.logger.info("=" * 60)
            self.logger.info(f"âœ… æœƒè¨ˆæ¨™ç±¤æ¨™è¨˜å®Œæˆ (è€—æ™‚: {duration:.2f}ç§’)")
            self.logger.info("=" * 60)

            # æ§‹å»º metadata
            metadata = (StepMetadataBuilder()
                        .set_row_counts(input_count, len(df))
                        .set_process_counts(processed=total_labeled, skipped=input_count - total_labeled)
                        .set_time_info(start_datetime, end_datetime)
                        .add_custom('priority_labeled', sum(priority_stats.values()))
                        .add_custom('erm_labeled', sum(erm_stats.values()))
                        .add_custom('statistics', statistics)
                        .build())

            return StepResult(
                step_name=self.name,
                status=StepStatus.SUCCESS,
                data=df,
                message='-'.join([f"å·²æ¨™è¨˜ {total_labeled:,} ç­†è¨˜éŒ„\n",
                                 f"\t(å„ªå…ˆç´š: {sum(priority_stats.values()):,}, ERM: {sum(erm_stats.values()):,})"]),
                duration=duration,
                metadata=metadata
            )

        except Exception as e:
            duration = time.time() - start_time
            self.logger.error(f"âŒ æœƒè¨ˆæ¨™ç±¤æ¨™è¨˜å¤±æ•—: {str(e)}", exc_info=True)
            context.add_error(f"Accounting label marking failed: {str(e)}")

            error_metadata = create_error_metadata(
                e, context, self.name,
                stage='accounting_label_marking'
            )

            return StepResult(
                step_name=self.name,
                status=StepStatus.FAILED,
                error=e,
                message=f"æœƒè¨ˆæ¨™ç±¤æ¨™è¨˜å¤±æ•—: {str(e)}",
                duration=duration,
                metadata=error_metadata
            )

    def _get_status_column(self, df: pd.DataFrame) -> str:
        """å‹•æ…‹åˆ¤æ–·ç‹€æ…‹æ¬„ä½åç¨±"""
        if 'POç‹€æ…‹' in df.columns:
            return 'POç‹€æ…‹'
        elif 'PRç‹€æ…‹' in df.columns:
            return 'PRç‹€æ…‹'
        else:
            # å¦‚æœéƒ½ä¸å­˜åœ¨ï¼Œå‰µå»º POç‹€æ…‹ æ¬„ä½
            df['POç‹€æ…‹'] = pd.NA
            return 'POç‹€æ…‹'

    def _build_conditions(self, df: pd.DataFrame) -> SPTStatusLabelConditions:
        """
        æ§‹å»ºæ‰€æœ‰åˆ¤æ–·æ¢ä»¶

        å°‡æ¢ä»¶é‚è¼¯é›†ä¸­åœ¨æ­¤è™•ï¼Œæé«˜å¯è®€æ€§å’Œç¶­è­·æ€§
        """

        # === Item Description é—œéµå­—æ¢ä»¶ ===
        item_desc = df.get('Item Description', pd.Series(dtype=str))

        has_ssp = item_desc.str.contains(r'(?i)SSP', na=False, regex=True)
        has_logistics_fee = item_desc.str.contains(r'(?i)Logistics fee|Logistic fee', na=False, regex=True)
        has_handling_fee = item_desc.str.contains(r'(?i)Handling fee', na=False, regex=True)
        has_remittance_fee = item_desc.str.contains(r'(?i)Remittance fee', na=False, regex=True)
        has_shipping_fee = item_desc.str.contains(r'(?i)shipping fee', na=False, regex=True)
        has_hidden_code_fee = item_desc.str.contains(r'ç‰©æµéš±ç¢¼è²»|éš±ç¢¼è²»', na=False, regex=True)
        has_commissions = item_desc.str.contains(r'(?i)Commissions', na=False, regex=True)
        has_seller_affiliate = item_desc.str.contains(r'(?i)Seller affiliate', na=False, regex=True)
        has_refund = item_desc.str.contains(r'(?i)refund', na=False, regex=True)
        has_service_charges = item_desc.str.contains(r'(?i)service charges', na=False, regex=True)

        # === Department å’Œ Supplier çµ„åˆæ¢ä»¶ ===
        dept = df.get('Department', pd.Series(dtype=str))
        supplier_col: str = df.filter(regex='(?i)supplier').columns[0]
        supplier = df.get(supplier_col, pd.Series(dtype=str))

        # é—œè²¿ç¶²è·¯æ¢ä»¶
        is_tradewan = supplier == 'TW_é—œè²¿ç¶²è·¯è‚¡ä»½æœ‰é™å…¬å¸'
        dept_starts_g21 = dept.str.startswith('G21', na=False)
        tradewan_non_g21 = is_tradewan & (~dept_starts_g21)
        tradewan_g21 = is_tradewan & dept_starts_g21

        # æ¼¸å¼·è³´ä¼¯æ¢ä»¶
        is_jianqiang = supplier == 'TW_æ¼¸å¼·è³´ä¼¯è‚¡ä»½æœ‰é™å…¬å¸'
        dept_has_mkt = dept.str.contains(r'(?i)Marketing', na=False, regex=True)
        jianqiang_non_mkt = is_jianqiang & (~dept_has_mkt)
        jianqiang_mkt = is_jianqiang & dept_has_mkt

        # === Department ç‰¹å®šæ¢ä»¶ ===
        g44_telecom = (
            (dept == 'G44 - Corporate IT (BE)') &
            item_desc.str.contains(r'é›»ä¿¡è²»|é€šä¿¡è²»|æœˆç§Ÿè²»|é€šè©±è²»|ç°¡è¨Š|è¡Œå‹•ä¸Šç¶²', na=False, regex=True)
        )

        # === Supplier ç‰¹å®šæ¢ä»¶ ===
        ctbc_bank = supplier == 'TW_ä¸­åœ‹ä¿¡è¨—å•†æ¥­éŠ€è¡Œè‚¡ä»½æœ‰é™å…¬å¸'

        # === Requester çµ„åˆæ¢ä»¶ ===
        requester_col: str = df.filter(regex='(?i)requester').columns[0]
        requester = df.get(requester_col, pd.Series(dtype=str))

        # Sherry Wu + S01
        is_sherry = (requester == 'Sherry Wu (å³æ¬£æ€¡)')
        sherry_wu_s01 = is_sherry & (dept == 'S01 - Marketing & Publishing')

        # Chen Hung I + G42 + å°ç£å›ºç¶²
        is_chen = (requester == 'Chen Hung I (é™³è™¹æ²‚)')
        chen_hung_i_g42_twn = (
            is_chen &
            (dept == 'G42 - Corporate Infrastructure') &
            (supplier == 'TW_å°ç£å›ºç¶²è‚¡ä»½æœ‰é™å…¬å¸')
        )

        # === Supplier + Item Description çµ„åˆæ¢ä»¶ ===

        # ç¦å§”æœƒ + Employee welfare fund
        welfare_fund = (
            (supplier == 'TW_æ–°åŠ å¡å•†è¦çš®å¨›æ¨‚é›»å•†æœ‰é™å…¬å¸å°ç£åˆ†å…¬å¸è¯åˆè·å·¥ç¦åˆ©å§”å“¡æœƒ') &
            item_desc.str.contains(r'(?i)Employee welfare fund', na=False, regex=True)
        )

        # åœ‹æ³°ä¸–è¯ + è¯åå¡
        cobranded_card = (
            (supplier == 'TW_åœ‹æ³°ä¸–è¯å•†æ¥­éŠ€è¡Œä¿¡ç”¨å¡ä½œæ¥­éƒ¨') &
            item_desc.str.contains(r'(?i)Co-Branded Card Campaign Fee è¯åå¡', na=False, regex=True)
        )

        # ç§Ÿé‡‘æ¢ä»¶
        rent_global_life = (
            (supplier == 'TW_å…¨çƒäººå£½ä¿éšªè‚¡ä»½æœ‰é™å…¬å¸') &
            item_desc.str.contains(r'è¾¦å…¬å®¤ç§Ÿ', na=False, regex=True)
        )

        rent_taipei_wenchuang = (
            (supplier == 'TW_è‡ºåŒ—æ–‡å‰µé–‹ç™¼è‚¡ä»½æœ‰é™å…¬å¸') &
            item_desc.str.contains(r'è¾¦å…¬å®¤ç§Ÿ', na=False, regex=True)
        )

        rent_united_daily = (
            (supplier == 'TW_è¯åˆå ±è‚¡ä»½æœ‰é™å…¬å¸') &
            item_desc.str.contains(r'(?i)office rental fee|deposit', na=False, regex=True)
        )

        return SPTStatusLabelConditions(
            has_ssp=has_ssp,
            has_logistics_fee=has_logistics_fee,
            has_handling_fee=has_handling_fee,
            has_remittance_fee=has_remittance_fee,
            has_shipping_fee=has_shipping_fee,
            has_hidden_code_fee=has_hidden_code_fee,
            has_commissions=has_commissions,
            has_seller_affiliate=has_seller_affiliate,
            has_refund=has_refund,
            has_service_charges=has_service_charges,
            tradewan_non_g21=tradewan_non_g21,
            tradewan_g21=tradewan_g21,
            jianqiang_non_mkt=jianqiang_non_mkt,
            jianqiang_mkt=jianqiang_mkt,
            g44_telecom=g44_telecom,
            ctbc_bank=ctbc_bank,
            sherry_wu_s01=sherry_wu_s01,
            chen_hung_i_g42_twn=chen_hung_i_g42_twn,
            welfare_fund=welfare_fund,
            cobranded_card=cobranded_card,
            rent_global_life=rent_global_life,
            rent_taipei_wenchuang=rent_taipei_wenchuang,
            rent_united_daily=rent_united_daily
        )

    def _apply_priority_conditions(self, df: pd.DataFrame,
                                   cond: SPTStatusLabelConditions) -> Dict[str, int]:
        """
        æ‡‰ç”¨å„ªå…ˆç´šæ¢ä»¶ï¼ˆå¼·åˆ¶è¦†è“‹ï¼‰

        æ›´æ–°: POç‹€æ…‹ å’Œ Remarked by FN

        Returns:
            Dict[str, int]: å„æ¢ä»¶çš„åŒ¹é…è¨ˆæ•¸
        """
        stats = {}

        # Blaire ç›¸é—œæ¢ä»¶
        blaire_conditions = [
            ('SSP', cond.has_ssp, 'ä¸ä¼°è¨ˆ(Blaire)', 'Blaire'),
            ('Logistics fee', cond.has_logistics_fee, 'ä¸ä¼°è¨ˆ(Blaire)', 'Blaire'),
            ('Handling fee', cond.has_handling_fee, 'ä¸ä¼°è¨ˆ(Blaire)', 'Blaire'),
            ('Remittance fee', cond.has_remittance_fee, 'ä¸ä¼°è¨ˆ(Blaire)', 'Blaire'),
            ('Shipping fee', cond.has_shipping_fee, 'ä¸ä¼°è¨ˆ(Blaire)', 'Blaire'),
            ('éš±ç¢¼è²»', cond.has_hidden_code_fee, 'ä¸ä¼°è¨ˆ(Blaire)', 'Blaire'),
            ('Commissions', cond.has_commissions, 'ä¸ä¼°è¨ˆ(Blaire)', 'Blaire'),
            ('Seller affiliate', cond.has_seller_affiliate, 'ä¸ä¼°è¨ˆ(Blaire)', 'Blaire'),
            ('Refund', cond.has_refund, 'ä¸ä¼°è¨ˆ(Blaire)', 'Blaire'),
            ('Service charges', cond.has_service_charges, 'ä¸ä¼°è¨ˆ(Blaire)', 'Blaire'),
            ('é—œè²¿(éG21)', cond.tradewan_non_g21, 'ä¸ä¼°è¨ˆ(Blaire)', 'Blaire'),
        ]

        for name, mask, status, remark in blaire_conditions:
            count = mask.sum()
            if count > 0:
                df.loc[mask, self.status_column] = status
                df.loc[mask, self.remark_column] = remark
                self.logger.debug(f"  âœ“ {name}: {count:,} ç­†")
                stats[name] = count

        # Shirley æ¢ä»¶
        if cond.g44_telecom.sum() > 0:
            df.loc[cond.g44_telecom, self.status_column] = 'ä¸ä¼°è¨ˆ(Shirley)'
            df.loc[cond.g44_telecom, self.remark_column] = 'Shirley'
            count = cond.g44_telecom.sum()
            self.logger.debug(f"  âœ“ G44é›»ä¿¡è²»: {count:,} ç­†")
            stats['G44é›»ä¿¡è²»'] = count

        # Cindy æ¢ä»¶
        cindy_conditions = [
            ('ä¸­åœ‹ä¿¡è¨—', cond.ctbc_bank, 'ä¸ä¼°è¨ˆ(Cindy)', 'Cindy'),
            ('Sherry Wuå¾…ç¢ºèª', cond.sherry_wu_s01, 'å¾…ç¢ºèª(Cindy)', 'Cindy'),
        ]

        for name, mask, status, remark in cindy_conditions:
            count = mask.sum()
            if count > 0:
                df.loc[mask, self.status_column] = status
                df.loc[mask, self.remark_column] = remark
                self.logger.debug(f"  âœ“ {name}: {count:,} ç­†")
                stats[name] = count

        # Hosting æ¢ä»¶
        if cond.chen_hung_i_g42_twn.sum() > 0:
            df.loc[cond.chen_hung_i_g42_twn, self.status_column] = 'ä¸ä¼°è¨ˆ(Hosting)'
            df.loc[cond.chen_hung_i_g42_twn, self.remark_column] = 'Hosting'
            count = cond.chen_hung_i_g42_twn.sum()
            self.logger.debug(f"  âœ“ Hosting(å°ç£å›ºç¶²): {count:,} ç­†")
            stats['Hosting'] = count

        # Michael æ¢ä»¶
        michael_conditions = [
            ('ç¦å§”æœƒ', cond.welfare_fund, 'ä¸ä¼°è¨ˆ(Michael)', 'Michael'),
            ('è¯åå¡', cond.cobranded_card, 'ä¸ä¼°è¨ˆ(Michael)', 'Michael'),
        ]

        for name, mask, status, remark in michael_conditions:
            count = mask.sum()
            if count > 0:
                df.loc[mask, self.status_column] = status
                df.loc[mask, self.remark_column] = remark
                self.logger.debug(f"  âœ“ {name}: {count:,} ç­†")
                stats[name] = count

        # ç§Ÿé‡‘æ¢ä»¶
        rent_conditions = [
            ('å…¨çƒäººå£½ç§Ÿé‡‘', cond.rent_global_life, 'ä¸ä¼°è¨ˆ(ç§Ÿé‡‘)', 'ç§Ÿé‡‘'),
            ('è‡ºåŒ—æ–‡å‰µç§Ÿé‡‘', cond.rent_taipei_wenchuang, 'ä¸ä¼°è¨ˆ(ç§Ÿé‡‘)', 'ç§Ÿé‡‘'),
            ('è¯åˆå ±ç§Ÿé‡‘', cond.rent_united_daily, 'ä¸ä¼°è¨ˆ(ç§Ÿé‡‘)', 'ç§Ÿé‡‘'),
        ]

        for name, mask, status, remark in rent_conditions:
            count = mask.sum()
            if count > 0:
                df.loc[mask, self.status_column] = status
                df.loc[mask, self.remark_column] = remark
                self.logger.debug(f"  âœ“ {name}: {count:,} ç­†")
                stats[name] = count

        return stats

    def _apply_erm_conditions(self, df: pd.DataFrame,
                              cond: SPTStatusLabelConditions) -> Dict[str, int]:
        """
        æ‡‰ç”¨ ERM æ¢ä»¶ï¼ˆåƒ…æ›´æ–° Remarked by FNï¼‰

        ä¸æ›´æ–°ç‹€æ…‹ï¼Œä¼°è¨ˆèˆ‡å¦ç”±å¾ŒçºŒ ERM æ­¥é©Ÿæ±ºå®š

        Returns:
            Dict[str, int]: å„æ¢ä»¶çš„åŒ¹é…è¨ˆæ•¸
        """
        stats = {}

        # ERM æ¢ä»¶ï¼šé—œè²¿(G21)
        if cond.tradewan_g21.sum() > 0:
            df.loc[cond.tradewan_g21, self.remark_column] = 'Blaire'
            count = cond.tradewan_g21.sum()
            self.logger.debug(f"  âœ“ é—œè²¿(G21): {count:,} ç­†")
            stats['é—œè²¿(G21)'] = count

        # ERM æ¢ä»¶ï¼šæ¼¸å¼·(éMarketing)
        if cond.jianqiang_non_mkt.sum() > 0:
            df.loc[cond.jianqiang_non_mkt, self.remark_column] = 'Cindy-æ¼¸å¼·'
            count = cond.jianqiang_non_mkt.sum()
            self.logger.debug(f"  âœ“ æ¼¸å¼·(éMKT): {count:,} ç­†")
            stats['æ¼¸å¼·(éMKT)'] = count

        # ERM æ¢ä»¶ï¼šæ¼¸å¼·(Marketing)
        if cond.jianqiang_mkt.sum() > 0:
            df.loc[cond.jianqiang_mkt, self.remark_column] = 'æ¼¸å¼·MKT'
            count = cond.jianqiang_mkt.sum()
            self.logger.debug(f"  âœ“ æ¼¸å¼·(MKT): {count:,} ç­†")
            stats['æ¼¸å¼·(MKT)'] = count

        return stats

    def _log_detailed_statistics(self, stats: Dict[str, Any]):
        """è¨˜éŒ„è©³ç´°çµ±è¨ˆæ—¥èªŒ"""
        self.logger.info("\n" + "=" * 60)
        self.logger.info("ğŸ“Š æœƒè¨ˆæ¨™ç±¤æ¨™è¨˜çµ±è¨ˆå ±å‘Š")
        self.logger.info("=" * 60)
        self.logger.info(f"ğŸ“ˆ ç¸½è¨˜éŒ„æ•¸: {stats['total_records']:,}")
        self.logger.info(f"ğŸ·ï¸  å·²æ¨™è¨˜: {stats['total_labeled']:,} ({stats['label_rate']})")
        self.logger.info(f"   â€¢ å„ªå…ˆç´šæ¢ä»¶: {stats['priority_labeled']:,}")
        self.logger.info(f"   â€¢ ERM æ¢ä»¶: {stats['erm_labeled']:,}")

        if stats['priority_breakdown']:
            self.logger.info("\nğŸ“‹ å„ªå…ˆç´šæ¢ä»¶æ˜ç´°:")
            for label, count in sorted(stats['priority_breakdown'].items()):
                self.logger.info(f"   â€¢ {label}: {count:,}")

        if stats['erm_breakdown']:
            self.logger.info("\nğŸ“‹ ERM æ¢ä»¶æ˜ç´°:")
            for label, count in sorted(stats['erm_breakdown'].items()):
                self.logger.info(f"   â€¢ {label}: {count:,}")

        self.logger.info("=" * 60 + "\n")

    async def validate_input(self, context: ProcessingContext) -> bool:
        """
        é©—è­‰è¼¸å…¥è³‡æ–™çš„å®Œæ•´æ€§

        æª¢æŸ¥é …ç›®:
        1. DataFrame ä¸ç‚ºç©º
        2. å¿…è¦æ¬„ä½å­˜åœ¨
        """
        try:
            df = context.data

            # æª¢æŸ¥ DataFrame
            if df is None or df.empty:
                self.logger.error("âŒ è¼¸å…¥è³‡æ–™ç‚ºç©º")
                return False

            # æª¢æŸ¥å¿…è¦æ¬„ä½ï¼ˆåŸºæœ¬æ¬„ä½ï¼‰
            required_columns = [
                'Item Description',
                'Department',
                'Supplier'
            ]

            missing_columns = [col for col in required_columns if col not in df.columns]
            if missing_columns:
                self.logger.error(f"âŒ ç¼ºå°‘å¿…è¦æ¬„ä½: {missing_columns}")
                return False

            # æª¢æŸ¥æˆ–å‰µå»ºç‹€æ…‹å’Œå‚™è¨»æ¬„ä½
            if self.remark_column not in df.columns:
                self.logger.warning(f"âš ï¸  {self.remark_column} æ¬„ä½ä¸å­˜åœ¨ï¼Œå°‡è‡ªå‹•å‰µå»º")
                df[self.remark_column] = pd.NA

            # ç‹€æ…‹æ¬„ä½æœƒåœ¨ execute ä¸­å‹•æ…‹åˆ¤æ–·

            self.logger.info("âœ… è¼¸å…¥é©—è­‰é€šé")
            return True

        except Exception as e:
            self.logger.error(f"âŒ é©—è­‰å¤±æ•—: {str(e)}", exc_info=True)
            return False

    async def rollback(self, context: ProcessingContext, error: Exception):
        """å›æ»¾æ“ä½œï¼ˆå¦‚éœ€è¦ï¼‰"""
        self.logger.warning(f"å›æ»¾æœƒè¨ˆæ¨™ç±¤æ¨™è¨˜ï¼š{str(error)}")
        # é€šå¸¸ä¸éœ€è¦ç‰¹æ®Šå›æ»¾æ“ä½œ
