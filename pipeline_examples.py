"""
Pipelineä½¿ç”¨ç¯„ä¾‹
å±•ç¤ºå„ç¨®Pipelineçš„ä½¿ç”¨æ–¹æ³•
è‡ªå‹•ç”Ÿæˆæ¸¬è©¦è³‡æ–™ï¼Œç„¡éœ€æ‰‹å‹•æº–å‚™
"""

import asyncio
import pandas as pd
from datetime import datetime
import logging
import sys
import os
from pathlib import Path

# ç¢ºä¿åœ¨æ­£ç¢ºçš„ç›®éŒ„
script_dir = Path(__file__).parent
os.chdir(script_dir)

# æ·»åŠ å°ˆæ¡ˆè·¯å¾‘
if str(script_dir) not in sys.path:
    sys.path.insert(0, str(script_dir))

from accrual_bot.test_data_generator import TestDataGenerator
from pipeline_main import AccrualPipelineManager
from accrual_bot.core.pipeline.context import ProcessingContext
from accrual_bot.core.pipeline.config_manager import PipelineConfigManager
from accrual_bot.core.pipeline.entity_strategies import EntityStrategyFactory
from accrual_bot.core.pipeline.templates import PipelineTemplateManager


# è¨­ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    filename='logs/examples_pipeline.log'
)


async def setup_test_data():
    """
    è¨­ç½®æ¸¬è©¦è³‡æ–™
    åœ¨åŸ·è¡Œç¯„ä¾‹å‰è‡ªå‹•ç”Ÿæˆæ‰€éœ€çš„æ¸¬è©¦è³‡æ–™
    """
    print("\n" + "=" * 60)
    print("æº–å‚™æ¸¬è©¦ç’°å¢ƒ...")
    print("=" * 60)
    
    # ç”Ÿæˆæ¸¬è©¦è³‡æ–™
    generator = TestDataGenerator(output_dir="accrual_bot/test_data")
    test_data_dir = generator.generate_all_test_data()
    
    print("\nâœ… æ¸¬è©¦è³‡æ–™æº–å‚™å®Œæˆ")
    print(f"ğŸ“ è³‡æ–™ä½ç½®: {test_data_dir}")
    
    return test_data_dir


async def example_1_basic_processing():
    """
    ç¯„ä¾‹1ï¼šåŸºæœ¬è™•ç†æµç¨‹
    æœ€ç°¡å–®çš„ä½¿ç”¨æ–¹å¼
    """
    print("\n" + "=" * 50)
    print("ç¯„ä¾‹1ï¼šåŸºæœ¬MOB POè™•ç†")
    print("=" * 50)
    
    # å‰µå»ºç®¡ç†å™¨
    manager = AccrualPipelineManager()
    
    # è¼‰å…¥æ¸¬è©¦è³‡æ–™
    data = pd.read_excel("accrual_bot/test_data/sample_mob_po.xlsx")
    print(f"è¼‰å…¥è³‡æ–™: {len(data)} ç­† MOB PO è¨˜éŒ„")
    
    # å‰µå»ºè™•ç†ä¸Šä¸‹æ–‡
    context = ProcessingContext(
        data=data,
        entity_type="MOB",
        processing_date=202410,
        processing_type="PO"
    )
    
    # ä½¿ç”¨æ¨¡å¼2ï¼ˆåŸºæœ¬è™•ç†ï¼‰å‰µå»ºPipeline
    pipeline = manager._create_pipeline("MOB", "PO", mode=2)
    
    # åŸ·è¡ŒPipeline
    result = await pipeline.execute(context)
    
    # é¡¯ç¤ºçµæœ
    print(f"è™•ç†çµæœï¼š{'æˆåŠŸ' if result['success'] else 'å¤±æ•—'}")
    print(f"åŸ·è¡Œæ™‚é–“ï¼š{result['duration']:.2f}ç§’")
    print(f"è™•ç†è¡Œæ•¸ï¼š{len(context.data)}")
    print(f"æˆåŠŸæ­¥é©Ÿï¼š{result.get('successful_steps', 0)}")
    print(f"å¤±æ•—æ­¥é©Ÿï¼š{result.get('failed_steps', 0)}")
    
    # é¡¯ç¤ºè©³ç´°æ­¥é©Ÿçµæœ
    if 'results' in result and result['results']:
        print("\næ­¥é©ŸåŸ·è¡Œè©³æƒ…ï¼š")
        for step_result in result['results'][:5]:  # åªé¡¯ç¤ºå‰5å€‹
            status_emoji = "âœ…" if step_result['status'] == 'success' else "âŒ"
            print(f"  {status_emoji} {step_result['step_name']}: {step_result['status']}")
    
    return result


async def example_2_with_auxiliary_data():
    """
    ç¯„ä¾‹2ï¼šå«è¼”åŠ©è³‡æ–™çš„è™•ç†
    æ•´åˆæ¡è³¼åº•ç¨¿å’Œä¸ŠæœŸåº•ç¨¿
    """
    print("\n" + "=" * 50)
    print("ç¯„ä¾‹2ï¼šSPT POè™•ç†ï¼ˆå«è¼”åŠ©è³‡æ–™ï¼‰")
    print("=" * 50)
    
    manager = AccrualPipelineManager()
    
    # å¾æ–‡ä»¶è™•ç†ï¼ŒåŒ…å«è¼”åŠ©è³‡æ–™
    result = await manager.process_from_files(
        data_path="accrual_bot/test_data/sample_spt_po.xlsx",
        entity_type="SPT",
        processing_date=202410,
        processing_type="PO",
        mode=1,  # å®Œæ•´è™•ç†æ¨¡å¼
        auxiliary_files={
            'procurement': 'accrual_bot/test_data/procurement.xlsx',
            'previous_workpaper': 'accrual_bot/test_data/previous_workpaper.xlsx'
        }
    )
    
    print(f"è™•ç†çµæœï¼š{'æˆåŠŸ' if result['success'] else 'å¤±æ•—'}")
    print(f"åŸ·è¡Œæ­¥é©Ÿæ•¸ï¼š{result.get('executed_steps', 0)}")
    print(f"è™•ç†æ™‚é–“ï¼š{result.get('duration', 0):.2f}ç§’")
    
    # é¡¯ç¤ºå„æ­¥é©Ÿçµæœ
    if 'results' in result and result['results']:
        print("\næ­¥é©ŸåŸ·è¡Œè©³æƒ…ï¼š")
        success_count = sum(1 for r in result['results'] if r['status'] == 'success')
        failed_count = sum(1 for r in result['results'] if r['status'] == 'failed')
        skipped_count = sum(1 for r in result['results'] if r['status'] == 'skipped')
        
        print(f"  æˆåŠŸ: {success_count} | å¤±æ•—: {failed_count} | è·³é: {skipped_count}")
        
        # é¡¯ç¤ºå¤±æ•—çš„æ­¥é©Ÿ
        if failed_count > 0:
            print("\n  å¤±æ•—æ­¥é©Ÿï¼š")
            for step_result in result['results']:
                if step_result['status'] == 'failed':
                    print(f"    âŒ {step_result['step_name']}: {step_result.get('message', '')}")
    
    return result


async def example_3_spx_special_processing():
    """
    ç¯„ä¾‹3ï¼šSPXç‰¹æ®Šè™•ç†
    åŒ…å«æŠ¼é‡‘ã€ç§Ÿé‡‘ã€è³‡ç”¢é©—æ”¶ç­‰è¤‡é›œé‚è¼¯
    """
    print("\n" + "=" * 50)
    print("ç¯„ä¾‹3ï¼šSPXç‰¹æ®Šè™•ç†æµç¨‹")
    print("=" * 50)
    
    manager = AccrualPipelineManager()
    
    # è¼‰å…¥SPXæ¸¬è©¦è³‡æ–™
    data = pd.read_excel("accrual_bot/test_data/sample_spx_po.xlsx")
    print(f"è¼‰å…¥è³‡æ–™: {len(data)} ç­† SPX PO è¨˜éŒ„")
    
    # æª¢æŸ¥ç‰¹æ®Šé …ç›®
    if 'Item Description' in data.columns:
        deposit_count = data['Item Description'].str.contains('æŠ¼é‡‘|ä¿è­‰é‡‘|Deposit', na=False).sum()
        rent_count = data['Item Description'].str.contains('ç§Ÿé‡‘|Rent', na=False).sum()
        kiosk_count = data['Item Description'].str.contains('Kiosk', na=False).sum()
        locker_count = data['Item Description'].str.contains('Locker', na=False).sum()
        
        print("\nç‰¹æ®Šé …ç›®åˆ†å¸ƒï¼š")
        print(f"  - æŠ¼é‡‘é …ç›®: {deposit_count}")
        print(f"  - ç§Ÿé‡‘é …ç›®: {rent_count}")
        print(f"  - Kioskè¨­å‚™: {kiosk_count}")
        print(f"  - Lockerè¨­å‚™: {locker_count}")
    
    # ä½¿ç”¨SPXç‰¹æ®Šæ¨¡æ¿
    result = await manager.process_with_template(
        template_name="SPX_Special",
        data=data,
        entity_type="SPX",
        processing_date=202410,
        processing_type="PO",
        deposit_keywords='æŠ¼é‡‘|ä¿è­‰é‡‘|Deposit',
        require_validation=True,
        export_format="excel",
        output_path="output/spx"
    )
    
    print(f"\nè™•ç†çµæœï¼š{'æˆåŠŸ' if result['success'] else 'å¤±æ•—'}")
    
    # é¡¯ç¤ºç‰¹æ®Šè™•ç†çµ±è¨ˆ
    if result['success']:
        if 'output_data' in result:
            output_data = result['output_data']
            print("\nè™•ç†å¾Œçµ±è¨ˆï¼š")
            
            # çµ±è¨ˆå„ç¨®æ¨™è¨˜
            if 'æŠ¼é‡‘æ¨™è¨˜' in output_data.columns:
                deposit_marked = (output_data['æŠ¼é‡‘æ¨™è¨˜'] == 'Y').sum()
                print(f"  - è­˜åˆ¥ç‚ºæŠ¼é‡‘: {deposit_marked}")
            
            if 'ç§Ÿé‡‘æ¨™è¨˜' in output_data.columns:
                rent_marked = (output_data['ç§Ÿé‡‘æ¨™è¨˜'] == 'Y').sum()
                print(f"  - è­˜åˆ¥ç‚ºç§Ÿé‡‘: {rent_marked}")
            
            if 'é©—æ”¶ç‹€æ…‹' in output_data.columns:
                validation_status = output_data['é©—æ”¶ç‹€æ…‹'].value_counts()
                print("  - é©—æ”¶ç‹€æ…‹åˆ†å¸ƒ:")
                for status, count in validation_status.items():
                    print(f"    â€¢ {status}: {count}")
    
    return result


async def example_4_adaptive_mode():
    """
    ç¯„ä¾‹4ï¼šè‡ªé©æ‡‰æ¨¡å¼é¸æ“‡
    ç³»çµ±è‡ªå‹•æ ¹æ“šæ•¸æ“šç‰¹å¾µé¸æ“‡æœ€ä½³è™•ç†æ¨¡å¼
    """
    print("\n" + "=" * 50)
    print("ç¯„ä¾‹4ï¼šè‡ªé©æ‡‰æ¨¡å¼è™•ç†")
    print("=" * 50)
    
    manager = AccrualPipelineManager()
    
    # æ¸¬è©¦ä¸åŒå¤§å°çš„è³‡æ–™é›†
    test_cases = [
        ("accrual_bot/test_data/sample_mob_po.xlsx", "MOB", 50),   # å°è³‡æ–™é›†
        ("accrual_bot/test_data/mob_po_202410.xlsx", "MOB", 100),  # ä¸­ç­‰è³‡æ–™é›†
        ("accrual_bot/test_data/sample_data.xlsx", "MOB", 200)      # å¤§è³‡æ–™é›†
    ]
    
    for data_path, entity_type, expected_rows in test_cases:
        print(f"\næ¸¬è©¦è³‡æ–™: {Path(data_path).name} ({expected_rows}è¡Œ)")
        
        # ä¸æŒ‡å®šmodeï¼Œè®“ç³»çµ±è‡ªå‹•é¸æ“‡
        result = await manager.process_from_files(
            data_path=data_path,
            entity_type=entity_type,
            processing_date=202410,
            processing_type="PO",
            mode=None,  # è‡ªå‹•é¸æ“‡æ¨¡å¼
            auxiliary_files={
                'procurement': 'accrual_bot/test_data/procurement.xlsx'
            }
        )
        
        print(f"  è™•ç†çµæœï¼š{'æˆåŠŸ' if result['success'] else 'å¤±æ•—'}")
        
        # å¾contextä¸­ç²å–é¸æ“‡çš„æ¨¡å¼
        # æ³¨æ„ï¼šé€™éœ€è¦åœ¨å¯¦éš›åŸ·è¡Œä¸­å¾contextç²å–
        mode_names = {
            1: "å®Œæ•´è™•ç†",
            2: "åŸºæœ¬è™•ç†", 
            3: "PRè™•ç†",
            4: "å¿«é€Ÿè™•ç†",
            5: "SPXç‰¹æ®Š"
        }
        
        # é€™è£¡ç°¡å–®æ ¹æ“šè³‡æ–™å¤§å°æ¨æ¸¬
        if expected_rows < 100:
            selected_mode = 4  # å¿«é€Ÿè™•ç†
        elif expected_rows < 150:
            selected_mode = 2  # åŸºæœ¬è™•ç†
        else:
            selected_mode = 1  # å®Œæ•´è™•ç†
            
        print(f"  æ¨æ¸¬é¸æ“‡æ¨¡å¼ï¼šMode {selected_mode} ({mode_names.get(selected_mode, 'æœªçŸ¥')})")
    
    return result


async def example_5_pr_processing():
    """
    ç¯„ä¾‹5ï¼šPRè™•ç†
    ç°¡åŒ–çš„PRè™•ç†æµç¨‹
    """
    print("\n" + "=" * 50)
    print("ç¯„ä¾‹5ï¼šPRè™•ç†æµç¨‹")
    print("=" * 50)
    
    manager = AccrualPipelineManager()
    
    # æ¸¬è©¦ä¸‰å€‹å¯¦é«”çš„PRè™•ç†
    entities = ["MOB", "SPT", "SPX"]
    
    for entity in entities:
        print(f"\nè™•ç† {entity} PRè³‡æ–™...")
        
        # PRè™•ç†ä½¿ç”¨æ¨¡å¼3
        result = await manager.process_from_files(
            data_path=f"accrual_bot/test_data/sample_{entity.lower()}_pr.xlsx",
            entity_type=entity,
            processing_date=202410,
            processing_type="PR",
            mode=3,
            save_results=False  # PRé€šå¸¸ä¸éœ€è¦ä¿å­˜çµæœ
        )
        
        print(f"  {entity} PRè™•ç†ï¼š{'æˆåŠŸ' if result['success'] else 'å¤±æ•—'}")
        
        if result['success'] and 'output_data' in result:
            pr_data = result['output_data']
            print(f"  è™•ç†é …ç›®æ•¸ï¼š{len(pr_data)}")
            
            # é¡¯ç¤ºç‹€æ…‹åˆ†å¸ƒ
            if 'PRç‹€æ…‹' in pr_data.columns:
                status_counts = pr_data['PRç‹€æ…‹'].value_counts()
                print("  ç‹€æ…‹åˆ†å¸ƒï¼š")
                for status, count in status_counts.items()[:3]:
                    print(f"    â€¢ {status}: {count}")
    
    return result


async def example_6_custom_pipeline():
    """
    ç¯„ä¾‹6ï¼šè‡ªå®šç¾©Pipeline
    æ ¹æ“šç‰¹å®šéœ€æ±‚çµ„åˆæ­¥é©Ÿ
    """
    print("\n" + "=" * 50)
    print("ç¯„ä¾‹6ï¼šè‡ªå®šç¾©Pipeline - æ•¸æ“šå“è³ªæª¢æŸ¥")
    print("=" * 50)
    
    from accrual_bot.core.pipeline.pipeline import PipelineBuilder
    from accrual_bot.core.pipeline.steps import (
        DataCleaningStep,
        DateFormattingStep,
        ValidationStep,
        MOBValidationStep
    )
    
    # å‰µå»ºè‡ªå®šç¾©Pipeline - å°ˆæ³¨æ–¼æ•¸æ“šå“è³ª
    builder = PipelineBuilder("Custom_Quality_Check", "MOB")
    builder.with_stop_on_error(False)  # ä¸å› éŒ¯èª¤åœæ­¢ï¼Œæ”¶é›†æ‰€æœ‰å•é¡Œ
    
    # åªæ·»åŠ æ¸…ç†å’Œé©—è­‰æ­¥é©Ÿ
    builder.add_steps(
        DataCleaningStep(
            name="InitialClean",
            columns_to_clean=['Item Description', 'GL#', 'Department']
        ),
        DateFormattingStep(
            name="DateFormat",
            date_columns={
                'Expected Receive Month': '%b-%y',
                'Submission Date': '%d-%b-%y'
            }
        ),
        ValidationStep(
            name="BasicValidation",
            validations=['required_columns', 'data_types']
        ),
        MOBValidationStep(
            name="MOBSpecificValidation"
        )
    )
    
    pipeline = builder.build()
    
    # è¼‰å…¥æ¸¬è©¦è³‡æ–™
    data = pd.read_excel("accrual_bot/test_data/sample_mob_po.xlsx")
    print(f"è¼‰å…¥è³‡æ–™: {len(data)} ç­†è¨˜éŒ„")
    
    context = ProcessingContext(
        data=data,
        entity_type="MOB",
        processing_date=202410,
        processing_type="PO"
    )
    
    # åŸ·è¡Œè‡ªå®šç¾©Pipeline
    result = await pipeline.execute(context)
    
    print(f"\nå“è³ªæª¢æŸ¥çµæœï¼š{'é€šé' if result['success'] else 'ç™¼ç¾å•é¡Œ'}")
    print(f"é©—è­‰éŒ¯èª¤æ•¸ï¼š{len(context.errors)}")
    print(f"é©—è­‰è­¦å‘Šæ•¸ï¼š{len(context.warnings)}")
    
    # é¡¯ç¤ºç™¼ç¾çš„å•é¡Œ
    if context.errors:
        print("\nç™¼ç¾çš„éŒ¯èª¤ï¼š")
        for i, error in enumerate(context.errors[:3], 1):
            print(f"  {i}. {error}")
        if len(context.errors) > 3:
            print(f"  ... é‚„æœ‰ {len(context.errors)-3} å€‹éŒ¯èª¤")
    
    if context.warnings:
        print("\nç™¼ç¾çš„è­¦å‘Šï¼š")
        for i, warning in enumerate(context.warnings[:3], 1):
            print(f"  {i}. {warning}")
        if len(context.warnings) > 3:
            print(f"  ... é‚„æœ‰ {len(context.warnings)-3} å€‹è­¦å‘Š")
    
    return result


async def example_7_batch_processing():
    """
    ç¯„ä¾‹7ï¼šæ‰¹æ¬¡è™•ç†
    è™•ç†å¤šå€‹å¯¦é«”çš„æ•¸æ“š
    """
    print("\n" + "=" * 50)
    print("ç¯„ä¾‹7ï¼šæ‰¹æ¬¡è™•ç†å¤šå€‹å¯¦é«”")
    print("=" * 50)
    
    manager = AccrualPipelineManager()
    
    # å®šç¾©æ‰¹æ¬¡ä»»å‹™
    tasks = [
        {"entity": "MOB", "file": "accrual_bot/test_data/mob_po_202410.xlsx", "name": "MOBåæœˆPO"},
        {"entity": "SPT", "file": "accrual_bot/test_data/spt_po_202410.xlsx", "name": "SPTåæœˆPO"},
        {"entity": "SPX", "file": "accrual_bot/test_data/spx_po_202410.xlsx", "name": "SPXåæœˆPO"}
    ]
    
    print(f"æº–å‚™è™•ç† {len(tasks)} å€‹æ‰¹æ¬¡ä»»å‹™...")
    
    results = {}
    start_time = datetime.now()
    
    # ä¸¦è¡Œè™•ç†æ‰€æœ‰ä»»å‹™
    async def process_entity(task):
        print(f"  é–‹å§‹è™•ç† {task['name']}...")
        result = await manager.process_from_files(
            data_path=task["file"],
            entity_type=task["entity"],
            processing_date=202410,
            processing_type="PO",
            mode=2  # ä½¿ç”¨åŸºæœ¬æ¨¡å¼åŠ å¿«è™•ç†
        )
        return task["entity"], result
    
    # åŸ·è¡Œæ‰¹æ¬¡è™•ç†
    batch_tasks = [process_entity(task) for task in tasks]
    batch_results = await asyncio.gather(*batch_tasks, return_exceptions=True)
    
    # æ•´ç†çµæœ
    for item in batch_results:
        if isinstance(item, Exception):
            print(f"  âŒ è™•ç†å¤±æ•—ï¼š{str(item)}")
        else:
            entity, result = item
            results[entity] = result
            status = "âœ… æˆåŠŸ" if result['success'] else "âŒ å¤±æ•—"
            duration = result.get('duration', 0)
            print(f"  {status} {entity}: è€—æ™‚ {duration:.2f}ç§’")
    
    # ç¸½çµ
    total_time = (datetime.now() - start_time).total_seconds()
    success_count = sum(1 for r in results.values() if r['success'])
    
    print("\næ‰¹æ¬¡è™•ç†å®Œæˆçµ±è¨ˆï¼š")
    print(f"  - æˆåŠŸ: {success_count}/{len(results)}")
    print(f"  - ç¸½è€—æ™‚: {total_time:.2f}ç§’")
    print(f"  - å¹³å‡è€—æ™‚: {total_time/len(results):.2f}ç§’/ä»»å‹™")
    
    return results


async def example_8_error_handling():
    """
    ç¯„ä¾‹8ï¼šéŒ¯èª¤è™•ç†å’Œæ¢å¾©
    å±•ç¤ºPipelineçš„éŒ¯èª¤è™•ç†æ©Ÿåˆ¶
    """
    print("\n" + "=" * 50)
    print("ç¯„ä¾‹8ï¼šéŒ¯èª¤è™•ç†ç¤ºä¾‹")
    print("=" * 50)
    
    from accrual_bot.core.pipeline.pipeline import PipelineBuilder
    from accrual_bot.core.pipeline.steps import DataCleaningStep, ValidationStep
    
    # è¼‰å…¥æœ‰å•é¡Œçš„æ¸¬è©¦è³‡æ–™
    bad_data = pd.read_excel("accrual_bot/test_data/bad_data.xlsx")
    print(f"è¼‰å…¥å•é¡Œè³‡æ–™: {len(bad_data)} ç­†è¨˜éŒ„")
    
    # é¡¯ç¤ºè³‡æ–™å•é¡Œ
    print("\nè³‡æ–™å•é¡Œé è¦½ï¼š")
    print(f"  - ç©ºå€¼PO#: {bad_data['PO#'].isna().sum()}")
    invalid_amt = (bad_data['Entry Amount']
                   .apply(
                       lambda x: not str(x).replace('.', '').replace('-', '').isdigit() if pd.notna(x) else True
    ).sum()
    )
    print(f"  - ç„¡æ•ˆé‡‘é¡: {invalid_amt}")
    print(f"  - ç©ºå€¼GL#: {bad_data['GL#'].isna().sum()}")
    
    # å‰µå»ºåŒ…å«éŒ¯èª¤è™•ç†çš„Pipeline
    builder = PipelineBuilder("Error_Handling_Demo", "MOB")
    builder.with_stop_on_error(False)  # ä¸å› éŒ¯èª¤åœæ­¢ï¼Œç¹¼çºŒåŸ·è¡Œ
    
    builder.add_steps(
        DataCleaningStep(
            name="CleanWithErrors",
            required=False  # éå¿…éœ€æ­¥é©Ÿ
        ),
        ValidationStep(
            name="StrictValidation",
            validations=['required_columns', 'data_types'],
            required=False,  # å¤±æ•—ä¸åœæ­¢Pipeline
            retry_count=2    # é‡è©¦2æ¬¡
        )
    )
    
    pipeline = builder.build()
    
    context = ProcessingContext(
        data=bad_data,
        entity_type="MOB",
        processing_date=202410,
        processing_type="PO"
    )
    
    # åŸ·è¡Œä¸¦è™•ç†éŒ¯èª¤
    result = await pipeline.execute(context)
    
    print(f"\nåŸ·è¡Œçµæœï¼š{'å®Œæˆ' if result else 'å¤±æ•—'}")
    print(f"Pipelineç‹€æ…‹ï¼š{'æˆåŠŸ' if result.get('success') else 'éƒ¨åˆ†å¤±æ•—'}")
    
    # è©³ç´°éŒ¯èª¤å ±å‘Š
    if context.errors or context.warnings:
        print("\néŒ¯èª¤è™•ç†å ±å‘Šï¼š")
        print(f"  éŒ¯èª¤æ•¸é‡: {len(context.errors)}")
        print(f"  è­¦å‘Šæ•¸é‡: {len(context.warnings)}")
        
        if context.errors:
            print("\n  ä¸»è¦éŒ¯èª¤ï¼š")
            for i, error in enumerate(context.errors[:3], 1):
                print(f"    {i}. {error[:100]}...")  # æˆªæ–·é•·éŒ¯èª¤ä¿¡æ¯
        
        if context.warnings:
            print("\n  ä¸»è¦è­¦å‘Šï¼š")
            for i, warning in enumerate(context.warnings[:3], 1):
                print(f"    {i}. {warning[:100]}...")
    
    # é¡¯ç¤ºæ¢å¾©æƒ…æ³
    if 'results' in result:
        recovered = (sum(1 for r in result['results'] 
                     if r.get('status') == 'success' and r.get('metadata', {}).get('retry_count', 0) > 0))
        if recovered > 0:
            print(f"\n  âœ“ {recovered} å€‹æ­¥é©Ÿé€šéé‡è©¦æ¢å¾©")
    
    return result


async def example_9_performance_test():
    """
    ç¯„ä¾‹9ï¼šæ•ˆèƒ½æ¸¬è©¦
    æ¸¬è©¦ä¸åŒè¦æ¨¡è³‡æ–™çš„è™•ç†æ•ˆèƒ½
    """
    print("\n" + "=" * 50)
    print("ç¯„ä¾‹9ï¼šæ•ˆèƒ½æ¸¬è©¦")
    print("=" * 50)
    
    manager = AccrualPipelineManager()
    
    # ç”Ÿæˆä¸åŒè¦æ¨¡çš„æ¸¬è©¦è³‡æ–™
    generator = TestDataGenerator(output_dir="accrual_bot/test_data")
    
    test_sizes = [10, 50, 100, 500]
    performance_results = []
    
    print("æ¸¬è©¦ä¸åŒè¦æ¨¡è³‡æ–™çš„è™•ç†æ•ˆèƒ½...")
    
    for size in test_sizes:
        # ç”Ÿæˆæ¸¬è©¦è³‡æ–™
        test_data = generator.generate_mob_po_data(size)
        
        # æ¸¬è©¦è™•ç†æ™‚é–“
        start_time = datetime.now()
        
        context = ProcessingContext(
            data=test_data,
            entity_type="MOB",
            processing_date=202410,
            processing_type="PO"
        )
        
        pipeline = manager._create_pipeline("MOB", "PO", mode=4)  # å¿«é€Ÿæ¨¡å¼
        result = await pipeline.execute(context)
        
        duration = (datetime.now() - start_time).total_seconds()
        
        performance_results.append({
            'size': size,
            'duration': duration,
            'success': result['success']
        })
        
        print(f"  {size:4d} ç­†è³‡æ–™: {duration:.3f}ç§’ ({'æˆåŠŸ' if result['success'] else 'å¤±æ•—'})")
    
    # åˆ†ææ•ˆèƒ½
    print("\næ•ˆèƒ½åˆ†æï¼š")
    if len(performance_results) > 1:
        # è¨ˆç®—å¹³å‡è™•ç†é€Ÿåº¦
        total_rows = sum(r['size'] for r in performance_results)
        total_time = sum(r['duration'] for r in performance_results)
        avg_speed = total_rows / total_time if total_time > 0 else 0
        
        print(f"  å¹³å‡è™•ç†é€Ÿåº¦: {avg_speed:.1f} ç­†/ç§’")
        
        # æª¢æŸ¥æ˜¯å¦ç·šæ€§å¢é•·
        if len(performance_results) >= 2:
            time_ratio = performance_results[-1]['duration'] / performance_results[0]['duration']
            size_ratio = performance_results[-1]['size'] / performance_results[0]['size']
            efficiency = size_ratio / time_ratio if time_ratio > 0 else 0
            
            print(f"  æ“´å±•æ•ˆç‡: {efficiency:.2f} (1.0 = å®Œç¾ç·šæ€§)")
    
    return performance_results


async def run_all_examples():
    """åŸ·è¡Œæ‰€æœ‰ç¯„ä¾‹"""
    print("\n" + "#" * 60)
    print("#" + " " * 18 + "Pipeline ä½¿ç”¨ç¯„ä¾‹" + " " * 21 + "#")
    print("#" * 60)
    
    # è¨­ç½®æ¸¬è©¦è³‡æ–™
    test_data_dir = await setup_test_data()
    
    # æ‰€æœ‰ç¯„ä¾‹å‡½æ•¸
    examples = [
        ("åŸºæœ¬è™•ç†", example_1_basic_processing),
        ("è¼”åŠ©è³‡æ–™æ•´åˆ", example_2_with_auxiliary_data),
        ("SPXç‰¹æ®Šè™•ç†", example_3_spx_special_processing),
        ("è‡ªé©æ‡‰æ¨¡å¼", example_4_adaptive_mode),
        ("PRè™•ç†", example_5_pr_processing),
        ("è‡ªå®šç¾©Pipeline", example_6_custom_pipeline),
        ("æ‰¹æ¬¡è™•ç†", example_7_batch_processing),
        ("éŒ¯èª¤è™•ç†", example_8_error_handling),
        ("æ•ˆèƒ½æ¸¬è©¦", example_9_performance_test)
    ]
    
    # åŸ·è¡Œçµ±è¨ˆ
    results_summary = {
        'total': len(examples),
        'success': 0,
        'failed': 0,
        'errors': []
    }
    
    # åŸ·è¡Œæ‰€æœ‰ç¯„ä¾‹
    for i, (name, example_func) in enumerate(examples, 1):
        try:
            print(f"\n{'='*60}")
            print(f"åŸ·è¡Œç¯„ä¾‹ {i}/{len(examples)}: {name}")
            print('=' * 60)
            
            await example_func()
            results_summary['success'] += 1
            
        except Exception as e:
            results_summary['failed'] += 1
            error_msg = f"ç¯„ä¾‹{i} ({name}) åŸ·è¡Œå¤±æ•—ï¼š{str(e)}"
            results_summary['errors'].append(error_msg)
            print(f"\nâŒ {error_msg}")
            
            # ç¹¼çºŒåŸ·è¡Œä¸‹ä¸€å€‹ç¯„ä¾‹
            continue
    
    # é¡¯ç¤ºç¸½çµ
    print("\n" + "#" * 60)
    print("#" + " " * 22 + "åŸ·è¡Œç¸½çµ" + " " * 23 + "#")
    print("#" * 60)
    
    print("\nğŸ“Š åŸ·è¡Œçµ±è¨ˆï¼š")
    print(f"  ç¸½ç¯„ä¾‹æ•¸: {results_summary['total']}")
    print(f"  âœ… æˆåŠŸ: {results_summary['success']}")
    print(f"  âŒ å¤±æ•—: {results_summary['failed']}")
    
    if results_summary['errors']:
        print("\nâŒ éŒ¯èª¤åˆ—è¡¨ï¼š")
        for error in results_summary['errors']:
            print(f"  - {error}")
    else:
        print("\nâœ… æ‰€æœ‰ç¯„ä¾‹åŸ·è¡ŒæˆåŠŸï¼")
    
    print(f"\nğŸ“ æ¸¬è©¦è³‡æ–™ä½ç½®: {test_data_dir}")
    print("ğŸ’¡ æç¤º: æ‚¨å¯ä»¥å–®ç¨åŸ·è¡Œä»»ä½•ç¯„ä¾‹å‡½æ•¸ä¾†æ·±å…¥äº†è§£ç‰¹å®šåŠŸèƒ½")
    
    print("\n" + "#" * 60)


async def run_single_example(example_number: int):
    """
    åŸ·è¡Œå–®å€‹ç¯„ä¾‹
    
    Args:
        example_number: ç¯„ä¾‹ç·¨è™Ÿ (1-9)
    """
    # è¨­ç½®æ¸¬è©¦è³‡æ–™
    await setup_test_data()
    
    examples = [
        example_1_basic_processing,
        example_2_with_auxiliary_data,
        example_3_spx_special_processing,
        example_4_adaptive_mode,
        example_5_pr_processing,
        example_6_custom_pipeline,
        example_7_batch_processing,
        example_8_error_handling,
        example_9_performance_test
    ]
    
    if 1 <= example_number <= len(examples):
        print(f"\nåŸ·è¡Œç¯„ä¾‹ {example_number}...")
        await examples[example_number - 1]()
    else:
        print(f"âŒ ç„¡æ•ˆçš„ç¯„ä¾‹ç·¨è™Ÿã€‚è«‹é¸æ“‡ 1-{len(examples)} ä¹‹é–“çš„æ•¸å­—ã€‚")


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        # å¦‚æœæä¾›äº†åƒæ•¸ï¼ŒåŸ·è¡ŒæŒ‡å®šçš„ç¯„ä¾‹
        try:
            example_num = int(sys.argv[1])
            asyncio.run(run_single_example(example_num))
        except ValueError:
            print("âŒ è«‹æä¾›æœ‰æ•ˆçš„ç¯„ä¾‹ç·¨è™Ÿ (1-9)")
            print("ç”¨æ³•: python examples.py [ç¯„ä¾‹ç·¨è™Ÿ]")
            print("æˆ–ç›´æ¥åŸ·è¡Œ python examples.py ä¾†é‹è¡Œæ‰€æœ‰ç¯„ä¾‹")
    else:
        # åŸ·è¡Œæ‰€æœ‰ç¯„ä¾‹
        asyncio.run(run_all_examples())
